{"cells":[{"cell_type":"markdown","source":["Trail and Error Method\n","\n","I used this notebook for identifing the structure of website, API call etc\n","\n","```\n","First trying to print all the grama panjayaths of malappuram\n","```\n","\n"],"metadata":{"id":"ZM7m8EAO56OG"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1053,"status":"ok","timestamp":1766297578050,"user":{"displayName":"FARHAN JAFFAR","userId":"00674461129948116447"},"user_tz":-330},"id":"KLKlgFN6X4Xn","outputId":"559706a8-86b2-448e-c898-58ad3f953220"},"outputs":[{"name":"stdout","output_type":"stream","text":["--- Starting Scraping for Year 2020 ---\n","Fetching list for Dist 1 - Grama Panchayat...\n","  -> Error: Expecting value: line 8 column 1 (char 7)\n","No data found. Check 'lb_id' payload key.\n"]}],"source":["import requests\n","import pandas as pd\n","import time\n","import urllib3\n","\n","# Disable SSL warnings (common for these gov sites)\n","urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n","\n","# --- CORRECTED URLS  ---\n","BASE_URL_LIST = \"https://lbtrend.kerala.gov.in/includes/stateView2_ajax.php\"\n","BASE_URL_DETAILS = \"https://lbtrend.kerala.gov.in/includes/lb_ajax2.php\"\n","\n","HEADERS = {\n","    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36\",\n","    \"X-Requested-With\": \"XMLHttpRequest\",\n","    \"Referer\": \"https://lbtrend.kerala.gov.in/\"\n","}\n","\n","# Mapping: G=Grama Pyt, B=Block, D=District, M=Municipality, C=Corp\n","LB_TYPES = {\n","    \"G\": \"Grama Panchayat\",\n","    # Uncomment these when ready to scrape everything\n","    # \"B\": \"Block Panchayat\",\n","    # \"D\": \"District Panchayat\",\n","    # \"M\": \"Municipality\",\n","    # \"C\": \"Corporation\"\n","}\n","\n","def scrape_kerala_election(year=2020):\n","    master_data = []\n","\n","    # Testing with just District 1 (Thiruvananthapuram) first\n","    districts = [1]\n","\n","    print(f\"--- Starting Scraping for Year {year} ---\")\n","\n","    with requests.Session() as session:\n","        session.headers.update(HEADERS)\n","\n","        for dist_id in districts:\n","            for lb_code, lb_name in LB_TYPES.items():\n","\n","                # 1. GET LIST OF LOCAL BODIES\n","                payload_list = {\"year\": year, \"district\": dist_id, \"type\": lb_code}\n","\n","                try:\n","                    print(f\"Fetching list for Dist {dist_id} - {lb_name}...\")\n","                    resp = session.post(BASE_URL_LIST, data=payload_list, verify=False)\n","\n","                    if resp.status_code != 200:\n","                        print(f\"Error: Status {resp.status_code}\")\n","                        continue\n","\n","                    data_list = resp.json()\n","                    # The list is in \"summary\" based on your previous logs\n","                    local_bodies = data_list.get(\"summary\", [])\n","\n","                    print(f\"  -> Found {len(local_bodies)} local bodies.\")\n","\n","                    # 2. GET DETAILS FOR EACH BODY\n","                    # Limit to first 3 bodies for testing\n","                    for body in local_bodies[:3]:\n","                        lb_id = body[0]   # ID (e.g. G001)\n","                        lb_text = body[1] # Name (e.g. Adimaly)\n","\n","                        # PAYLOAD FOR DETAILS\n","                        # NOTE: Ensure key is 'lb_id' or 'lbid' based on your network tab!\n","                        payload_details = {\"year\": year, \"lb_id\": lb_id}\n","\n","                        resp_det = session.post(BASE_URL_DETAILS, data=payload_details, verify=False)\n","                        det_json = resp_det.json()\n","\n","                        # FIND THE WARDS DATA\n","                        # It is likely under 'wards', 'data', or just the root list.\n","                        # We try to find the list dynamically:\n","                        wards = []\n","                        if \"wards\" in det_json: wards = det_json[\"wards\"]\n","                        elif \"data\" in det_json: wards = det_json[\"data\"]\n","                        elif isinstance(det_json, list): wards = det_json\n","\n","                        for w in wards:\n","                            # Mapping based on your table screenshot:\n","                            # Col 0: Party (UDF)\n","                            # Col 1: Ward No (001)\n","                            # Col 2: Ward Name (Valliyaparamba)\n","                            # Col 4: Candidate Name (Malayalam text)\n","                            # Col 5: Votes\n","\n","                            master_data.append({\n","                                \"District\": dist_id,\n","                                \"Local Body\": lb_text,\n","                                \"Type\": lb_name,\n","                                \"WardName\": f\"{w[1]} - {w[2]}\",\n","                                \"Candidate\": w[4],\n","                                \"Party\": w[0],\n","                                \"Front\": w[0], # Usually same as party in this summary\n","                                \"Votes\": w[5],\n","                                \"Year\": year\n","                            })\n","\n","                        time.sleep(0.5) # Be polite\n","\n","                except Exception as e:\n","                    print(f\"  -> Error: {e}\")\n","\n","    # SAVE\n","    if master_data:\n","        df = pd.DataFrame(master_data)\n","        print(\"\\n--- SCRAPING SUCCESS! ---\")\n","        print(df.head())\n","        df.to_csv(\"kerala_election_sample.csv\", index=False)\n","    else:\n","        print(\"No data found. Check 'lb_id' payload key.\")\n","\n","if __name__ == \"__main__\":\n","    scrape_kerala_election()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28,"status":"ok","timestamp":1766297507230,"user":{"displayName":"FARHAN JAFFAR","userId":"00674461129948116447"},"user_tz":-330},"id":"pIz-nHVOh249","outputId":"23f6c694-961b-4b06-c055-9af6f0546e0a"},"outputs":[{"data":{"text/plain":["[]"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["master_data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":443,"status":"ok","timestamp":1766297805516,"user":{"displayName":"FARHAN JAFFAR","userId":"00674461129948116447"},"user_tz":-330},"id":"mUv2U-sUe49c","outputId":"121e1c95-f987-4544-fc20-26a3f35e5ce0"},"outputs":[{"name":"stdout","output_type":"stream","text":["--- DEBUGGING SERVER RESPONSE ---\n","Status Code: 200\n","\n","--- RAW RESPONSE TEXT (First 500 chars) ---\n","\n","\n","\n","\n","\n","\n","\n","\n","-------------------------------------------\n","DIAGNOSIS: Server returned EMPTY response.\n"]}],"source":["import requests\n","import urllib3\n","\n","# Disable SSL warnings\n","urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n","\n","# CONFIG\n","URL_LIST = \"https://lbtrend.kerala.gov.in/includes/stateView2_ajax.php\"\n","HEADERS = {\n","    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36\",\n","    \"X-Requested-With\": \"XMLHttpRequest\",\n","    \"Referer\": \"https://lbtrend.kerala.gov.in/\"\n","}\n","\n","def debug_response():\n","    print(\"--- DEBUGGING SERVER RESPONSE ---\")\n","\n","    # We try 'd' instead of 'district' just in case that's the issue\n","    # We also try 't' instead of 'type'\n","    payload = {\n","        \"year\": 2020,\n","        \"d\": 1,        # Common abbreviation in PHP sites\n","        \"district\": 1, # Sending both to be safe\n","        \"type\": \"G\",\n","        \"t\": \"G\"\n","    }\n","\n","    try:\n","        resp = requests.post(URL_LIST, data=payload, headers=HEADERS, verify=False)\n","\n","        print(f\"Status Code: {resp.status_code}\")\n","        print(\"\\n--- RAW RESPONSE TEXT (First 500 chars) ---\")\n","        # This will show us the PHP error or the whitespace\n","        print(resp.text[:500])\n","        print(\"-------------------------------------------\")\n","\n","        # Check if it works if we strip whitespace\n","        clean_text = resp.text.strip()\n","        if clean_text.startswith((\"<br\", \"<b\", \"Error\")):\n","            print(\"DIAGNOSIS: Server returned an HTML Error (likely PHP error).\")\n","        elif not clean_text:\n","            print(\"DIAGNOSIS: Server returned EMPTY response.\")\n","        else:\n","            print(\"DIAGNOSIS: Response received. Trying to parse...\")\n","            try:\n","                data = resp.json()\n","                print(\"SUCCESS! JSON Parsed.\")\n","                print(\"Keys found:\", data.keys())\n","            except:\n","                print(\"JSON Parse Failed. The data might be in a different format (e.g., JS Array).\")\n","\n","    except Exception as e:\n","        print(f\"Connection Error: {e}\")\n","\n","if __name__ == \"__main__\":\n","    debug_response()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4389,"status":"ok","timestamp":1766297816248,"user":{"displayName":"FARHAN JAFFAR","userId":"00674461129948116447"},"user_tz":-330},"id":"j4B1VhXXjaxJ","outputId":"8eff57cd-447a-4cff-94d1-048f3646e559"},"outputs":[{"name":"stdout","output_type":"stream","text":["--- 1. Getting Session Cookies ---\n","Cookies obtained: {}\n","\n","--- 2. Brute-Forcing Parameter Names ---\n","\n","\n","[FAILURE] None of the combinations worked.\n","Please manually check the 'Payload' tab in your browser Network tools.\n","Look for the 'Form Data' section.\n"]}],"source":["import requests\n","import urllib3\n","import time\n","\n","# Disable SSL warnings\n","urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n","\n","# CONFIG\n","HOME_URL = \"https://lbtrend.kerala.gov.in/\"\n","AJAX_URL = \"https://lbtrend.kerala.gov.in/includes/stateView2_ajax.php\"\n","\n","HEADERS = {\n","    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36\",\n","    \"X-Requested-With\": \"XMLHttpRequest\",\n","    \"Origin\": \"https://lbtrend.kerala.gov.in\",\n","    \"Referer\": \"https://lbtrend.kerala.gov.in/\"\n","}\n","\n","def find_correct_payload():\n","    print(\"--- 1. Getting Session Cookies ---\")\n","    session = requests.Session()\n","    session.headers.update(HEADERS)\n","\n","    try:\n","        # Visit homepage to get PHPSESSID\n","        session.get(HOME_URL, verify=False)\n","        print(\"Cookies obtained:\", session.cookies.get_dict())\n","    except Exception as e:\n","        print(f\"Could not load homepage: {e}\")\n","\n","    print(\"\\n--- 2. Brute-Forcing Parameter Names ---\")\n","\n","    # We know the VALUES (Malappuram=10, or TVM=1, Grama Panchayat=G)\n","    # We just need the KEYS.\n","\n","    # Common variations for \"District\"\n","    dist_keys = [\"district\", \"dist\", \"d\", \"dist_id\", \"district_id\", \"districtId\", \"did\"]\n","    # Common variations for \"Type\"\n","    type_keys = [\"type\", \"lb_type\", \"t\", \"lbt\", \"body_type\", \"lbtype\"]\n","\n","    found = False\n","\n","    for d_key in dist_keys:\n","        for t_key in type_keys:\n","            if found: break\n","\n","            # Construct payload\n","            payload = {\n","                \"year\": 2020,\n","                d_key: 1,  # Thiruvananthapuram\n","                t_key: \"G\" # Grama Panchayat\n","            }\n","\n","            try:\n","                # print(f\"Trying keys: {d_key}, {t_key} ...\", end=\"\\r\")\n","                resp = session.post(AJAX_URL, data=payload, verify=False)\n","\n","                # Check if we got JSON\n","                if resp.status_code == 200 and len(resp.text.strip()) > 0:\n","                    try:\n","                        data = resp.json()\n","                        # If we get a dictionary with \"summary\" or \"mdata\", we won!\n","                        if \"summary\" in data or \"mdata\" in data:\n","                            print(f\"\\n\\n[SUCCESS] FOUND THE KEYS!\")\n","                            print(f\"Correct District Key: '{d_key}'\")\n","                            print(f\"Correct Type Key:     '{t_key}'\")\n","                            print(f\"Response snippet: {str(data)[:100]}...\")\n","                            found = True\n","                    except:\n","                        pass # Not JSON\n","\n","            except Exception:\n","                pass\n","\n","    if not found:\n","        print(\"\\n\\n[FAILURE] None of the combinations worked.\")\n","        print(\"Please manually check the 'Payload' tab in your browser Network tools.\")\n","        print(\"Look for the 'Form Data' section.\")\n","\n","if __name__ == \"__main__\":\n","    find_correct_payload()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":979,"status":"ok","timestamp":1766298413016,"user":{"displayName":"FARHAN JAFFAR","userId":"00674461129948116447"},"user_tz":-330},"id":"qwJZZLnPltRm","outputId":"9f76b69d-81d8-4b9b-d3ab-1e29eaa8b9d5"},"outputs":[{"name":"stdout","output_type":"stream","text":["--- Starting Scraper for Malappuram (D10001) ---\n","1. Fetching list of Local Bodies...\n","   -> Found 5 Local Bodies.\n","2. Fetching details for MALAPPURAM (D10001)...\n","Critical Error: Expecting value: line 1 column 1 (char 0)\n"]}],"source":["import requests\n","import pandas as pd\n","import time\n","import urllib3\n","\n","# Disable SSL warnings\n","urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n","\n","# --- CONFIGURATION ---\n","URL_LIST = \"https://lbtrend.kerala.gov.in/includes/stateView2_ajax.php\"\n","URL_DETAILS = \"https://lbtrend.kerala.gov.in/includes/lb_ajax2.php\"\n","\n","HEADERS = {\n","    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36\",\n","    \"X-Requested-With\": \"XMLHttpRequest\",\n","    \"Referer\": \"https://lbtrend.kerala.gov.in/\"\n","}\n","\n","def scrape_malappuram():\n","    print(\"--- Starting Scraper for Malappuram (D10001) ---\")\n","\n","    session = requests.Session()\n","    session.headers.update(HEADERS)\n","\n","    # 1. GET THE LIST OF PANCHAYATS\n","    # Using the exact keys you found in the payload tab\n","    payload_list = {\n","        \"_p\": \"dv\",      # Fixed value\n","        \"_l\": \"P\",       # Fixed value (Likely 'P' for Grama Panchayat)\n","        \"_d\": \"D10001\",  # Malappuram District Code\n","        \"_s\": \"L\"        # Fixed value\n","    }\n","\n","    try:\n","        print(\"1. Fetching list of Local Bodies...\")\n","        resp_list = session.post(URL_LIST, data=payload_list, verify=False)\n","\n","        # Check for errors\n","        if resp_list.status_code != 200:\n","            print(f\"Error: Status {resp_list.status_code}\")\n","            return\n","\n","        # Parse JSON\n","        data_list = resp_list.json()\n","\n","        # In your screenshot, the list was inside 'summary' or 'mdata'\n","        # Adjust this key if needed based on the response you get\n","        local_bodies = []\n","        if \"summary\" in data_list:\n","            local_bodies = data_list[\"summary\"]\n","        elif \"mdata\" in data_list:\n","            # Sometimes it's inside mdata, we'll print keys to be sure\n","             print(\"Keys found in list:\", data_list.keys())\n","             # Fallback: try to find a list anywhere\n","             for k, v in data_list.items():\n","                 if isinstance(v, list):\n","                     local_bodies = v\n","                     break\n","\n","        print(f\"   -> Found {len(local_bodies)} Local Bodies.\")\n","\n","        # 2. LOOP THROUGH EACH LOCAL BODY\n","        master_data = []\n","\n","        # We limit to 5 bodies for this test to be fast\n","        for body in local_bodies[:5]:\n","            lb_id = body[0]   # e.g., \"G10072\"\n","            lb_name = body[1] # e.g., \"Abdurahman Nagar\"\n","\n","            print(f\"2. Fetching details for {lb_name} ({lb_id})...\")\n","\n","            # PAYLOAD FOR DETAILS\n","            # We assume the key is 'lb_id' or 'id'.\n","            # If this fails, check the Payload tab for lb_ajax2.php!\n","            payload_details = {\n","                \"lb_id\": lb_id,\n","                \"year\": 2020    # Often required\n","            }\n","\n","            resp_det = session.post(URL_DETAILS, data=payload_details, verify=False)\n","\n","            if resp_det.status_code == 200:\n","                det_json = resp_det.json()\n","\n","                # EXTRACT WARD DATA\n","                # Look for 'wards', 'data', or just the root list\n","                wards = []\n","                if \"wards\" in det_json: wards = det_json[\"wards\"]\n","                elif \"data\" in det_json: wards = det_json[\"data\"]\n","\n","                for w in wards:\n","                    # Mapping based on your screenshot:\n","                    # Col 1: Ward No, Col 2: Ward Name, Col 4: Candidate, Col 5: Votes\n","                    master_data.append({\n","                        \"District\": \"Malappuram\",\n","                        \"Local Body\": lb_name,\n","                        \"Ward\": f\"{w[1]} - {w[2]}\",\n","                        \"Candidate\": w[4],\n","                        \"Party\": w[0],\n","                        \"Votes\": w[5]\n","                    })\n","\n","            time.sleep(0.5) # Be polite\n","\n","        # 3. SAVE RESULTS\n","        if master_data:\n","            df = pd.DataFrame(master_data)\n","            print(\"\\n--- SUCCESS! Sample Data ---\")\n","            print(df.head())\n","            df.to_csv(\"Malappuram_Test.csv\", index=False)\n","        else:\n","            print(\"List fetched, but no ward details found. Check 'lb_id' key.\")\n","\n","    except Exception as e:\n","        print(f\"Critical Error: {e}\")\n","\n","if __name__ == \"__main__\":\n","    scrape_malappuram()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":756,"status":"ok","timestamp":1766298598984,"user":{"displayName":"FARHAN JAFFAR","userId":"00674461129948116447"},"user_tz":-330},"id":"FIjCjzR6l43r","outputId":"c7f1e0cc-bed3-45bf-8f6a-d2dc82de69df"},"outputs":[{"name":"stdout","output_type":"stream","text":["--- Starting Final Scraper ---\n","\n","Processing District: D10010\n","  Error on D10010 - Grama Panchayat: Expecting value: line 8 column 1 (char 7)\n","Scraping finished but no data found. Check Dist Code or JSON keys.\n"]}],"source":["import requests\n","import pandas as pd\n","import time\n","import urllib3\n","\n","# 1. SETUP\n","urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n","\n","URL_LIST = \"https://lbtrend.kerala.gov.in/includes/stateView2_ajax.php\"\n","URL_DETAILS = \"https://lbtrend.kerala.gov.in/includes/lb_ajax2.php\"\n","\n","HEADERS = {\n","    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36\",\n","    \"X-Requested-With\": \"XMLHttpRequest\",\n","    \"Referer\": \"https://lbtrend.kerala.gov.in/\"\n","}\n","\n","# 2. DEFINITIONS\n","# Code mapping for the 5 types of bodies\n","# 'P' seems to be the code for Grama Panchayat based on your screenshot\n","LB_TYPES = {\n","    \"P\": \"Grama Panchayat\",\n","    # \"B\": \"Block Panchayat\", # Enable these later\n","    # \"D\": \"District Panchayat\",\n","    # \"M\": \"Municipality\",\n","    # \"C\": \"Corporation\"\n","}\n","\n","def get_district_code(number):\n","    # Formats number 1 to \"D10001\", 10 to \"D10010\"\n","    return f\"D100{number:02d}\"\n","\n","def scrape_kerala_election():\n","    print(\"--- Starting Final Scraper ---\")\n","    master_data = []\n","\n","    # Session keeps our connection alive\n","    session = requests.Session()\n","    session.headers.update(HEADERS)\n","\n","    # Loop through Districts (Malappuram is usually 10, but let's try 1 to 14)\n","    # For testing, we just do ONE district. Change [10] to range(1, 15) for all.\n","    for dist_num in [10]:\n","        dist_code = get_district_code(dist_num) # e.g., D10010\n","        print(f\"\\nProcessing District: {dist_code}\")\n","\n","        for type_code, type_name in LB_TYPES.items():\n","\n","            # --- STEP 1: GET LIST OF LOCAL BODIES ---\n","            payload_list = {\n","                \"_p\": \"dv\",       # Constant\n","                \"_l\": type_code,  # 'P' for Panchayat\n","                \"_d\": dist_code,  # 'D10010'\n","                \"_s\": \"L\"         # Constant\n","            }\n","\n","            try:\n","                resp = session.post(URL_LIST, data=payload_list, verify=False)\n","                data_list = resp.json()\n","\n","                # Extract the list from 'summary' or 'mdata'\n","                # Based on your logs, it's a list inside 'summary'\n","                local_bodies = data_list.get(\"summary\", [])\n","\n","                if not local_bodies:\n","                    print(f\"  No {type_name} found for {dist_code}. Checking 'mdata'...\")\n","                    local_bodies = data_list.get(\"mdata\", [])\n","\n","                print(f\"  -> Found {len(local_bodies)} {type_name}s. Scraping details...\")\n","\n","                # --- STEP 2: LOOP THROUGH EACH BODY ---\n","                # We scrape the first 5 for testing. Remove [:5] to scrape ALL.\n","                for item in local_bodies[:5]:\n","                    lb_id = item[0]    # e.g., G10072\n","                    lb_name = item[1]  # e.g., Abdurehman Nagar\n","\n","                    # PAYLOAD FOR DETAILS (The keys you found!)\n","                    payload_details = {\n","                        \"_p\": \"wv\",       # Ward View\n","                        \"_w\": lb_id,      # The ID (G10072)\n","                        \"_t\": type_code,  # Type (P)\n","                        \"_s\": \"L\"         # Constant\n","                    }\n","\n","                    resp_det = session.post(URL_DETAILS, data=payload_details, verify=False)\n","                    data_det = resp_det.json()\n","\n","                    # Extract Wards\n","                    # Based on your screenshot, data is likely in 'mdata' -> 'wards' or just 'mdata'\n","                    wards = []\n","                    mdata = data_det.get(\"mdata\", {})\n","\n","                    # Handle different JSON structures safely\n","                    if isinstance(mdata, dict):\n","                         # If mdata is a dict, look for 'wards' or 'data' inside\n","                         if \"wards\" in mdata: wards = mdata[\"wards\"]\n","                         elif \"data\" in mdata: wards = mdata[\"data\"]\n","                    elif isinstance(mdata, list):\n","                         # If mdata is directly the list\n","                         wards = mdata\n","\n","                    # If still empty, check root level\n","                    if not wards and \"wards\" in data_det:\n","                        wards = data_det[\"wards\"]\n","\n","                    # PARSE THE ROWS\n","                    for w in wards:\n","                        # Index Mapping (Based on your table screenshot):\n","                        # 0: Party (UDF) | 1: Ward No | 2: Ward Name | 4: Candidate | 5: Votes\n","                        master_data.append({\n","                            \"District\": dist_code,\n","                            \"Local Body\": lb_name,\n","                            \"Type\": type_name,\n","                            \"Ward\": f\"{w[1]} - {w[2]}\",\n","                            \"Candidate\": w[4],\n","                            \"Party\": w[0],\n","                            \"Votes\": w[5],\n","                            \"Year\": 2020 # You can loop years too\n","                        })\n","\n","                    # Polite delay\n","                    time.sleep(0.2)\n","\n","            except Exception as e:\n","                print(f\"  Error on {dist_code} - {type_name}: {e}\")\n","\n","    # 3. SAVE\n","    if master_data:\n","        df = pd.DataFrame(master_data)\n","        print(\"\\n--- SUCCESS! Sample Data ---\")\n","        print(df.head())\n","        df.to_csv(\"Final_Kerala_Election_Data.csv\", index=False)\n","        print(f\"Saved {len(df)} rows to Final_Kerala_Election_Data.csv\")\n","    else:\n","        print(\"Scraping finished but no data found. Check Dist Code or JSON keys.\")\n","\n","if __name__ == \"__main__\":\n","    scrape_kerala_election()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1634,"status":"ok","timestamp":1766298729038,"user":{"displayName":"FARHAN JAFFAR","userId":"00674461129948116447"},"user_tz":-330},"id":"ybUHDFO-m006","outputId":"0b4edfb0-88c2-4275-eb13-e17a71a7a6f6"},"outputs":[{"name":"stdout","output_type":"stream","text":["--- Starting Scraper (Target: Malappuram / D10001) ---\n","Cookies initialized.\n","Fetching list for District Code: D10001...\n","-> Found 5 Local Bodies.\n","Scraping finished but no data found.\n"]}],"source":["import requests\n","import pandas as pd\n","import time\n","import urllib3\n","import json\n","\n","# 1. SETUP\n","urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n","\n","URL_HOME = \"https://lbtrend.kerala.gov.in/\"\n","URL_LIST = \"https://lbtrend.kerala.gov.in/includes/stateView2_ajax.php\"\n","URL_DETAILS = \"https://lbtrend.kerala.gov.in/includes/lb_ajax2.php\"\n","\n","HEADERS = {\n","    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36\",\n","    \"X-Requested-With\": \"XMLHttpRequest\",\n","    \"Referer\": \"https://lbtrend.kerala.gov.in/\"\n","}\n","\n","def scrape_malappuram_final():\n","    print(\"--- Starting Scraper (Target: Malappuram / D10001) ---\")\n","    master_data = []\n","\n","    # 2. START SESSION (Crucial for PHP Sites)\n","    session = requests.Session()\n","    session.headers.update(HEADERS)\n","\n","    try:\n","        # Visit homepage first to get the Session Cookie\n","        session.get(URL_HOME, verify=False)\n","        print(\"Cookies initialized.\")\n","    except Exception as e:\n","        print(f\"Warning: Could not fetch homepage ({e}). Proceeding anyway...\")\n","\n","    # 3. STEP 1: GET LIST (Using D10001 from your screenshot)\n","    payload_list = {\n","        \"_p\": \"dv\",\n","        \"_l\": \"P\",        # Grama Panchayat\n","        \"_d\": \"D10001\",   # <--- HARDCODED FROM YOUR SCREENSHOT\n","        \"_s\": \"L\"\n","    }\n","\n","    try:\n","        print(f\"Fetching list for District Code: {payload_list['_d']}...\")\n","        resp = session.post(URL_LIST, data=payload_list, verify=False)\n","\n","        # DEBUG: If this fails, we print the raw text\n","        if resp.status_code != 200:\n","            print(f\"Server Error: Status {resp.status_code}\")\n","            return\n","\n","        try:\n","            data_list = resp.json()\n","        except json.JSONDecodeError:\n","            print(\"CRITICAL ERROR: Server did not return JSON.\")\n","            print(f\"Raw Response: {resp.text[:500]}\") # Show first 500 chars\n","            return\n","\n","        # Find the list inside the JSON\n","        # It usually hides in 'summary' or 'mdata'\n","        local_bodies = data_list.get(\"summary\", [])\n","        if not local_bodies:\n","            local_bodies = data_list.get(\"mdata\", [])\n","\n","        print(f\"-> Found {len(local_bodies)} Local Bodies.\")\n","\n","        # 4. STEP 2: LOOP DETAILS\n","        # Scrape first 10 for testing\n","        for item in local_bodies[:10]:\n","            lb_id = item[0]    # e.g., G10072\n","            lb_name = item[1]  # e.g., Abdurehman Nagar\n","\n","            # Payload for 'lb_ajax2.php' (From your screenshot)\n","            payload_details = {\n","                \"_p\": \"wv\",       # Ward View\n","                \"_w\": lb_id,      # The ID (G10072)\n","                \"_t\": \"P\",        # Type\n","                \"_s\": \"L\"\n","            }\n","\n","            # Request\n","            resp_det = session.post(URL_DETAILS, data=payload_details, verify=False)\n","\n","            try:\n","                data_det = resp_det.json()\n","\n","                # Extract Wards (Handling variations in structure)\n","                wards = []\n","                # Check 'mdata' -> 'wards'\n","                if \"mdata\" in data_det and isinstance(data_det[\"mdata\"], dict):\n","                    wards = data_det[\"mdata\"].get(\"wards\", [])\n","                # Check 'mdata' directly if it's a list\n","                elif \"mdata\" in data_det and isinstance(data_det[\"mdata\"], list):\n","                    wards = data_det[\"mdata\"]\n","                # Check root 'wards'\n","                elif \"wards\" in data_det:\n","                    wards = data_det[\"wards\"]\n","\n","                # Add to Master Data\n","                for w in wards:\n","                    # Column Mapping based on your table\n","                    master_data.append({\n","                        \"District\": \"Malappuram\",\n","                        \"Local Body\": lb_name,\n","                        \"Type\": \"Grama Panchayat\",\n","                        \"Ward\": f\"{w[1]} - {w[2]}\", # Ward No + Name\n","                        \"Candidate\": w[4],\n","                        \"Party\": w[0],\n","                        \"Votes\": w[5],\n","                        \"Year\": 2025\n","                    })\n","\n","            except Exception as e:\n","                print(f\"Error parsing {lb_name}: {e}\")\n","\n","            time.sleep(0.1) # Be polite\n","\n","    except Exception as e:\n","        print(f\"Global Error: {e}\")\n","\n","    # 5. SAVE\n","    if master_data:\n","        df = pd.DataFrame(master_data)\n","        print(\"\\n--- SUCCESS! Sample Data ---\")\n","        print(df.head())\n","        df.to_csv(\"Malappuram_Result_Fixed.csv\", index=False)\n","        print(f\"Saved {len(df)} rows to CSV.\")\n","    else:\n","        print(\"Scraping finished but no data found.\")\n","\n","if __name__ == \"__main__\":\n","    scrape_malappuram_final()"]},{"cell_type":"markdown","source":["INSPECTING JSON STRUCTURE"],"metadata":{"id":"WIyTIJXh6ULX"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":605,"status":"ok","timestamp":1766298851219,"user":{"displayName":"FARHAN JAFFAR","userId":"00674461129948116447"},"user_tz":-330},"id":"_Tr-AbHmnYbi","outputId":"6933502a-9fc6-4ee0-a8e0-8eb0a721cb2c"},"outputs":[{"name":"stdout","output_type":"stream","text":["--- INSPECTING JSON STRUCTURE ---\n","Fetching List for D10001...\n","\n","[ROOT KEYS]: ['mdata', 'total', 'summary', 'payload']\n","[mdata KEYS]: ['rls', 'info', 'ut']\n","\n","[summary] Length: 5 (Expected ~5 rows for party stats)\n"]}],"source":["import requests\n","import urllib3\n","import json\n","\n","urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n","\n","# CONFIG\n","URL_LIST = \"https://lbtrend.kerala.gov.in/includes/stateView2_ajax.php\"\n","HEADERS = {\n","    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36\",\n","    \"X-Requested-With\": \"XMLHttpRequest\",\n","    \"Referer\": \"https://lbtrend.kerala.gov.in/\"\n","}\n","\n","def inspect_structure():\n","    print(\"--- INSPECTING JSON STRUCTURE ---\")\n","    session = requests.Session()\n","    session.headers.update(HEADERS)\n","\n","    # 1. FETCH THE LIST (District 10 - Malappuram)\n","    payload_list = {\n","        \"_p\": \"dv\",\n","        \"_l\": \"P\",\n","        \"_d\": \"D10001\",\n","        \"_s\": \"L\"\n","    }\n","\n","    try:\n","        print(\"Fetching List for D10001...\")\n","        resp = session.post(URL_LIST, data=payload_list, verify=False)\n","        data = resp.json()\n","\n","        print(f\"\\n[ROOT KEYS]: {list(data.keys())}\")\n","\n","        # Check 'mdata' contents if it exists\n","        if \"mdata\" in data:\n","            mdata = data[\"mdata\"]\n","            if isinstance(mdata, dict):\n","                print(f\"[mdata KEYS]: {list(mdata.keys())}\")\n","\n","                # Check likely candidates for the big list\n","                for k in mdata.keys():\n","                    val = mdata[k]\n","                    if isinstance(val, list):\n","                        print(f\"  -> Key '{k}' contains a LIST of length {len(val)}\")\n","                        if len(val) > 0:\n","                            print(f\"     Sample Item: {str(val[0])[:100]}...\")\n","            elif isinstance(mdata, list):\n","                print(f\"[mdata IS A LIST] Length: {len(mdata)}\")\n","                if len(mdata) > 0:\n","                    print(f\"  Sample Item: {str(mdata[0])[:100]}...\")\n","\n","        # Check 'summary' just to confirm it's the wrong one\n","        if \"summary\" in data:\n","            print(f\"\\n[summary] Length: {len(data['summary'])} (Expected ~5 rows for party stats)\")\n","\n","    except Exception as e:\n","        print(f\"Error: {e}\")\n","\n","if __name__ == \"__main__\":\n","    inspect_structure()"]},{"cell_type":"markdown","source":["Auto-Detecting Correct Parameters"],"metadata":{"id":"lNws8-mX6avU"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3582,"status":"ok","timestamp":1766299591239,"user":{"displayName":"FARHAN JAFFAR","userId":"00674461129948116447"},"user_tz":-330},"id":"bbuHoBf2nrpJ","outputId":"3e6048e3-2eb9-4467-868f-f840ff7734b2"},"outputs":[{"name":"stdout","output_type":"stream","text":["--- 1. Auto-Detecting Correct Parameters ---\n","Trying _s='M' -> Found 82 items.\n","--> MATCH! 'M' is the correct key.\n","\n","--- 2. Scraping Details using _s='M' ---\n","Fetching: Abdurehman Nagar (G10072)\n","Fetching: Alamkode (G10096)\n","Fetching: Aliparamba (G10043)\n","Fetching: Amarambalam (G10026)\n","Fetching: Anakayam (G10037)\n","No detail data found.\n"]}],"source":["import requests\n","import pandas as pd\n","import time\n","import urllib3\n","import json\n","\n","# 1. SETUP\n","urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n","\n","URL_HOME = \"https://lbtrend.kerala.gov.in/\"\n","URL_LIST = \"https://lbtrend.kerala.gov.in/includes/stateView2_ajax.php\"\n","URL_DETAILS = \"https://lbtrend.kerala.gov.in/includes/lb_ajax2.php\"\n","\n","HEADERS = {\n","    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36\",\n","    \"X-Requested-With\": \"XMLHttpRequest\",\n","    \"Referer\": \"https://lbtrend.kerala.gov.in/\"\n","}\n","\n","def scrape_with_key_search():\n","    print(\"--- 1. Auto-Detecting Correct Parameters ---\")\n","    session = requests.Session()\n","    session.headers.update(HEADERS)\n","\n","    # Get Session Cookie\n","    try:\n","        session.get(URL_HOME, verify=False)\n","    except:\n","        pass\n","\n","    # We need to find the '_s' value that gives us a list of 90+ panchayats\n","    # 'L' gave us 5 rows (Summary). Let's try others.\n","    # Common guesses: M=Majority List, S=Status List, O=Other, D=Details\n","    candidate_keys = [\"M\", \"S\", \"W\", \"O\", \"D\", \"T\", \"L\"]\n","\n","    correct_s_key = None\n","    local_bodies_found = []\n","\n","    for s_val in candidate_keys:\n","        payload_test = {\n","            \"_p\": \"dv\",\n","            \"_l\": \"P\",\n","            \"_d\": \"D10001\",  # Malappuram\n","            \"_s\": s_val      # Testing this!\n","        }\n","\n","        try:\n","            resp = session.post(URL_LIST, data=payload_test, verify=False)\n","            data = resp.json()\n","\n","            # The list might be in different places depending on the view\n","            # We look for ANY list longer than 10 items\n","            current_list = []\n","\n","            # Check root keys for a list\n","            for key, val in data.items():\n","                if isinstance(val, list) and len(val) > 10:\n","                    current_list = val\n","                    break\n","\n","            # Check inside 'mdata'\n","            if not current_list and \"mdata\" in data and isinstance(data[\"mdata\"], dict):\n","                for key, val in data[\"mdata\"].items():\n","                    if isinstance(val, list) and len(val) > 10:\n","                        current_list = val\n","                        break\n","\n","            # Check inside 'summary'\n","            if not current_list and \"summary\" in data and len(data[\"summary\"]) > 10:\n","                current_list = data[\"summary\"]\n","\n","            print(f\"Trying _s='{s_val}' -> Found {len(current_list) if current_list else 0} items.\")\n","\n","            if len(current_list) > 10:\n","                print(f\"--> MATCH! '{s_val}' is the correct key.\")\n","                correct_s_key = s_val\n","                local_bodies_found = current_list\n","                break\n","\n","        except Exception as e:\n","            pass\n","\n","    if not correct_s_key:\n","        print(\"\\n[ERROR] Could not find the correct parameter. The server might require a specific sequence.\")\n","        return\n","\n","    # --- 2. SCRAPING DETAILS ---\n","    print(f\"\\n--- 2. Scraping Details using _s='{correct_s_key}' ---\")\n","    master_data = []\n","\n","    # Scrape first 5 bodies for testing\n","    for item in local_bodies_found[:5]:\n","        # Item format is likely: [\"G10072\", \"Abdurehman Nagar\", ...] or similar\n","        # We need to be careful with indices.\n","        # Usually ID is index 0 or 1.\n","\n","        # Let's verify if item[0] looks like an ID (starts with G)\n","        lb_id = item[0]\n","        lb_name = item[1]\n","\n","        # If ID doesn't start with G, check other columns (sometimes order changes)\n","        if not str(lb_id).startswith(\"G\"):\n","            # Fallback search for ID\n","            for col in item:\n","                if str(col).startswith(\"G1\"):\n","                    lb_id = col\n","                    break\n","\n","        print(f\"Fetching: {lb_name} ({lb_id})\")\n","\n","        # Payload for Details\n","        payload_det = {\n","            \"_p\": \"wv\",\n","            \"_w\": lb_id,\n","            \"_t\": \"P\",\n","            \"_s\": \"L\"  # This seems constant for details based on your screenshot\n","        }\n","\n","        try:\n","            resp_det = session.post(URL_DETAILS, data=payload_det, verify=False)\n","            det_json = resp_det.json()\n","\n","            # Extract Wards\n","            wards = []\n","            if \"mdata\" in det_json and isinstance(det_json[\"mdata\"], dict):\n","                # Try common keys inside mdata\n","                for k in [\"wards\", \"data\", \"rows\"]:\n","                    if k in det_json[\"mdata\"]:\n","                        wards = det_json[\"mdata\"][k]\n","                        break\n","            elif \"wards\" in det_json:\n","                wards = det_json[\"wards\"]\n","\n","            for w in wards:\n","                master_data.append({\n","                    \"District\": \"Malappuram\",\n","                    \"Local Body\": lb_name,\n","                    \"Ward\": f\"{w[1]} - {w[2]}\",\n","                    \"Candidate\": w[4],\n","                    \"Party\": w[0],\n","                    \"Votes\": w[5],\n","                    \"Year\": 2020\n","                })\n","\n","        except Exception as e:\n","            print(f\"Error on {lb_name}: {e}\")\n","\n","        time.sleep(0.1)\n","\n","    # --- 3. SAVE ---\n","    if master_data:\n","        df = pd.DataFrame(master_data)\n","        print(\"\\nSUCCESS!\")\n","        print(df.head())\n","        df.to_csv(\"Final_Kerala_Data.csv\", index=False)\n","    else:\n","        print(\"No detail data found.\")\n","\n","if __name__ == \"__main__\":\n","    scrape_with_key_search()"]},{"cell_type":"markdown","source":["INSPECTING WARD DETAILS JSON"],"metadata":{"id":"jqkX9QIz6ezR"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":620,"status":"ok","timestamp":1766299000076,"user":{"displayName":"FARHAN JAFFAR","userId":"00674461129948116447"},"user_tz":-330},"id":"p-edL8jun8t1","outputId":"52b78dfc-d560-4b87-a022-698e522f46a1"},"outputs":[{"name":"stdout","output_type":"stream","text":["--- INSPECTING WARD DETAILS JSON ---\n","Fetching details for G10072...\n","\n","[ROOT KEYS]: ['mdata', 'payload', 'summary']\n","[mdata KEYS]: ['rls', 'info', 'ut']\n"]}],"source":["import requests\n","import urllib3\n","import json\n","\n","urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n","\n","# URLs\n","URL_DETAILS = \"https://lbtrend.kerala.gov.in/includes/lb_ajax2.php\"\n","HEADERS = {\n","    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36\",\n","    \"X-Requested-With\": \"XMLHttpRequest\",\n","    \"Referer\": \"https://lbtrend.kerala.gov.in/\"\n","}\n","\n","def inspect_details_structure():\n","    print(\"--- INSPECTING WARD DETAILS JSON ---\")\n","    session = requests.Session()\n","    session.headers.update(HEADERS)\n","\n","    # We use the ID for 'Abdurehman Nagar' which we found earlier: G10072\n","    payload = {\n","        \"_p\": \"wv\",\n","        \"_w\": \"G10072\",\n","        \"_t\": \"P\",\n","        \"_s\": \"L\"\n","    }\n","\n","    try:\n","        print(\"Fetching details for G10072...\")\n","        resp = session.post(URL_DETAILS, data=payload, verify=False)\n","        data = resp.json()\n","\n","        # 1. Print Root Keys\n","        print(f\"\\n[ROOT KEYS]: {list(data.keys())}\")\n","\n","        # 2. Inspect 'mdata'\n","        if \"mdata\" in data:\n","            mdata = data[\"mdata\"]\n","            if isinstance(mdata, dict):\n","                print(f\"[mdata KEYS]: {list(mdata.keys())}\")\n","\n","                # Check for lists inside mdata\n","                for k, v in mdata.items():\n","                    if isinstance(v, list):\n","                        print(f\"  -> Found LIST in key '{k}' (Length: {len(v)})\")\n","                        if len(v) > 0:\n","                            print(f\"     Sample Row: {v[0]}\")\n","\n","            elif isinstance(mdata, list):\n","                print(f\"  -> 'mdata' IS the list! (Length: {len(mdata)})\")\n","                if len(mdata) > 0:\n","                    print(f\"     Sample Row: {mdata[0]}\")\n","\n","    except Exception as e:\n","        print(f\"Error: {e}\")\n","        # If JSON fails, print raw text\n","        print(\"Raw Response:\", resp.text[:200])\n","\n","if __name__ == \"__main__\":\n","    inspect_details_structure()"]},{"cell_type":"markdown","source":["Starting Final Scraper ( failed )"],"metadata":{"id":"QvzmoO0U6plD"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1871,"status":"ok","timestamp":1766299252816,"user":{"displayName":"FARHAN JAFFAR","userId":"00674461129948116447"},"user_tz":-330},"id":"-_xC-b-7oTmI","outputId":"fe255c6a-7707-4932-f12b-b493c6486c31"},"outputs":[{"name":"stdout","output_type":"stream","text":["--- Starting Final Scraper ---\n","1. Initializing Session (Visiting Homepage)...\n","2. Fetching Panchayat List for Malappuram (D10001)...\n","   [ERROR] List is empty. Server response keys: dict_keys(['mdata', 'total', 'summary', 'payload'])\n","   Summary length: 5\n"]}],"source":["import requests\n","import pandas as pd\n","import time\n","import urllib3\n","import json\n","\n","# 1. SETUP\n","urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n","\n","URL_HOME = \"https://lbtrend.kerala.gov.in/\"\n","URL_LIST = \"https://lbtrend.kerala.gov.in/includes/stateView2_ajax.php\"\n","URL_DETAILS = \"https://lbtrend.kerala.gov.in/includes/lb_ajax2.php\"\n","\n","HEADERS = {\n","    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36\",\n","    \"X-Requested-With\": \"XMLHttpRequest\",\n","    \"Referer\": \"https://lbtrend.kerala.gov.in/\"\n","}\n","\n","def scrape_kerala_final():\n","    print(\"--- Starting Final Scraper ---\")\n","    master_data = []\n","\n","    session = requests.Session()\n","    session.headers.update(HEADERS)\n","\n","    # 1. CRITICAL: GET SESSION COOKIE\n","    try:\n","        print(\"1. Initializing Session (Visiting Homepage)...\")\n","        session.get(URL_HOME, verify=False)\n","    except Exception as e:\n","        print(f\"   Warning: Homepage visit failed ({e}). trying anyway...\")\n","\n","    # MALAPPURAM CONFIG (Hardcoded based on your success)\n","    DISTRICT_CODE = \"D10001\"\n","    DISTRICT_NAME = \"Malappuram\"\n","\n","    # --- STEP 1: GET LIST OF PANCHAYATS ---\n","    print(f\"2. Fetching Panchayat List for {DISTRICT_NAME} ({DISTRICT_CODE})...\")\n","\n","    payload_list = {\n","        \"_p\": \"dv\",\n","        \"_l\": \"P\",\n","        \"_d\": DISTRICT_CODE,\n","        \"_s\": \"M\"         # \"M\" = Majority List (Verified)\n","    }\n","\n","    try:\n","        resp = session.post(URL_LIST, data=payload_list, verify=False)\n","        data_list = resp.json()\n","\n","        # AGGRESSIVE LIST FINDER\n","        # We look for ANY list with > 10 items in 'summary', 'mdata', or root\n","        local_bodies = []\n","\n","        # Check 'summary' (Most likely location for _s='M')\n","        if \"summary\" in data_list and isinstance(data_list[\"summary\"], list) and len(data_list[\"summary\"]) > 10:\n","            local_bodies = data_list[\"summary\"]\n","\n","        # Fallback: Check 'mdata'\n","        elif \"mdata\" in data_list:\n","            if isinstance(data_list[\"mdata\"], list) and len(data_list[\"mdata\"]) > 10:\n","                local_bodies = data_list[\"mdata\"]\n","            elif isinstance(data_list[\"mdata\"], dict):\n","                for k, v in data_list[\"mdata\"].items():\n","                    if isinstance(v, list) and len(v) > 10:\n","                        local_bodies = v\n","                        break\n","\n","        if not local_bodies:\n","            print(\"   [ERROR] List is empty. Server response keys:\", data_list.keys())\n","            if \"summary\" in data_list: print(\"   Summary length:\", len(data_list[\"summary\"]))\n","            return\n","\n","        print(f\"   -> Found {len(local_bodies)} Local Bodies.\")\n","\n","        # --- STEP 2: LOOP THROUGH EACH LOCAL BODY ---\n","        print(\"3. Scraping Ward Details...\")\n","\n","        # Remove [:5] to scrape ALL 90+ bodies. Keeping it for test speed.\n","        # Change to `for item in local_bodies:` for full run.\n","        for item in local_bodies:\n","            # Item format check\n","            lb_id = item[0]\n","            lb_name = item[1]\n","\n","            # Robust ID extraction\n","            if not str(lb_id).startswith(\"G\"):\n","                for col in item:\n","                    if str(col).startswith(\"G1\"):\n","                        lb_id = col\n","                        break\n","\n","            print(f\"   -> Processing: {lb_name} ({lb_id})\")\n","\n","            # Payload for Details (Verified keys)\n","            payload_details = {\n","                \"_p\": \"wv\",\n","                \"_w\": lb_id,\n","                \"_t\": \"P\",\n","                \"_s\": \"L\"\n","            }\n","\n","            try:\n","                resp_det = session.post(URL_DETAILS, data=payload_details, verify=False)\n","                det_json = resp_det.json()\n","\n","                # EXTRACT WARDS\n","                # Verified: Data is in 'summary' for this view\n","                wards = []\n","                if \"summary\" in det_json:\n","                    wards = det_json[\"summary\"]\n","                elif \"mdata\" in det_json:\n","                    # Fallback check\n","                    if isinstance(det_json[\"mdata\"], list): wards = det_json[\"mdata\"]\n","                    elif isinstance(det_json[\"mdata\"], dict) and \"wards\" in det_json[\"mdata\"]:\n","                        wards = det_json[\"mdata\"][\"wards\"]\n","\n","                if not wards:\n","                    print(f\"      [Warning] No wards found for {lb_name}\")\n","\n","                # Add to Master Data\n","                for w in wards:\n","                    master_data.append({\n","                        \"District\": DISTRICT_NAME,\n","                        \"Local Body\": lb_name,\n","                        \"Type\": \"Grama Panchayat\",\n","                        \"WardName\": f\"{w[1]} - {w[2]}\",\n","                        \"Candidate\": w[4],\n","                        \"Party\": w[0],\n","                        \"Front\": w[0],\n","                        \"Votes\": w[5],\n","                        \"Year\": 2020\n","                    })\n","\n","            except Exception as e:\n","                print(f\"      Error: {e}\")\n","\n","            time.sleep(0.1)\n","\n","    except Exception as e:\n","        print(f\"Global Error: {e}\")\n","\n","    # --- 3. SAVE TO CSV ---\n","    if master_data:\n","        df = pd.DataFrame(master_data)\n","        print(\"\\n--- SCRAPING COMPLETE ---\")\n","        print(df.head())\n","        filename = \"Malappuram_Master_Dataset.csv\"\n","        df.to_csv(filename, index=False)\n","        print(f\"Saved {len(df)} rows to {filename}\")\n","    else:\n","        print(\"No data collected.\")\n","\n","if __name__ == \"__main__\":\n","    scrape_kerala_final()"]},{"cell_type":"markdown","source":["Starting Final Scraper (Target: Malappuram 2020) Again failed"],"metadata":{"id":"ZIkZF_Xo6vEa"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1681,"status":"ok","timestamp":1766299334660,"user":{"displayName":"FARHAN JAFFAR","userId":"00674461129948116447"},"user_tz":-330},"id":"9RDXX62ZpODy","outputId":"88bead31-0cd1-4255-ab4e-979f672f8408"},"outputs":[{"name":"stdout","output_type":"stream","text":["--- Starting Final Scraper (Target: Malappuram 2020) ---\n","1. Session initialized.\n","2. Fetching Panchayat List...\n","   [ERROR] List is empty.\n","   Server returned keys: dict_keys(['mdata', 'total', 'summary', 'payload'])\n","   mdata keys: dict_keys(['rls', 'info', 'ut'])\n"]}],"source":["import requests\n","import pandas as pd\n","import time\n","import urllib3\n","import json\n","\n","# 1. SETUP\n","urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n","\n","URL_HOME = \"https://lbtrend.kerala.gov.in/\"\n","URL_LIST = \"https://lbtrend.kerala.gov.in/includes/stateView2_ajax.php\"\n","URL_DETAILS = \"https://lbtrend.kerala.gov.in/includes/lb_ajax2.php\"\n","\n","HEADERS = {\n","    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36\",\n","    \"X-Requested-With\": \"XMLHttpRequest\",\n","    \"Referer\": \"https://lbtrend.kerala.gov.in/\"\n","}\n","\n","def scrape_kerala_final():\n","    print(\"--- Starting Final Scraper (Target: Malappuram 2020) ---\")\n","    master_data = []\n","\n","    session = requests.Session()\n","    session.headers.update(HEADERS)\n","\n","    # 1. VISITING HOMEPAGE (Gets the Session Cookie)\n","    try:\n","        session.get(URL_HOME, verify=False)\n","        print(\"1. Session initialized.\")\n","    except Exception as e:\n","        print(f\"   Warning: Session init failed ({e})\")\n","\n","    # CONFIGURATION\n","    DISTRICT_CODE = \"D10001\"\n","    DISTRICT_NAME = \"Malappuram\"\n","    TARGET_YEAR = 2020\n","\n","    # --- STEP 1: GET LIST OF PANCHAYATS ---\n","    print(f\"2. Fetching Panchayat List...\")\n","\n","    payload_list = {\n","        \"_p\": \"dv\",\n","        \"_l\": \"P\",\n","        \"_d\": DISTRICT_CODE,\n","        \"_s\": \"M\",        # Majority View (List of Bodies)\n","        \"_y\": TARGET_YEAR # <--- ADDED YEAR (Crucial fix)\n","    }\n","\n","    try:\n","        resp = session.post(URL_LIST, data=payload_list, verify=False)\n","        data_list = resp.json()\n","\n","        # AGGRESSIVE LIST FINDER\n","        local_bodies = []\n","\n","        # Check 'mdata' for the list (Common for Majority View)\n","        if \"mdata\" in data_list:\n","            # If mdata IS the list\n","            if isinstance(data_list[\"mdata\"], list) and len(data_list[\"mdata\"]) > 10:\n","                local_bodies = data_list[\"mdata\"]\n","            # If mdata is a dict containing the list (e.g., in 'rows' or 'data')\n","            elif isinstance(data_list[\"mdata\"], dict):\n","                for k, v in data_list[\"mdata\"].items():\n","                    if isinstance(v, list) and len(v) > 10:\n","                        local_bodies = v\n","                        break\n","\n","        # Fallback to 'summary'\n","        if not local_bodies and \"summary\" in data_list and len(data_list[\"summary\"]) > 10:\n","            local_bodies = data_list[\"summary\"]\n","\n","        if not local_bodies:\n","            print(\"   [ERROR] List is empty.\")\n","            print(\"   Server returned keys:\", data_list.keys())\n","            if \"mdata\" in data_list and isinstance(data_list[\"mdata\"], dict):\n","                print(\"   mdata keys:\", data_list[\"mdata\"].keys())\n","            return\n","\n","        print(f\"   -> Found {len(local_bodies)} Local Bodies.\")\n","\n","        # --- STEP 2: LOOP THROUGH EACH LOCAL BODY ---\n","        print(\"3. Scraping Ward Details...\")\n","\n","        for item in local_bodies:\n","            # ROBUST ID EXTRACTION\n","            # Sometimes ID is at index 0, sometimes 1. We find the \"G...\" code.\n","            lb_id = None\n","            lb_name = \"Unknown\"\n","\n","            for col in item:\n","                s_col = str(col)\n","                if s_col.startswith(\"G1\"): # G1xxxxx is the ID format\n","                    lb_id = s_col\n","                elif len(s_col) > 4 and not s_col.startswith(\"G\") and not s_col.isdigit():\n","                    lb_name = s_col # Heuristic for Name\n","\n","            # Fallback if heuristics fail (use fixed indices)\n","            if not lb_id: lb_id = item[0]\n","            if lb_name == \"Unknown\": lb_name = item[1]\n","\n","            print(f\"   -> Processing: {lb_name} ({lb_id})\")\n","\n","            # PAYLOAD FOR DETAILS\n","            payload_details = {\n","                \"_p\": \"wv\",\n","                \"_w\": lb_id,\n","                \"_t\": \"P\",\n","                \"_s\": \"L\",\n","                \"_y\": TARGET_YEAR # <--- ADDED YEAR\n","            }\n","\n","            try:\n","                resp_det = session.post(URL_DETAILS, data=payload_details, verify=False)\n","                det_json = resp_det.json()\n","\n","                # EXTRACT WARDS\n","                wards = []\n","                # Check summary first (Verified location for Ward List)\n","                if \"summary\" in det_json and len(det_json[\"summary\"]) > 0:\n","                    wards = det_json[\"summary\"]\n","                elif \"mdata\" in det_json:\n","                    if isinstance(det_json[\"mdata\"], list): wards = det_json[\"mdata\"]\n","                    elif isinstance(det_json[\"mdata\"], dict):\n","                         # Try to find list inside mdata dict\n","                         for k,v in det_json[\"mdata\"].items():\n","                             if isinstance(v, list): wards = v; break\n","\n","                if not wards:\n","                    print(f\"      [Warning] No wards found.\")\n","\n","                # Add to Master Data\n","                for w in wards:\n","                    # w format: [Party, WardNo, WardName, ..., Candidate, Votes]\n","                    # Adjust indices if your CSV looks wrong\n","                    master_data.append({\n","                        \"District\": DISTRICT_NAME,\n","                        \"Local Body\": lb_name,\n","                        \"Type\": \"Grama Panchayat\",\n","                        \"WardName\": f\"{w[1]} - {w[2]}\",\n","                        \"Candidate\": w[4],\n","                        \"Party\": w[0],\n","                        \"Front\": w[0],\n","                        \"Votes\": w[5],\n","                        \"Year\": TARGET_YEAR\n","                    })\n","\n","            except Exception as e:\n","                print(f\"      Error: {e}\")\n","\n","            time.sleep(0.1) # Be polite\n","\n","    except Exception as e:\n","        print(f\"Global Error: {e}\")\n","\n","    # --- 3. SAVE TO CSV ---\n","    if master_data:\n","        df = pd.DataFrame(master_data)\n","        print(\"\\n--- SCRAPING COMPLETE ---\")\n","        print(df.head())\n","        filename = f\"Malappuram_{TARGET_YEAR}_Data.csv\"\n","        df.to_csv(filename, index=False)\n","        print(f\"Saved {len(df)} rows to {filename}\")\n","    else:\n","        print(\"No data collected.\")\n","\n","if __name__ == \"__main__\":\n","    scrape_kerala_final()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1022,"status":"ok","timestamp":1766299473477,"user":{"displayName":"FARHAN JAFFAR","userId":"00674461129948116447"},"user_tz":-330},"id":"kjhD4K-tpsEq","outputId":"8db10d95-21bc-4b19-8e28-0bd3527de948"},"outputs":[{"name":"stdout","output_type":"stream","text":["--- Starting Final Scraper (Target: Malappuram) ---\n","1. Session initialized.\n","2. Fetching Panchayat List...\n","   [ERROR] List is empty.\n","   The server might have reverted to default view.\n"]}],"source":["import requests\n","import pandas as pd\n","import time\n","import urllib3\n","import json\n","\n","# 1. SETUP\n","urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n","\n","URL_HOME = \"https://lbtrend.kerala.gov.in/\"\n","URL_LIST = \"https://lbtrend.kerala.gov.in/includes/stateView2_ajax.php\"\n","URL_DETAILS = \"https://lbtrend.kerala.gov.in/includes/lb_ajax2.php\"\n","\n","HEADERS = {\n","    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36\",\n","    \"X-Requested-With\": \"XMLHttpRequest\",\n","    \"Referer\": \"https://lbtrend.kerala.gov.in/\"\n","}\n","\n","def scrape_kerala_final():\n","    print(\"--- Starting Final Scraper (Target: Malappuram) ---\")\n","    master_data = []\n","\n","    session = requests.Session()\n","    session.headers.update(HEADERS)\n","\n","    # 1. VISITING HOMEPAGE (Essential for Session Cookies)\n","    try:\n","        session.get(URL_HOME, verify=False)\n","        print(\"1. Session initialized.\")\n","    except Exception as e:\n","        print(f\"   Warning: Session init failed ({e})\")\n","\n","    # CONFIGURATION\n","    DISTRICT_CODE = \"D10001\"\n","    DISTRICT_NAME = \"Malappuram\"\n","\n","    # --- STEP 1: GET LIST OF PANCHAYATS ---\n","    print(f\"2. Fetching Panchayat List...\")\n","\n","    # REVERTED PAYLOAD: Removed '_y' because it caused the error.\n","    # Using exactly what worked in your Auto-Detect run.\n","    payload_list = {\n","        \"_p\": \"dv\",\n","        \"_l\": \"P\",\n","        \"_d\": DISTRICT_CODE,\n","        \"_s\": \"M\"  # \"M\" = Majority List (Verified to return ~82 items)\n","    }\n","\n","    try:\n","        resp = session.post(URL_LIST, data=payload_list, verify=False)\n","        data_list = resp.json()\n","\n","        local_bodies = []\n","\n","        # 1. Check 'mdata' for the list (Common for Majority View)\n","        if \"mdata\" in data_list:\n","            if isinstance(data_list[\"mdata\"], list) and len(data_list[\"mdata\"]) > 10:\n","                local_bodies = data_list[\"mdata\"]\n","            elif isinstance(data_list[\"mdata\"], dict):\n","                for k, v in data_list[\"mdata\"].items():\n","                    if isinstance(v, list) and len(v) > 10:\n","                        local_bodies = v\n","                        break\n","\n","        # 2. Check 'summary' (Fallback)\n","        if not local_bodies and \"summary\" in data_list and len(data_list[\"summary\"]) > 10:\n","            local_bodies = data_list[\"summary\"]\n","\n","        if not local_bodies:\n","            print(\"   [ERROR] List is empty.\")\n","            print(\"   The server might have reverted to default view.\")\n","            return\n","\n","        print(f\"   -> Found {len(local_bodies)} Local Bodies.\")\n","\n","        # --- STEP 2: LOOP THROUGH EACH LOCAL BODY ---\n","        print(\"3. Scraping Ward Details...\")\n","\n","        # We loop through ALL found bodies\n","        for item in local_bodies:\n","            # ROBUST ID EXTRACTION\n","            lb_id = None\n","            lb_name = \"Unknown\"\n","\n","            # Find the ID (starts with \"G1\")\n","            for col in item:\n","                s_col = str(col)\n","                if s_col.startswith(\"G1\"):\n","                    lb_id = s_col\n","                elif len(s_col) > 3 and not s_col.startswith(\"G\") and not s_col.isdigit():\n","                    lb_name = s_col\n","\n","            # Fallback\n","            if not lb_id: lb_id = item[0]\n","            if lb_name == \"Unknown\": lb_name = item[1]\n","\n","            print(f\"   -> Processing: {lb_name} ({lb_id})\")\n","\n","            # PAYLOAD FOR DETAILS\n","            # Verified in your Inspector run\n","            payload_details = {\n","                \"_p\": \"wv\",\n","                \"_w\": lb_id,\n","                \"_t\": \"P\",\n","                \"_s\": \"L\"\n","            }\n","\n","            try:\n","                resp_det = session.post(URL_DETAILS, data=payload_details, verify=False)\n","                det_json = resp_det.json()\n","\n","                # EXTRACT WARDS\n","                wards = []\n","\n","                # Verified: Data is often in 'summary' for this view\n","                if \"summary\" in det_json and len(det_json[\"summary\"]) > 0:\n","                    wards = det_json[\"summary\"]\n","                elif \"mdata\" in det_json:\n","                    if isinstance(det_json[\"mdata\"], list): wards = det_json[\"mdata\"]\n","                    elif isinstance(det_json[\"mdata\"], dict):\n","                         for k,v in det_json[\"mdata\"].items():\n","                             if isinstance(v, list): wards = v; break\n","\n","                if not wards:\n","                    print(f\"      [Warning] No wards found.\")\n","\n","                # Add to Master Data\n","                for w in wards:\n","                    # w format usually: [Party, WardNo, WardName, ..., Candidate, Votes]\n","                    # Adjust indices based on your specific CSV output if needed\n","                    master_data.append({\n","                        \"District\": DISTRICT_NAME,\n","                        \"Local Body\": lb_name,\n","                        \"Type\": \"Grama Panchayat\",\n","                        \"WardName\": f\"{w[1]} - {w[2]}\",\n","                        \"Candidate\": w[4],\n","                        \"Party\": w[0],\n","                        \"Front\": w[0],\n","                        \"Votes\": w[5],\n","                        \"Year\": 2020\n","                    })\n","\n","            except Exception as e:\n","                print(f\"      Error: {e}\")\n","\n","            time.sleep(0.1) # Be polite\n","\n","    except Exception as e:\n","        print(f\"Global Error: {e}\")\n","\n","    # --- 3. SAVE TO CSV ---\n","    if master_data:\n","        df = pd.DataFrame(master_data)\n","        print(\"\\n--- SCRAPING COMPLETE ---\")\n","        print(df.head())\n","        filename = \"Malappuram_Master_Dataset.csv\"\n","        df.to_csv(filename, index=False)\n","        print(f\"Saved {len(df)} rows to {filename}\")\n","    else:\n","        print(\"No data collected.\")\n","\n","if __name__ == \"__main__\":\n","    scrape_kerala_final()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2434,"status":"ok","timestamp":1766299557316,"user":{"displayName":"FARHAN JAFFAR","userId":"00674461129948116447"},"user_tz":-330},"id":"0vwOoweUqEdP","outputId":"82dd0992-39e2-44a3-dbf7-624edcfa8981"},"outputs":[{"name":"stdout","output_type":"stream","text":["--- Starting Robust Scraper (Hunter-Seeker Mode) ---\n","1. Session initialized.\n","2. Hunting for Panchayat List (Dist: D10001)...\n","   -> Key 'M' failed (returned 5 items).\n","   -> Key 'S' error: Expecting value: line 8 column 1 (char 7)\n","   -> Key 'L' failed (returned 5 items).\n","   -> Key 'W' error: Expecting value: line 8 column 1 (char 7)\n","   -> Key 'O' error: Expecting value: line 8 column 1 (char 7)\n","[CRITICAL FAILURE] Could not find the Panchayat list with any key.\n"]}],"source":["import requests\n","import pandas as pd\n","import time\n","import urllib3\n","import json\n","\n","# 1. SETUP\n","urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n","\n","URL_HOME = \"https://lbtrend.kerala.gov.in/\"\n","URL_LIST = \"https://lbtrend.kerala.gov.in/includes/stateView2_ajax.php\"\n","URL_DETAILS = \"https://lbtrend.kerala.gov.in/includes/lb_ajax2.php\"\n","\n","HEADERS = {\n","    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36\",\n","    \"X-Requested-With\": \"XMLHttpRequest\",\n","    \"Referer\": \"https://lbtrend.kerala.gov.in/\"\n","}\n","\n","def scrape_kerala_robust():\n","    print(\"--- Starting Robust Scraper (Hunter-Seeker Mode) ---\")\n","    master_data = []\n","\n","    session = requests.Session()\n","    session.headers.update(HEADERS)\n","\n","    # 1. INIT SESSION\n","    try:\n","        session.get(URL_HOME, verify=False)\n","        print(\"1. Session initialized.\")\n","    except:\n","        pass\n","\n","    # CONFIG\n","    DISTRICT_CODE = \"D10001\" # Malappuram\n","\n","    # --- STEP 1: HUNT FOR THE LIST ---\n","    print(f\"2. Hunting for Panchayat List (Dist: {DISTRICT_CODE})...\")\n","\n","    # We try these keys in order. 'M' worked once, so it's first.\n","    # 'S' (Status) and 'L' (List) are fallbacks.\n","    candidate_keys = [\"M\", \"S\", \"L\", \"W\", \"O\"]\n","    local_bodies = []\n","    found_key = None\n","\n","    for key in candidate_keys:\n","        payload_list = {\n","            \"_p\": \"dv\",\n","            \"_l\": \"P\",\n","            \"_d\": DISTRICT_CODE,\n","            \"_s\": key\n","        }\n","\n","        try:\n","            resp = session.post(URL_LIST, data=payload_list, verify=False)\n","            data = resp.json()\n","\n","            # Check for ANY list > 10 items\n","            temp_list = []\n","            if \"mdata\" in data:\n","                if isinstance(data[\"mdata\"], list): temp_list = data[\"mdata\"]\n","                elif isinstance(data[\"mdata\"], dict):\n","                     for k, v in data[\"mdata\"].items():\n","                         if isinstance(v, list): temp_list = v; break\n","\n","            if not temp_list and \"summary\" in data and isinstance(data[\"summary\"], list):\n","                temp_list = data[\"summary\"]\n","\n","            # DID WE FIND IT?\n","            if len(temp_list) > 10:\n","                print(f\"   -> MATCH! Key '{key}' returned {len(temp_list)} items.\")\n","                local_bodies = temp_list\n","                found_key = key\n","                break\n","            else:\n","                print(f\"   -> Key '{key}' failed (returned {len(temp_list) if temp_list else 0} items).\")\n","\n","        except Exception as e:\n","            print(f\"   -> Key '{key}' error: {e}\")\n","\n","    if not local_bodies:\n","        print(\"[CRITICAL FAILURE] Could not find the Panchayat list with any key.\")\n","        return\n","\n","    # --- STEP 2: SCRAPE DETAILS ---\n","    print(f\"3. Scraping {len(local_bodies)} Panchayats...\")\n","\n","    for item in local_bodies:\n","        # ID Extraction Logic\n","        lb_id = None\n","        lb_name = \"Unknown\"\n","\n","        # Smart search for \"G1xxxx\" ID\n","        for col in item:\n","            s_col = str(col)\n","            if s_col.startswith(\"G1\"):\n","                lb_id = s_col\n","            elif len(s_col) > 3 and not s_col.startswith(\"G\") and not s_col.isdigit():\n","                lb_name = s_col\n","\n","        if not lb_id: lb_id = item[0] # Fallback\n","        if lb_name == \"Unknown\": lb_name = item[1]\n","\n","        print(f\"   -> Processing: {lb_name} ({lb_id})\")\n","\n","        # PAYLOAD FOR DETAILS\n","        # We assume _s=\"L\" is constant for details (as per your earlier logs)\n","        payload_details = {\n","            \"_p\": \"wv\",\n","            \"_w\": lb_id,\n","            \"_t\": \"P\",\n","            \"_s\": \"L\"\n","        }\n","\n","        try:\n","            resp_det = session.post(URL_DETAILS, data=payload_details, verify=False)\n","            det_json = resp_det.json()\n","\n","            # Extract Wards\n","            wards = []\n","            if \"summary\" in det_json and len(det_json[\"summary\"]) > 0:\n","                wards = det_json[\"summary\"]\n","            elif \"mdata\" in det_json:\n","                if isinstance(det_json[\"mdata\"], list): wards = det_json[\"mdata\"]\n","                elif isinstance(det_json[\"mdata\"], dict):\n","                     for k,v in det_json[\"mdata\"].items():\n","                         if isinstance(v, list): wards = v; break\n","\n","            # Append Data\n","            for w in wards:\n","                master_data.append({\n","                    \"District\": \"Malappuram\",\n","                    \"Local Body\": lb_name,\n","                    \"Type\": \"Grama Panchayat\",\n","                    \"WardName\": f\"{w[1]} - {w[2]}\",\n","                    \"Candidate\": w[4],\n","                    \"Party\": w[0],\n","                    \"Front\": w[0],\n","                    \"Votes\": w[5],\n","                    \"Year\": 2020\n","                })\n","\n","        except Exception as e:\n","            print(f\"      Error: {e}\")\n","\n","        time.sleep(0.1)\n","\n","    # --- 3. SAVE ---\n","    if master_data:\n","        df = pd.DataFrame(master_data)\n","        print(\"\\n--- SCRAPING SUCCESS ---\")\n","        print(df.head())\n","        df.to_csv(\"Malappuram_Robust_Dataset.csv\", index=False)\n","        print(f\"Saved {len(df)} rows.\")\n","    else:\n","        print(\"No detail data collected.\")\n","\n","if __name__ == \"__main__\":\n","    scrape_kerala_robust()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":41176,"status":"ok","timestamp":1766299781106,"user":{"displayName":"FARHAN JAFFAR","userId":"00674461129948116447"},"user_tz":-330},"id":"fof7tmBkqxdu","outputId":"7846dbbf-d9a1-4347-88aa-76887e70d120"},"outputs":[{"name":"stdout","output_type":"stream","text":["--- Starting Direct Scraper (Bypassing List) ---\n","Checking IDs G10001 to G10130...\n","   [SUCCESS] G10001: Found 2 wards.\n","   [SUCCESS] G10002: Found 2 wards.\n","   [SUCCESS] G10003: Found 2 wards.\n","   [SUCCESS] G10004: Found 2 wards.\n","   [SUCCESS] G10005: Found 2 wards.\n","   [SUCCESS] G10006: Found 2 wards.\n","   [G10007] Failed (Status 500)\n","   [SUCCESS] G10008: Found 2 wards.\n","   [SUCCESS] G10009: Found 2 wards.\n","   [SUCCESS] G10010: Found 2 wards.\n","   [SUCCESS] G10011: Found 2 wards.\n","   [SUCCESS] G10012: Found 2 wards.\n","   [G10013] Failed (Status 500)\n","   [SUCCESS] G10014: Found 2 wards.\n","   [SUCCESS] G10015: Found 2 wards.\n","   [SUCCESS] G10016: Found 2 wards.\n","   [SUCCESS] G10017: Found 2 wards.\n","   [SUCCESS] G10018: Found 2 wards.\n","   [SUCCESS] G10019: Found 2 wards.\n","   [SUCCESS] G10020: Found 2 wards.\n","   [SUCCESS] G10021: Found 2 wards.\n","   [SUCCESS] G10022: Found 2 wards.\n","   [SUCCESS] G10023: Found 2 wards.\n","   [SUCCESS] G10024: Found 2 wards.\n","   [SUCCESS] G10025: Found 2 wards.\n","   [SUCCESS] G10026: Found 2 wards.\n","   [SUCCESS] G10027: Found 2 wards.\n","   [SUCCESS] G10028: Found 2 wards.\n","   [SUCCESS] G10029: Found 2 wards.\n","   [SUCCESS] G10030: Found 2 wards.\n","   [SUCCESS] G10031: Found 2 wards.\n","   [SUCCESS] G10032: Found 2 wards.\n","   [SUCCESS] G10033: Found 2 wards.\n","   [SUCCESS] G10034: Found 2 wards.\n","   [SUCCESS] G10035: Found 2 wards.\n","   [SUCCESS] G10036: Found 2 wards.\n","   [SUCCESS] G10037: Found 2 wards.\n","   [SUCCESS] G10038: Found 2 wards.\n","   [SUCCESS] G10039: Found 2 wards.\n","   [SUCCESS] G10040: Found 2 wards.\n","   [SUCCESS] G10041: Found 2 wards.\n","   [SUCCESS] G10042: Found 2 wards.\n","   [SUCCESS] G10043: Found 2 wards.\n","   [SUCCESS] G10044: Found 2 wards.\n","   [SUCCESS] G10045: Found 2 wards.\n","   [SUCCESS] G10046: Found 2 wards.\n","   [SUCCESS] G10047: Found 2 wards.\n","   [SUCCESS] G10048: Found 2 wards.\n","   [SUCCESS] G10049: Found 2 wards.\n","   [SUCCESS] G10050: Found 2 wards.\n","   [SUCCESS] G10051: Found 2 wards.\n","   [SUCCESS] G10052: Found 2 wards.\n","   [SUCCESS] G10053: Found 2 wards.\n","   [SUCCESS] G10054: Found 2 wards.\n","   [SUCCESS] G10055: Found 2 wards.\n","   [SUCCESS] G10056: Found 2 wards.\n","   [SUCCESS] G10057: Found 2 wards.\n","   [SUCCESS] G10058: Found 2 wards.\n","   [SUCCESS] G10059: Found 2 wards.\n","   [SUCCESS] G10060: Found 2 wards.\n","   [SUCCESS] G10061: Found 2 wards.\n","   [G10062] Failed (Status 500)\n","   [SUCCESS] G10063: Found 2 wards.\n","   [G10064] Failed (Status 500)\n","   [SUCCESS] G10065: Found 2 wards.\n","   [SUCCESS] G10066: Found 2 wards.\n","   [SUCCESS] G10067: Found 2 wards.\n","   [SUCCESS] G10068: Found 2 wards.\n","   [SUCCESS] G10069: Found 2 wards.\n","   [SUCCESS] G10070: Found 2 wards.\n","   [SUCCESS] G10071: Found 2 wards.\n","   [SUCCESS] G10072: Found 2 wards.\n","   [SUCCESS] G10073: Found 2 wards.\n","   [SUCCESS] G10074: Found 2 wards.\n","   [SUCCESS] G10075: Found 2 wards.\n","   [SUCCESS] G10076: Found 2 wards.\n","   [SUCCESS] G10077: Found 2 wards.\n","   [SUCCESS] G10078: Found 2 wards.\n","   [G10079] Failed (Status 500)\n","   [SUCCESS] G10080: Found 2 wards.\n","   [SUCCESS] G10081: Found 2 wards.\n","   [SUCCESS] G10082: Found 2 wards.\n","   [G10083] Failed (Status 500)\n","   [SUCCESS] G10084: Found 2 wards.\n","   [SUCCESS] G10085: Found 2 wards.\n","   [SUCCESS] G10086: Found 2 wards.\n","   [SUCCESS] G10087: Found 2 wards.\n","   [SUCCESS] G10088: Found 2 wards.\n","   [SUCCESS] G10089: Found 2 wards.\n","   [SUCCESS] G10090: Found 2 wards.\n","   [SUCCESS] G10091: Found 2 wards.\n","   [SUCCESS] G10092: Found 2 wards.\n","   [SUCCESS] G10093: Found 2 wards.\n","   [SUCCESS] G10094: Found 2 wards.\n","   [SUCCESS] G10095: Found 2 wards.\n","   [SUCCESS] G10096: Found 2 wards.\n","   [SUCCESS] G10097: Found 2 wards.\n","   [SUCCESS] G10098: Found 2 wards.\n","   [SUCCESS] G10099: Found 2 wards.\n","   [SUCCESS] G10100: Found 2 wards.\n","   [G10101] Failed (Status 500)\n","   [G10102] Failed (Status 500)\n","   [G10103] Failed (Status 500)\n","   [G10104] Failed (Status 500)\n","   [G10105] Failed (Status 500)\n","   [G10106] Failed (Status 500)\n","   [G10107] Failed (Status 500)\n","   [G10108] Failed (Status 500)\n","   [G10109] Failed (Status 500)\n","   [G10110] Failed (Status 500)\n","   [G10111] Failed (Status 500)\n","   [G10112] Failed (Status 500)\n","   [G10113] Failed (Status 500)\n","   [G10114] Failed (Status 500)\n","   [G10115] Failed (Status 500)\n","   [G10116] Failed (Status 500)\n","   [G10117] Failed (Status 500)\n","   [G10118] Failed (Status 500)\n","   [G10119] Failed (Status 500)\n","   [G10120] Failed (Status 500)\n","   [G10121] Failed (Status 500)\n","   [G10122] Failed (Status 500)\n","   [G10123] Failed (Status 500)\n","   [G10124] Failed (Status 500)\n","   [G10125] Failed (Status 500)\n","   [G10126] Failed (Status 500)\n","   [G10127] Failed (Status 500)\n","   [G10128] Failed (Status 500)\n","   [G10129] Failed (Status 500)\n","   [G10130] Failed (Status 500)\n","No data found. Try removing '_y' from payload if 2020 fails.\n"]}],"source":["import requests\n","import pandas as pd\n","import time\n","import urllib3\n","\n","# 1. SETUP\n","urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n","\n","URL_DETAILS = \"https://lbtrend.kerala.gov.in/includes/lb_ajax2.php\"\n","\n","HEADERS = {\n","    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36\",\n","    \"X-Requested-With\": \"XMLHttpRequest\",\n","    \"Referer\": \"https://lbtrend.kerala.gov.in/\"\n","}\n","\n","def scrape_by_brute_force():\n","    print(\"--- Starting Direct Scraper (Bypassing List) ---\")\n","    master_data = []\n","\n","    session = requests.Session()\n","    session.headers.update(HEADERS)\n","\n","    # CONFIGURATION\n","    DISTRICT_NAME = \"Malappuram\"\n","    DISTRICT_PREFIX = \"G10\" # G + District Number (10 for Malappuram)\n","    TARGET_YEAR = 2020\n","\n","    # Range of IDs to check (Malappuram likely has ~100-120 panchayats)\n","    # We check 1 to 130 to be safe.\n","    print(f\"Checking IDs {DISTRICT_PREFIX}001 to {DISTRICT_PREFIX}130...\")\n","\n","    for i in range(1, 131):\n","        # Generate ID: G10001, G10002, ... G10130\n","        lb_id = f\"{DISTRICT_PREFIX}{i:03d}\"\n","\n","        # Payload (The one we know works!)\n","        payload = {\n","            \"_p\": \"wv\",\n","            \"_w\": lb_id,\n","            \"_t\": \"P\",\n","            \"_s\": \"L\",\n","            \"_y\": TARGET_YEAR # Try adding year. If it fails, remove this line.\n","        }\n","\n","        try:\n","            resp = session.post(URL_DETAILS, data=payload, verify=False)\n","\n","            # Check if valid\n","            if resp.status_code != 200:\n","                print(f\"   [{lb_id}] Failed (Status {resp.status_code})\")\n","                continue\n","\n","            data = resp.json()\n","\n","            # Find the wards list\n","            wards = []\n","            if \"summary\" in data and len(data[\"summary\"]) > 0:\n","                wards = data[\"summary\"]\n","            elif \"mdata\" in data and isinstance(data[\"mdata\"], list):\n","                wards = data[\"mdata\"]\n","            elif \"mdata\" in data and isinstance(data[\"mdata\"], dict):\n","                 for k,v in data[\"mdata\"].items():\n","                     if isinstance(v, list): wards = v; break\n","\n","            if wards:\n","                # We found a valid Panchayat!\n","                # Extract Name from the first row or log it\n","                # Usually name isn't in the ward row explicitly, but we can just use ID\n","                # Or sometimes the JSON has a 'header' key with the name.\n","\n","                # Let's verify we have data\n","                sample_ward = wards[0]\n","                # Assuming WardName is index 2, Party index 0\n","\n","                print(f\"   [SUCCESS] {lb_id}: Found {len(wards)} wards.\")\n","\n","                for w in wards:\n","                    master_data.append({\n","                        \"District\": DISTRICT_NAME,\n","                        \"LocalBodyID\": lb_id,\n","                        # \"Local Body\": \"Unknown\", # We can merge names later or find name in JSON\n","                        \"Type\": \"Grama Panchayat\",\n","                        \"WardName\": f\"{w[1]} - {w[2]}\",\n","                        \"Candidate\": w[4],\n","                        \"Party\": w[0],\n","                        \"Front\": w[0],\n","                        \"Votes\": w[5],\n","                        \"Year\": TARGET_YEAR\n","                    })\n","            else:\n","                # Valid JSON but empty (ID might not exist)\n","                # print(f\"   [{lb_id}] No data.\") # Uncomment to see misses\n","                pass\n","\n","        except Exception as e:\n","            # print(f\"   [{lb_id}] Error: {e}\")\n","            pass\n","\n","        # Very short sleep to fly through empty IDs\n","        time.sleep(0.05)\n","\n","    # SAVE\n","    if master_data:\n","        df = pd.DataFrame(master_data)\n","        print(\"\\n--- SCRAPING COMPLETE ---\")\n","        print(df.head())\n","        filename = f\"Malappuram_{TARGET_YEAR}_Direct.csv\"\n","        df.to_csv(filename, index=False)\n","        print(f\"Saved {len(df)} rows to {filename}\")\n","    else:\n","        print(\"No data found. Try removing '_y' from payload if 2020 fails.\")\n","\n","if __name__ == \"__main__\":\n","    scrape_by_brute_force()"]},{"cell_type":"markdown","source":["X-RAY DEBUGGER (G10001)"],"metadata":{"id":"1d0d7Cos7ANT"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1336,"status":"ok","timestamp":1766299867101,"user":{"displayName":"FARHAN JAFFAR","userId":"00674461129948116447"},"user_tz":-330},"id":"O3XFn9pyrQSX","outputId":"d85b4394-c76a-42e1-8110-e2f60b728e35"},"outputs":[{"name":"stdout","output_type":"stream","text":["--- X-RAY DEBUGGER (G10001) ---\n","\n","[ROOT KEYS]: ['mdata', 'payload', 'summary']\n","\n","[summary] (Length 2):\n","[\n","  [\n","    \"G10001\",\n","    15,\n","    5,\n","    0,\n","    4\n","  ],\n","  [\n","    \"G10001\",\n","    15,\n","    5,\n","    0,\n","    4\n","  ]\n","]\n","\n","[mdata] Type: <class 'dict'>\n","Keys: dict_keys(['rls', 'info', 'ut'])\n"]}],"source":["import requests\n","import urllib3\n","import json\n","\n","urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n","\n","URL_DETAILS = \"https://lbtrend.kerala.gov.in/includes/lb_ajax2.php\"\n","\n","HEADERS = {\n","    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36\",\n","    \"X-Requested-With\": \"XMLHttpRequest\",\n","    \"Referer\": \"https://lbtrend.kerala.gov.in/\"\n","}\n","\n","def xray_debug():\n","    print(\"--- X-RAY DEBUGGER (G10001) ---\")\n","    session = requests.Session()\n","    session.headers.update(HEADERS)\n","\n","    # Payload WITHOUT year (to avoid defaults)\n","    payload = {\n","        \"_p\": \"wv\",\n","        \"_w\": \"G10001\",\n","        \"_t\": \"P\",\n","        \"_s\": \"L\"\n","    }\n","\n","    try:\n","        resp = session.post(URL_DETAILS, data=payload, verify=False)\n","        data = resp.json()\n","\n","        print(\"\\n[ROOT KEYS]:\", list(data.keys()))\n","\n","        # Check 'summary'\n","        if \"summary\" in data:\n","            print(f\"\\n[summary] (Length {len(data['summary'])}):\")\n","            print(json.dumps(data[\"summary\"], indent=2, ensure_ascii=False))\n","\n","        # Check 'mdata'\n","        if \"mdata\" in data:\n","            print(f\"\\n[mdata] Type: {type(data['mdata'])}\")\n","            if isinstance(data[\"mdata\"], list):\n","                print(f\"Length: {len(data['mdata'])}\")\n","                print(json.dumps(data[\"mdata\"][:2], indent=2, ensure_ascii=False)) # Print first 2 items\n","            elif isinstance(data[\"mdata\"], dict):\n","                print(\"Keys:\", data[\"mdata\"].keys())\n","                if \"wards\" in data[\"mdata\"]:\n","                     print(f\"Wards found in mdata['wards']! Length: {len(data['mdata']['wards'])}\")\n","                     print(json.dumps(data[\"mdata\"][\"wards\"][:2], indent=2, ensure_ascii=False))\n","\n","    except Exception as e:\n","        print(f\"Error: {e}\")\n","\n","if __name__ == \"__main__\":\n","    xray_debug()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":49155,"status":"ok","timestamp":1766300038317,"user":{"displayName":"FARHAN JAFFAR","userId":"00674461129948116447"},"user_tz":-330},"id":"LjtrdKXErtmW","outputId":"ed26774e-61db-4f91-b45c-b149210938a4"},"outputs":[{"name":"stdout","output_type":"stream","text":["--- Starting Session-Primed Scraper ---\n","1. Session Cookie obtained.\n","2. Priming Session with District/Year context...\n","   Context set. Server response length: 4668\n","   List parsing failed/empty. Falling back to Brute Force on valid Malappuram IDs.\n","3. Scraping Details for 149 IDs...\n","No data. Session priming might have failed.\n"]}],"source":["import requests\n","import pandas as pd\n","import time\n","import urllib3\n","import json\n","\n","# 1. SETUP\n","urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n","\n","URL_HOME = \"https://lbtrend.kerala.gov.in/\"\n","URL_LIST = \"https://lbtrend.kerala.gov.in/includes/stateView2_ajax.php\"\n","URL_DETAILS = \"https://lbtrend.kerala.gov.in/includes/lb_ajax2.php\"\n","\n","HEADERS = {\n","    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36\",\n","    \"X-Requested-With\": \"XMLHttpRequest\",\n","    \"Referer\": \"https://lbtrend.kerala.gov.in/\"\n","}\n","\n","def scrape_kerala_final_fixed():\n","    print(\"--- Starting Session-Primed Scraper ---\")\n","    master_data = []\n","\n","    session = requests.Session()\n","    session.headers.update(HEADERS)\n","\n","    # 1. INIT SESSION (Home)\n","    try:\n","        session.get(URL_HOME, verify=False)\n","        print(\"1. Session Cookie obtained.\")\n","    except:\n","        pass\n","\n","    # CONFIG\n","    DIST_CODE = \"D10001\" # Malappuram\n","\n","    # --- STEP 1: PRIME THE SESSION ---\n","    # We MUST tell the server which district/year we are in.\n","    # We call the 'List' endpoint. even if the response is ignored,\n","    # the server updates $_SESSION['district'] and $_SESSION['year'].\n","    print(\"2. Priming Session with District/Year context...\")\n","\n","    payload_prime = {\n","        \"_p\": \"dv\",\n","        \"_l\": \"P\",\n","        \"_d\": DIST_CODE,\n","        \"_s\": \"M\"\n","        # Note: If year is needed, we might need to add it here,\n","        # but let's stick to what worked in your browser first.\n","    }\n","\n","    try:\n","        resp_prime = session.post(URL_LIST, data=payload_prime, verify=False)\n","        # We don't care if this returns a list or summary.\n","        # We just need the cookie to update.\n","        print(\"   Context set. Server response length:\", len(resp_prime.text))\n","\n","        # Try to extract valid IDs if possible, otherwise use manual range\n","        valid_ids = []\n","        try:\n","            data_list = resp_prime.json()\n","            if \"mdata\" in data_list and isinstance(data_list[\"mdata\"], list):\n","                valid_ids = [x[0] for x in data_list[\"mdata\"]]\n","            elif \"summary\" in data_list and len(data_list[\"summary\"]) > 10:\n","                valid_ids = [x[0] for x in data_list[\"summary\"]]\n","        except:\n","            pass\n","\n","        if valid_ids:\n","            print(f\"   Success! Found {len(valid_ids)} valid IDs from list.\")\n","        else:\n","            print(\"   List parsing failed/empty. Falling back to Brute Force on valid Malappuram IDs.\")\n","            # Known valid range for Malappuram based on your screenshots:\n","            # G10026, G10072, G10096.\n","            # We will scan a safe range.\n","            valid_ids = [f\"G10{i:03d}\" for i in range(1, 150)]\n","\n","    except Exception as e:\n","        print(f\"   Priming failed: {e}\")\n","        return\n","\n","    # --- STEP 2: SCRAPE DETAILS ---\n","    print(f\"3. Scraping Details for {len(valid_ids)} IDs...\")\n","\n","    success_count = 0\n","\n","    for lb_id in valid_ids:\n","        # Payload for Details\n","        payload_details = {\n","            \"_p\": \"wv\",\n","            \"_w\": lb_id,\n","            \"_t\": \"P\",\n","            \"_s\": \"L\"\n","        }\n","\n","        try:\n","            resp = session.post(URL_DETAILS, data=payload_details, verify=False)\n","            data = resp.json()\n","\n","            # Extract Wards (Look in 'summary' and 'mdata')\n","            wards = []\n","\n","            # Logic: If it's the 2-row summary, IGNORE IT. We want the long list.\n","\n","            potential_lists = []\n","            if \"summary\" in data: potential_lists.append(data[\"summary\"])\n","            if \"mdata\" in data:\n","                if isinstance(data[\"mdata\"], list): potential_lists.append(data[\"mdata\"])\n","                elif isinstance(data[\"mdata\"], dict):\n","                     for v in data[\"mdata\"].values():\n","                         if isinstance(v, list): potential_lists.append(v)\n","\n","            for lst in potential_lists:\n","                if len(lst) > 5: # Real ward list will have > 5 items (wards)\n","                    wards = lst\n","                    break\n","\n","            if wards:\n","                # Name is usually not in the row, so we use ID as placeholder or\n","                # extract if available in a header (not visible in JSON logs so far)\n","                lb_name = f\"Panchayat {lb_id}\"\n","\n","                # Check for Name in the previous \"Prime\" step if we had it\n","                # For now, just scrape the data\n","\n","                for w in wards:\n","                    # w: [Party, WardNum, WardName, ... Candidate, Votes]\n","                    if len(w) > 5:\n","                        master_data.append({\n","                            \"District\": \"Malappuram\",\n","                            \"LocalBodyID\": lb_id,\n","                            \"Ward\": f\"{w[1]} - {w[2]}\",\n","                            \"Candidate\": w[4],\n","                            \"Party\": w[0],\n","                            \"Votes\": w[5],\n","                            \"Year\": 2020\n","                        })\n","\n","                print(f\"   [SUCCESS] {lb_id}: {len(wards)} wards scraped.\")\n","                success_count += 1\n","            else:\n","                # print(f\"   [SKIP] {lb_id}: No detailed ward data (Length {len(wards)})\")\n","                pass\n","\n","        except Exception as e:\n","            pass\n","\n","        time.sleep(0.05) # Fast scan\n","\n","    # --- SAVE ---\n","    if master_data:\n","        df = pd.DataFrame(master_data)\n","        print(\"\\n--- SCRAPING COMPLETE ---\")\n","        print(df.head())\n","        df.to_csv(\"Malappuram_Final_Fixed.csv\", index=False)\n","        print(f\"Saved {len(df)} rows.\")\n","    else:\n","        print(\"No data. Session priming might have failed.\")\n","\n","if __name__ == \"__main__\":\n","    scrape_kerala_final_fixed()"]},{"cell_type":"markdown","source":["Starting 'Walk the Path' Scraper"],"metadata":{"id":"xvoVwpaq7KJr"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32213,"status":"ok","timestamp":1766314761996,"user":{"displayName":"FARHAN JAFFAR","userId":"00674461129948116447"},"user_tz":-330},"id":"I95-kKabj9Om","outputId":"96df5c49-2230-462b-dd91-adc9d41c396e"},"outputs":[{"name":"stdout","output_type":"stream","text":["--- Starting 'Walk the Path' Scraper ---\n","1. Homepage visited (Session started).\n","2. Fetching Malappuram List (_s='L')...\n","   -> Success! Found list with 94 items.\n","3. Scraping Ward Details...\n","   -> Processing: Abdurehman Nagar (G10072)\n","   -> Processing: Alamkode (G10096)\n","   -> Processing: Aliparamba (G10043)\n","   -> Processing: Amarambalam (G10026)\n","   -> Processing: Anakayam (G10037)\n","   -> Processing: Angadippuram (G10050)\n","   -> Processing: Areacode (G10029)\n","   -> Processing: Athavanad (G10057)\n","   -> Processing: Chaliyar (G10006)\n","   -> Processing: Cheacode (G10034)\n","   -> Processing: Chelembra (G10015)\n","   -> Processing: Cheriyamundam (G10066)\n","   -> Processing: Cherukavu (G10008)\n","   -> Processing: Chokkad (G10023)\n","   -> Processing: Chungathara (G10005)\n","   -> Processing: Edakkara (G10003)\n","   -> Processing: Edapatta (G10028)\n","   -> Processing: Edappal (G10094)\n","   -> Processing: Edarikkode (G10078)\n","   -> Processing: Edavanna (G10036)\n","   -> Processing: Edayur (G10058)\n","   -> Processing: Elamkulam (G10044)\n","   -> Processing: Irumbiliyum (G10059)\n","   -> Processing: Kalady (G10095)\n","   -> Processing: Kalikavu (G10022)\n","   -> Processing: Kalpakancheri (G10063)\n","   -> Processing: Kannamangalam (G10076)\n","   -> Processing: Karulai (G10027)\n","   -> Processing: Karuvarakundu (G10024)\n","   -> Processing: Kavannur (G10031)\n","   -> Processing: Keezhattur (G10046)\n","   -> Processing: Keezhuparamba (G10032)\n","   -> Processing: Kodur (G10042)\n","   -> Processing: Koottilangadi (G10052)\n","   -> Processing: Kuruva (G10051)\n","   -> Processing: Kuttippuram (G10061)\n","   -> Processing: Kuzhimanna (G10033)\n","   -> Processing: Makkaraparamba (G10055)\n","   -> Processing: Mampad (G10018)\n","   -> Processing: Mangalam (G10087)\n","   -> Processing: Mankada (G10056)\n","   -> Processing: Marakkara (G10060)\n","   -> Processing: Maranchery (G10097)\n","   -> Processing: Melattur (G10045)\n","   -> Processing: Moonniyur (G10081)\n","   -> Processing: Moorkanad (G10054)\n","   -> Processing: Moothedam (G10004)\n","   -> Processing: Morayur (G10038)\n","   -> Processing: Muthuvallur (G10014)\n","   -> Processing: Nannambra (G10080)\n","   -> Processing: Nannamukku (G10098)\n","   -> Processing: Niramaruthoor (G10068)\n","   -> Processing: Oorakam (G10077)\n","   -> Processing: Othukkungal (G10041)\n","   -> Processing: Ozhoor (G10067)\n","   -> Processing: Pallikkal (G10009)\n","   -> Processing: Pandikkad (G10020)\n","   -> Processing: Parappur (G10073)\n","   -> Processing: Perumanna Clari (G10071)\n","   -> Processing: Perumbadappu (G10099)\n","   -> Processing: Peruvallur (G10085)\n","   -> Processing: Ponmala (G10039)\n","   -> Processing: Ponmundam (G10065)\n","   -> Processing: Pookkottur (G10040)\n","   -> Processing: Porur (G10019)\n","   -> Processing: Pothukal (G10002)\n","   -> Processing: Pulamanthole (G10049)\n","   -> Processing: Pulikkal (G10012)\n","   -> Processing: Pulpetta (G10035)\n","   -> Processing: Purathur (G10086)\n","   -> Processing: Puzhakkatiri (G10053)\n","   -> Processing: Thalakkad (G10090)\n","   -> Processing: Thanalur (G10069)\n","   -> Processing: Thavanur (G10092)\n","   -> Processing: Thazhekkode (G10047)\n","   -> Processing: Thenhippalam (G10082)\n","   -> Processing: Thennela (G10074)\n","   -> Processing: Thirunavaya (G10091)\n","   -> Processing: Thiruvali (G10017)\n","   -> Processing: Thrikkalangode (G10021)\n","   -> Processing: Thriprangode (G10088)\n","   -> Processing: Thuvvur (G10025)\n","   -> Processing: Urangattiri (G10030)\n","   -> Processing: Valavannur (G10070)\n","   -> Processing: Vallikkunnu (G10084)\n","   -> Processing: Vattamkulam (G10093)\n","   -> Processing: Vazhakkad (G10011)\n","   -> Processing: Vazhayur (G10010)\n","   -> Processing: Vazhikkadavu (G10001)\n","   -> Processing: Veliyancode (G10100)\n","   -> Processing: Vengara (G10075)\n","   -> Processing: Vettathur (G10048)\n","   -> Processing: Vettom (G10089)\n","   -> Processing: Wandoor (G10016)\n","\n","--- SUCCESS! ---\n","     District        Local Body             Type WardName  Candidate  \\\n","0  Malappuram  Abdurehman Nagar  Grama Panchayat  UDF - 3        622   \n","1  Malappuram  Abdurehman Nagar  Grama Panchayat  UDF - 2        748   \n","2  Malappuram  Abdurehman Nagar  Grama Panchayat  UDF - 4        516   \n","3  Malappuram  Abdurehman Nagar  Grama Panchayat  UDF - 5        543   \n","4  Malappuram  Abdurehman Nagar  Grama Panchayat  UDF - 3        553   \n","\n","       Party             Votes  Year  \n","0  G10072001     Valiyaparamba  2020  \n","1  G10072002  Pukayoor Kunnath  2020  \n","2  G10072003          Pukayoor  2020  \n","3  G10072004        Kottamchal  2020  \n","4  G10072005      Puthiyangadi  2020  \n","Saved 2000 rows.\n"]}],"source":["import requests\n","import pandas as pd\n","import time\n","import urllib3\n","import json\n","\n","# 1. SETUP\n","urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n","\n","URL_HOME = \"https://lbtrend.kerala.gov.in/\"\n","URL_LIST = \"https://lbtrend.kerala.gov.in/includes/stateView2_ajax.php\"\n","URL_DETAILS = \"https://lbtrend.kerala.gov.in/includes/lb_ajax2.php\"\n","\n","HEADERS = {\n","    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36\",\n","    \"X-Requested-With\": \"XMLHttpRequest\",\n","    \"Referer\": \"https://lbtrend.kerala.gov.in/\"\n","}\n","\n","def deep_search_for_list(data, min_length=10):\n","    \"\"\"Recursively searches JSON for any list longer than min_length.\"\"\"\n","    candidates = []\n","\n","    if isinstance(data, dict):\n","        for k, v in data.items():\n","            if isinstance(v, list) and len(v) > min_length:\n","                candidates.append(v)\n","            elif isinstance(v, (dict, list)):\n","                candidates.extend(deep_search_for_list(v, min_length))\n","    elif isinstance(data, list):\n","        for item in data:\n","            if isinstance(item, (dict, list)):\n","                candidates.extend(deep_search_for_list(item, min_length))\n","\n","    return candidates\n","\n","def scrape_kerala_walkthrough():\n","    print(\"--- Starting 'Walk the Path' Scraper ---\")\n","    master_data = []\n","\n","    session = requests.Session()\n","    session.headers.update(HEADERS)\n","\n","    # STEP 1: VISIT HOME (Start Session)\n","    try:\n","        session.get(URL_HOME, verify=False)\n","        print(\"1. Homepage visited (Session started).\")\n","    except:\n","        pass\n","\n","    # STEP 2: \"CLICK\" MALAPPURAM\n","    # We use exactly the keys from your screenshot: _s=\"L\"\n","    print(\"2. Fetching Malappuram List (_s='L')...\")\n","\n","    payload_list = {\n","        \"_p\": \"dv\",\n","        \"_l\": \"P\",\n","        \"_d\": \"D10001\",   # Malappuram\n","        \"_s\": \"L\"         # The key from your screenshot\n","    }\n","\n","    try:\n","        resp = session.post(URL_LIST, data=payload_list, verify=False)\n","        data_list = resp.json()\n","\n","        # DEEP SEARCH: Find the big list (90+ items) ignoring key names\n","        found_lists = deep_search_for_list(data_list, min_length=20)\n","\n","        if not found_lists:\n","            print(\"[ERROR] No list found. Server returned keys:\", data_list.keys())\n","            if \"mdata\" in data_list: print(\"mdata:\", data_list[\"mdata\"])\n","            return\n","\n","        # The longest list found is likely our Panchayat list\n","        local_bodies = max(found_lists, key=len)\n","        print(f\"   -> Success! Found list with {len(local_bodies)} items.\")\n","\n","        # STEP 3: \"CLICK\" EACH PANCHAYAT\n","        print(\"3. Scraping Ward Details...\")\n","\n","        # Loop through the found list\n","        for item in local_bodies:\n","            # ID extraction (look for G1xxxx)\n","            lb_id = None\n","            lb_name = \"Unknown\"\n","\n","            # Robust ID finder\n","            for col in item:\n","                s_col = str(col)\n","                if s_col.startswith(\"G1\"):\n","                    lb_id = s_col\n","                elif len(s_col) > 3 and not s_col.startswith(\"G\") and not s_col.isdigit():\n","                    lb_name = s_col\n","\n","            if not lb_id: lb_id = item[0]\n","            if lb_name == \"Unknown\": lb_name = item[1]\n","\n","            print(f\"   -> Processing: {lb_name} ({lb_id})\")\n","\n","            # Payload for Details (Verified: _s='L')\n","            payload_details = {\n","                \"_p\": \"wv\",\n","                \"_w\": lb_id,\n","                \"_t\": \"P\",\n","                \"_s\": \"L\"\n","            }\n","\n","            try:\n","                resp_det = session.post(URL_DETAILS, data=payload_details, verify=False)\n","                det_json = resp_det.json()\n","\n","                # EXTRACT WARDS (Search again for list > 5 items)\n","                wards_lists = deep_search_for_list(det_json, min_length=5)\n","\n","                if wards_lists:\n","                    wards = max(wards_lists, key=len)\n","\n","                    for w in wards:\n","                        # Ensure row has enough columns\n","                        if len(w) >= 6:\n","                            master_data.append({\n","                                \"District\": \"Malappuram\",\n","                                \"Local Body\": lb_name,\n","                                \"Type\": \"Grama Panchayat\",\n","                                \"WardName\": f\"{w[1]} - {w[2]}\", # Adjust indices if needed\n","                                \"Candidate\": w[4],\n","                                \"Party\": w[0],\n","                                \"Votes\": w[5],\n","                                \"Year\": 2020\n","                            })\n","                else:\n","                    print(f\"      [Warning] No wards found for {lb_name}\")\n","\n","            except Exception as e:\n","                pass\n","\n","            time.sleep(0.05) # Speed up\n","\n","    except Exception as e:\n","        print(f\"Global Error: {e}\")\n","\n","    # SAVE\n","    if master_data:\n","        df = pd.DataFrame(master_data)\n","        print(\"\\n--- SUCCESS! ---\")\n","        print(df.head())\n","        df.to_csv(\"Malappuram_Full_Data.csv\", index=False)\n","        print(f\"Saved {len(df)} rows.\")\n","    else:\n","        print(\"No data collected.\")\n","\n","if __name__ == \"__main__\":\n","    scrape_kerala_walkthrough()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30750,"status":"ok","timestamp":1766315048582,"user":{"displayName":"FARHAN JAFFAR","userId":"00674461129948116447"},"user_tz":-330},"id":"YZLiO-gNlDUs","outputId":"b472ed51-ef46-4b03-c349-1989c7c3feb0"},"outputs":[{"name":"stdout","output_type":"stream","text":["--- Starting Final Corrected Scraper ---\n","Fetching Malappuram Panchayat List...\n","-> Found 94 Panchayats.\n","Scraping Ward Details...\n","   Processing: Abdurehman Nagar (G10072)\n","\n","[DEBUG] Raw Row Data: ['G10072001', 'UDF', 3, '\\u200d ', 622, 'Valiyaparamba', 'Y', 2, '2 - \\u200d ', 278]\n","Mapping Applied: 0=ID, 1=Party, 2=No, 3=Candidate?, 4=Votes, 5=Name\n","\n","   Processing: Alamkode (G10096)\n","   Processing: Aliparamba (G10043)\n","   Processing: Amarambalam (G10026)\n","   Processing: Anakayam (G10037)\n","   Processing: Angadippuram (G10050)\n","   Processing: Areacode (G10029)\n","   Processing: Athavanad (G10057)\n","   Processing: Chaliyar (G10006)\n","   Processing: Cheacode (G10034)\n","   Processing: Chelembra (G10015)\n","   Processing: Cheriyamundam (G10066)\n","   Processing: Cherukavu (G10008)\n","   Processing: Chokkad (G10023)\n","   Processing: Chungathara (G10005)\n","   Processing: Edakkara (G10003)\n","   Processing: Edapatta (G10028)\n","   Processing: Edappal (G10094)\n","   Processing: Edarikkode (G10078)\n","   Processing: Edavanna (G10036)\n","   Processing: Edayur (G10058)\n","   Processing: Elamkulam (G10044)\n","   Processing: Irumbiliyum (G10059)\n","   Processing: Kalady (G10095)\n","   Processing: Kalikavu (G10022)\n","   Processing: Kalpakancheri (G10063)\n","   Processing: Kannamangalam (G10076)\n","   Processing: Karulai (G10027)\n","   Processing: Karuvarakundu (G10024)\n","   Processing: Kavannur (G10031)\n","   Processing: Keezhattur (G10046)\n","   Processing: Keezhuparamba (G10032)\n","   Processing: Kodur (G10042)\n","   Processing: Koottilangadi (G10052)\n","   Processing: Kuruva (G10051)\n","   Processing: Kuttippuram (G10061)\n","   Processing: Kuzhimanna (G10033)\n","   Processing: Makkaraparamba (G10055)\n","   Processing: Mampad (G10018)\n","   Processing: Mangalam (G10087)\n","   Processing: Mankada (G10056)\n","   Processing: Marakkara (G10060)\n","   Processing: Maranchery (G10097)\n","   Processing: Melattur (G10045)\n","   Processing: Moonniyur (G10081)\n","   Processing: Moorkanad (G10054)\n","   Processing: Moothedam (G10004)\n","   Processing: Morayur (G10038)\n","   Processing: Muthuvallur (G10014)\n","   Processing: Nannambra (G10080)\n","   Processing: Nannamukku (G10098)\n","   Processing: Niramaruthoor (G10068)\n","   Processing: Oorakam (G10077)\n","   Processing: Othukkungal (G10041)\n","   Processing: Ozhoor (G10067)\n","   Processing: Pallikkal (G10009)\n","   Processing: Pandikkad (G10020)\n","   Processing: Parappur (G10073)\n","   Processing: Perumanna Clari (G10071)\n","   Processing: Perumbadappu (G10099)\n","   Processing: Peruvallur (G10085)\n","   Processing: Ponmala (G10039)\n","   Processing: Ponmundam (G10065)\n","   Processing: Pookkottur (G10040)\n","   Processing: Porur (G10019)\n","   Processing: Pothukal (G10002)\n","   Processing: Pulamanthole (G10049)\n","   Processing: Pulikkal (G10012)\n","   Processing: Pulpetta (G10035)\n","   Processing: Purathur (G10086)\n","   Processing: Puzhakkatiri (G10053)\n","   Processing: Thalakkad (G10090)\n","   Processing: Thanalur (G10069)\n","   Processing: Thavanur (G10092)\n","   Processing: Thazhekkode (G10047)\n","   Processing: Thenhippalam (G10082)\n","   Processing: Thennela (G10074)\n","   Processing: Thirunavaya (G10091)\n","   Processing: Thiruvali (G10017)\n","   Processing: Thrikkalangode (G10021)\n","   Processing: Thriprangode (G10088)\n","   Processing: Thuvvur (G10025)\n","   Processing: Urangattiri (G10030)\n","   Processing: Valavannur (G10070)\n","   Processing: Vallikkunnu (G10084)\n","   Processing: Vattamkulam (G10093)\n","   Processing: Vazhakkad (G10011)\n","   Processing: Vazhayur (G10010)\n","   Processing: Vazhikkadavu (G10001)\n","   Processing: Veliyancode (G10100)\n","   Processing: Vengara (G10075)\n","   Processing: Vettathur (G10048)\n","   Processing: Vettom (G10089)\n","   Processing: Wandoor (G10016)\n","\n","--- SCRAPING SUCCESS ---\n","     District        Local Body             Type              WardName  \\\n","0  Malappuram  Abdurehman Nagar  Grama Panchayat     3 - Valiyaparamba   \n","1  Malappuram  Abdurehman Nagar  Grama Panchayat  2 - Pukayoor Kunnath   \n","2  Malappuram  Abdurehman Nagar  Grama Panchayat          4 - Pukayoor   \n","3  Malappuram  Abdurehman Nagar  Grama Panchayat        5 - Kottamchal   \n","4  Malappuram  Abdurehman Nagar  Grama Panchayat      3 - Puthiyangadi   \n","\n","               Candidate Party Front  Votes  Year  \n","0         UDF   UDF    622  2020  \n","1               UDF   UDF    748  2020  \n","2         UDF   UDF    516  2020  \n","3      UDF   UDF    543  2020  \n","4                 .   UDF   UDF    553  2020  \n","Saved to 'Malappuram_Corrected.csv'\n","\n","Total Rows Scraped: 2000\n"]}],"source":["import requests\n","import pandas as pd\n","import time\n","import urllib3\n","import json\n","\n","# 1. SETUP\n","urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n","\n","URL_HOME = \"https://lbtrend.kerala.gov.in/\"\n","URL_LIST = \"https://lbtrend.kerala.gov.in/includes/stateView2_ajax.php\"\n","URL_DETAILS = \"https://lbtrend.kerala.gov.in/includes/lb_ajax2.php\"\n","\n","HEADERS = {\n","    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36\",\n","    \"X-Requested-With\": \"XMLHttpRequest\",\n","    \"Referer\": \"https://lbtrend.kerala.gov.in/\"\n","}\n","\n","def deep_search_for_list(data, min_length=10):\n","    \"\"\"Recursively searches JSON for any list longer than min_length.\"\"\"\n","    candidates = []\n","    if isinstance(data, dict):\n","        for k, v in data.items():\n","            if isinstance(v, list) and len(v) > min_length:\n","                candidates.append(v)\n","            elif isinstance(v, (dict, list)):\n","                candidates.extend(deep_search_for_list(v, min_length))\n","    elif isinstance(data, list):\n","        for item in data:\n","            if isinstance(item, (dict, list)):\n","                candidates.extend(deep_search_for_list(item, min_length))\n","    return candidates\n","\n","def scrape_kerala_final():\n","    print(\"--- Starting Final Corrected Scraper ---\")\n","    master_data = []\n","\n","    session = requests.Session()\n","    session.headers.update(HEADERS)\n","\n","    # 1. START SESSION\n","    try:\n","        session.get(URL_HOME, verify=False)\n","    except:\n","        pass\n","\n","    # 2. GET MALAPPURAM LIST\n","    print(\"Fetching Malappuram Panchayat List...\")\n","    payload_list = {\n","        \"_p\": \"dv\", \"_l\": \"P\", \"_d\": \"D10001\", \"_s\": \"L\"\n","    }\n","\n","    try:\n","        resp = session.post(URL_LIST, data=payload_list, verify=False)\n","        data_list = resp.json()\n","\n","        found_lists = deep_search_for_list(data_list, min_length=20)\n","        if not found_lists:\n","            print(\"[ERROR] List not found.\")\n","            return None\n","\n","        local_bodies = max(found_lists, key=len)\n","        print(f\"-> Found {len(local_bodies)} Panchayats.\")\n","\n","        # 3. SCRAPE DETAILS\n","        print(\"Scraping Ward Details...\")\n","\n","        debug_printed = False # To print just one raw row for verification\n","\n","        for item in local_bodies:\n","            # ID Extraction\n","            lb_id = None\n","            lb_name = \"Unknown\"\n","            for col in item:\n","                s_col = str(col)\n","                if s_col.startswith(\"G1\"): lb_id = s_col\n","                elif len(s_col) > 3 and not s_col.startswith(\"G\") and not s_col.isdigit(): lb_name = s_col\n","\n","            if not lb_id: lb_id = item[0]\n","            if lb_name == \"Unknown\": lb_name = item[1]\n","\n","            print(f\"   Processing: {lb_name} ({lb_id})\")\n","\n","            payload_details = {\n","                \"_p\": \"wv\", \"_w\": lb_id, \"_t\": \"P\", \"_s\": \"L\"\n","            }\n","\n","            try:\n","                resp_det = session.post(URL_DETAILS, data=payload_details, verify=False)\n","                det_json = resp_det.json()\n","\n","                wards_lists = deep_search_for_list(det_json, min_length=5)\n","\n","                if wards_lists:\n","                    wards = max(wards_lists, key=len)\n","\n","                    # DEBUG: Print the first raw row once to verify columns\n","                    if not debug_printed and len(wards) > 0:\n","                        print(f\"\\n[DEBUG] Raw Row Data: {wards[0]}\")\n","                        print(\"Mapping Applied: 0=ID, 1=Party, 2=No, 3=Candidate?, 4=Votes, 5=Name\\n\")\n","                        debug_printed = True\n","\n","                    for w in wards:\n","                        # BASED ON YOUR SCRAMBLED OUTPUT:\n","                        # w[0] was ID (G10072001)\n","                        # w[1] was Party (UDF)\n","                        # w[2] was WardNo (3)\n","                        # w[3] = CANDIDATE (Assumed, as it's the only slot left)\n","                        # w[4] was Votes (622)\n","                        # w[5] was WardName (Valiyaparamba)\n","\n","                        if len(w) >= 6:\n","                            master_data.append({\n","                                \"District\": \"Malappuram\",\n","                                \"Local Body\": lb_name,\n","                                \"Type\": \"Grama Panchayat\",\n","                                \"WardName\": f\"{w[2]} - {w[5]}\", # Number - Name\n","                                \"Candidate\": w[3], # Corrected Index\n","                                \"Party\": w[1],\n","                                \"Front\": w[1],     # Assuming Front = Party for now\n","                                \"Votes\": w[4],     # Corrected Index\n","                                \"Year\": 2020\n","                            })\n","            except Exception as e:\n","                pass\n","\n","            time.sleep(0.05)\n","\n","    except Exception as e:\n","        print(f\"Global Error: {e}\")\n","\n","    # SAVE AND RETURN\n","    if master_data:\n","        df = pd.DataFrame(master_data)\n","        print(\"\\n--- SCRAPING SUCCESS ---\")\n","        print(df.head()) # This will show if the columns are right\n","        df.to_csv(\"Malappuram_Corrected.csv\", index=False)\n","        print(\"Saved to 'Malappuram_Corrected.csv'\")\n","        return df\n","    else:\n","        return None\n","\n","# --- MAIN EXECUTION ---\n","if __name__ == \"__main__\":\n","    # We assign the result to 'df' so it persists after the function ends\n","    df = scrape_kerala_final()\n","\n","    # Now you can use 'df' or print it\n","    if df is not None:\n","        print(f\"\\nTotal Rows Scraped: {len(df)}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HVbGWASpkHZp"},"outputs":[],"source":["master_data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0s_fLfDWl8UJ"},"outputs":[],"source":["import requests\n","import pandas as pd\n","import time\n","import urllib3\n","import json\n","\n","# 1. SETUP\n","urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n","\n","URL_HOME = \"https://lbtrend.kerala.gov.in/\"\n","URL_LIST = \"https://lbtrend.kerala.gov.in/includes/stateView2_ajax.php\"\n","URL_DETAILS = \"https://lbtrend.kerala.gov.in/includes/lb_ajax2.php\"\n","\n","HEADERS = {\n","    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36\",\n","    \"X-Requested-With\": \"XMLHttpRequest\",\n","    \"Referer\": \"https://lbtrend.kerala.gov.in/\"\n","}\n","\n","def deep_search_for_list(data, min_length=10):\n","    \"\"\"Recursively searches JSON for any list longer than min_length.\"\"\"\n","    candidates = []\n","    if isinstance(data, dict):\n","        for k, v in data.items():\n","            if isinstance(v, list) and len(v) > min_length:\n","                candidates.append(v)\n","            elif isinstance(v, (dict, list)):\n","                candidates.extend(deep_search_for_list(v, min_length))\n","    elif isinstance(data, list):\n","        for item in data:\n","            if isinstance(item, (dict, list)):\n","                candidates.extend(deep_search_for_list(item, min_length))\n","    return candidates\n","\n","def scrape_kerala_final():\n","    print(\"--- Starting Final Corrected Scraper ---\")\n","    master_data = []\n","\n","    session = requests.Session()\n","    session.headers.update(HEADERS)\n","\n","    # 1. START SESSION\n","    try:\n","        session.get(URL_HOME, verify=False)\n","    except:\n","        pass\n","\n","    # 2. GET MALAPPURAM LIST\n","    print(\"Fetching Malappuram Panchayat List...\")\n","    payload_list = {\n","        \"_p\": \"dv\", \"_l\": \"P\", \"_d\": \"D10001\", \"_s\": \"L\"\n","    }\n","\n","    try:\n","        resp = session.post(URL_LIST, data=payload_list, verify=False)\n","        data_list = resp.json()\n","\n","        found_lists = deep_search_for_list(data_list, min_length=20)\n","        if not found_lists:\n","            print(\"[ERROR] List not found.\")\n","            return None\n","\n","        local_bodies = max(found_lists, key=len)\n","        print(f\"-> Found {len(local_bodies)} Panchayats.\")\n","\n","        # 3. SCRAPE DETAILS\n","        print(\"Scraping Ward Details...\")\n","\n","        debug_printed = False # To print just one raw row for verification\n","\n","        for item in local_bodies:\n","            # ID Extraction\n","            lb_id = None\n","            lb_name = \"Unknown\"\n","            for col in item:\n","                s_col = str(col)\n","                if s_col.startswith(\"G1\"): lb_id = s_col\n","                elif len(s_col) > 3 and not s_col.startswith(\"G\") and not s_col.isdigit(): lb_name = s_col\n","\n","            if not lb_id: lb_id = item[0]\n","            if lb_name == \"Unknown\": lb_name = item[1]\n","\n","            print(f\"   Processing: {lb_name} ({lb_id})\")\n","\n","            payload_details = {\n","                \"_p\": \"wv\", \"_w\": lb_id, \"_t\": \"P\", \"_s\": \"L\"\n","            }\n","\n","            try:\n","                resp_det = session.post(URL_DETAILS, data=payload_details, verify=False)\n","                det_json = resp_det.json()\n","\n","                wards_lists = deep_search_for_list(det_json, min_length=5)\n","\n","                if wards_lists:\n","                    wards = max(wards_lists, key=len)\n","\n","                    # DEBUG: Print the first raw row once to verify columns\n","                    if not debug_printed and len(wards) > 0:\n","                        print(f\"\\n[DEBUG] Raw Row Data: {wards[0]}\")\n","                        print(\"Mapping Applied: 0=ID, 1=Party, 2=No, 3=Candidate?, 4=Votes, 5=Name\\n\")\n","                        debug_printed = True\n","\n","                    for w in wards:\n","                        # BASED ON YOUR SCRAMBLED OUTPUT:\n","                        # w[0] was ID (G10072001)\n","                        # w[1] was Party (UDF)\n","                        # w[2] was WardNo (3)\n","                        # w[3] = CANDIDATE (Assumed, as it's the only slot left)\n","                        # w[4] was Votes (622)\n","                        # w[5] was WardName (Valiyaparamba)\n","\n","                        if len(w) >= 6:\n","                            master_data.append({\n","                                \"District\": \"Malappuram\",\n","                                \"Local Body\": lb_name,\n","                                \"Type\": \"Grama Panchayat\",\n","                                \"WardName\": f\"{w[2]} - {w[5]}\", # Number - Name\n","                                \"Candidate\": w[3], # Corrected Index\n","                                \"Party\": w[1],\n","                                \"Front\": w[1],     # Assuming Front = Party for now\n","                                \"Votes\": w[4],     # Corrected Index\n","                                \"Year\": 2025\n","                            })\n","            except Exception as e:\n","                pass\n","\n","            time.sleep(0.05)\n","\n","    except Exception as e:\n","        print(f\"Global Error: {e}\")\n","\n","    # SAVE AND RETURN\n","    if master_data:\n","        df = pd.DataFrame(master_data)\n","        print(\"\\n--- SCRAPING SUCCESS ---\")\n","        print(df.head()) # This will show if the columns are right\n","        df.to_csv(\"Malappuram_Corrected.csv\", index=False)\n","        print(\"Saved to 'Malappuram_Corrected.csv'\")\n","        return df\n","    else:\n","        return None\n","\n","# --- MAIN EXECUTION ---\n","if __name__ == \"__main__\":\n","    # We assign the result to 'df' so it persists after the function ends\n","    df = scrape_kerala_final()\n","\n","    # Now you can use 'df' or print it\n","    if df is not None:\n","        print(f\"\\nTotal Rows Scraped: {len(df)}\")"]},{"cell_type":"markdown","source":["Starting Final Scraper (With Malayalam Fix)"],"metadata":{"id":"FBGiLbQB7W5G"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28798,"status":"ok","timestamp":1766315668366,"user":{"displayName":"FARHAN JAFFAR","userId":"00674461129948116447"},"user_tz":-330},"id":"GnjuiysZnbCy","outputId":"fa16c262-f2ad-4d42-b22c-e874dbcc8bc0"},"outputs":[{"name":"stdout","output_type":"stream","text":["--- Starting Final Scraper (With Malayalam Fix) ---\n","Fetching Malappuram Panchayat List...\n","-> Found 94 Panchayats.\n","Scraping Ward Details...\n","   Processing: Abdurehman Nagar (G10072)\n","   Processing: Alamkode (G10096)\n","   Processing: Aliparamba (G10043)\n","   Processing: Amarambalam (G10026)\n","   Processing: Anakayam (G10037)\n","   Processing: Angadippuram (G10050)\n","   Processing: Areacode (G10029)\n","   Processing: Athavanad (G10057)\n","   Processing: Chaliyar (G10006)\n","   Processing: Cheacode (G10034)\n","   Processing: Chelembra (G10015)\n","   Processing: Cheriyamundam (G10066)\n","   Processing: Cherukavu (G10008)\n","   Processing: Chokkad (G10023)\n","   Processing: Chungathara (G10005)\n","   Processing: Edakkara (G10003)\n","   Processing: Edapatta (G10028)\n","   Processing: Edappal (G10094)\n","   Processing: Edarikkode (G10078)\n","   Processing: Edavanna (G10036)\n","   Processing: Edayur (G10058)\n","   Processing: Elamkulam (G10044)\n","   Processing: Irumbiliyum (G10059)\n","   Processing: Kalady (G10095)\n","   Processing: Kalikavu (G10022)\n","   Processing: Kalpakancheri (G10063)\n","   Processing: Kannamangalam (G10076)\n","   Processing: Karulai (G10027)\n","   Processing: Karuvarakundu (G10024)\n","   Processing: Kavannur (G10031)\n","   Processing: Keezhattur (G10046)\n","   Processing: Keezhuparamba (G10032)\n","   Processing: Kodur (G10042)\n","   Processing: Koottilangadi (G10052)\n","   Processing: Kuruva (G10051)\n","   Processing: Kuttippuram (G10061)\n","   Processing: Kuzhimanna (G10033)\n","   Processing: Makkaraparamba (G10055)\n","   Processing: Mampad (G10018)\n","   Processing: Mangalam (G10087)\n","   Processing: Mankada (G10056)\n","   Processing: Marakkara (G10060)\n","   Processing: Maranchery (G10097)\n","   Processing: Melattur (G10045)\n","   Processing: Moonniyur (G10081)\n","   Processing: Moorkanad (G10054)\n","   Processing: Moothedam (G10004)\n","   Processing: Morayur (G10038)\n","   Processing: Muthuvallur (G10014)\n","   Processing: Nannambra (G10080)\n","   Processing: Nannamukku (G10098)\n","   Processing: Niramaruthoor (G10068)\n","   Processing: Oorakam (G10077)\n","   Processing: Othukkungal (G10041)\n","   Processing: Ozhoor (G10067)\n","   Processing: Pallikkal (G10009)\n","   Processing: Pandikkad (G10020)\n","   Processing: Parappur (G10073)\n","   Processing: Perumanna Clari (G10071)\n","   Processing: Perumbadappu (G10099)\n","   Processing: Peruvallur (G10085)\n","   Processing: Ponmala (G10039)\n","   Processing: Ponmundam (G10065)\n","   Processing: Pookkottur (G10040)\n","   Processing: Porur (G10019)\n","   Processing: Pothukal (G10002)\n","   Processing: Pulamanthole (G10049)\n","   Processing: Pulikkal (G10012)\n","   Processing: Pulpetta (G10035)\n","   Processing: Purathur (G10086)\n","   Processing: Puzhakkatiri (G10053)\n","   Processing: Thalakkad (G10090)\n","   Processing: Thanalur (G10069)\n","   Processing: Thavanur (G10092)\n","   Processing: Thazhekkode (G10047)\n","   Processing: Thenhippalam (G10082)\n","   Processing: Thennela (G10074)\n","   Processing: Thirunavaya (G10091)\n","   Processing: Thiruvali (G10017)\n","   Processing: Thrikkalangode (G10021)\n","   Processing: Thriprangode (G10088)\n","   Processing: Thuvvur (G10025)\n","   Processing: Urangattiri (G10030)\n","   Processing: Valavannur (G10070)\n","   Processing: Vallikkunnu (G10084)\n","   Processing: Vattamkulam (G10093)\n","   Processing: Vazhakkad (G10011)\n","   Processing: Vazhayur (G10010)\n","   Processing: Vazhikkadavu (G10001)\n","   Processing: Veliyancode (G10100)\n","   Processing: Vengara (G10075)\n","   Processing: Vettathur (G10048)\n","   Processing: Vettom (G10089)\n","   Processing: Wandoor (G10016)\n","\n","--- SCRAPING SUCCESS ---\n","     District        Local Body             Type              WardName  \\\n","0  Malappuram  Abdurehman Nagar  Grama Panchayat     3 - Valiyaparamba   \n","1  Malappuram  Abdurehman Nagar  Grama Panchayat  2 - Pukayoor Kunnath   \n","2  Malappuram  Abdurehman Nagar  Grama Panchayat          4 - Pukayoor   \n","3  Malappuram  Abdurehman Nagar  Grama Panchayat        5 - Kottamchal   \n","4  Malappuram  Abdurehman Nagar  Grama Panchayat      3 - Puthiyangadi   \n","\n","               Candidate Party Front  Votes  Year  \n","0         UDF   UDF    622  2020  \n","1               UDF   UDF    748  2020  \n","2         UDF   UDF    516  2020  \n","3      UDF   UDF    543  2020  \n","4                 .   UDF   UDF    553  2020  \n","Saved to 'Malappuram_Final_Fixed.csv' (Open this in Excel)\n"]}],"source":["import requests\n","import pandas as pd\n","import time\n","import urllib3\n","import json\n","\n","# 1. SETUP\n","urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n","\n","URL_HOME = \"https://lbtrend.kerala.gov.in/\"\n","URL_LIST = \"https://lbtrend.kerala.gov.in/includes/stateView2_ajax.php\"\n","URL_DETAILS = \"https://lbtrend.kerala.gov.in/includes/lb_ajax2.php\"\n","\n","HEADERS = {\n","    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36\",\n","    \"X-Requested-With\": \"XMLHttpRequest\",\n","    \"Referer\": \"https://lbtrend.kerala.gov.in/\"\n","}\n","\n","def deep_search_for_list(data, min_length=10):\n","    \"\"\"Recursively searches JSON for any list longer than min_length.\"\"\"\n","    candidates = []\n","    if isinstance(data, dict):\n","        for k, v in data.items():\n","            if isinstance(v, list) and len(v) > min_length:\n","                candidates.append(v)\n","            elif isinstance(v, (dict, list)):\n","                candidates.extend(deep_search_for_list(v, min_length))\n","    elif isinstance(data, list):\n","        for item in data:\n","            if isinstance(item, (dict, list)):\n","                candidates.extend(deep_search_for_list(item, min_length))\n","    return candidates\n","\n","def scrape_kerala_final():\n","    print(\"--- Starting Final Scraper (With Malayalam Fix) ---\")\n","    master_data = []\n","\n","    session = requests.Session()\n","    session.headers.update(HEADERS)\n","\n","    # 1. START SESSION\n","    try:\n","        session.get(URL_HOME, verify=False)\n","    except:\n","        pass\n","\n","    # 2. GET MALAPPURAM LIST\n","    print(\"Fetching Malappuram Panchayat List...\")\n","    payload_list = {\n","        \"_p\": \"dv\", \"_l\": \"P\", \"_d\": \"D10001\", \"_s\": \"L\"\n","    }\n","\n","    try:\n","        resp = session.post(URL_LIST, data=payload_list, verify=False)\n","        data_list = resp.json()\n","\n","        found_lists = deep_search_for_list(data_list, min_length=20)\n","        if not found_lists:\n","            print(\"[ERROR] List not found.\")\n","            return\n","\n","        local_bodies = max(found_lists, key=len)\n","        print(f\"-> Found {len(local_bodies)} Panchayats.\")\n","\n","        # 3. SCRAPE DETAILS\n","        print(\"Scraping Ward Details...\")\n","\n","        for item in local_bodies:\n","            # ID Extraction\n","            lb_id = None\n","            lb_name = \"Unknown\"\n","            for col in item:\n","                s_col = str(col)\n","                if s_col.startswith(\"G1\"): lb_id = s_col\n","                elif len(s_col) > 3 and not s_col.startswith(\"G\") and not s_col.isdigit(): lb_name = s_col\n","\n","            if not lb_id: lb_id = item[0]\n","            if lb_name == \"Unknown\": lb_name = item[1]\n","\n","            print(f\"   Processing: {lb_name} ({lb_id})\")\n","\n","            payload_details = {\n","                \"_p\": \"wv\", \"_w\": lb_id, \"_t\": \"P\", \"_s\": \"L\"\n","            }\n","\n","            try:\n","                resp_det = session.post(URL_DETAILS, data=payload_details, verify=False)\n","                det_json = resp_det.json()\n","\n","                wards_lists = deep_search_for_list(det_json, min_length=5)\n","\n","                if wards_lists:\n","                    wards = max(wards_lists, key=len)\n","\n","                    for w in wards:\n","                        if len(w) >= 6:\n","                            master_data.append({\n","                                \"District\": \"Malappuram\",\n","                                \"Local Body\": lb_name,\n","                                \"Type\": \"Grama Panchayat\",\n","                                \"WardName\": f\"{w[2]} - {w[5]}\", # Ward No - Ward Name\n","                                \"Candidate\": w[3], # Malayalam Name\n","                                \"Party\": w[1],     # e.g., UDF (Front)\n","                                \"Front\": w[1],     # e.g., UDF (Front)\n","                                \"Votes\": w[4],     # Winner Votes\n","                                \"Year\": 2020\n","                            })\n","            except Exception as e:\n","                pass\n","\n","            time.sleep(0.05)\n","\n","    except Exception as e:\n","        print(f\"Global Error: {e}\")\n","\n","    # 4. SAVE WITH UTF-8-SIG (The Fix!)\n","    if master_data:\n","        df = pd.DataFrame(master_data)\n","        print(\"\\n--- SCRAPING SUCCESS ---\")\n","        print(df.head())\n","\n","        # 'utf-8-sig' allows Excel to read Malayalam correctly\n","        df.to_csv(\"Malappuram_Final_Fixed.csv\", index=False, encoding='utf-8-sig')\n","        print(\"Saved to 'Malappuram_Final_Fixed.csv' (Open this in Excel)\")\n","    else:\n","        print(\"No data collected.\")\n","\n","if __name__ == \"__main__\":\n","    scrape_kerala_final()"]},{"cell_type":"markdown","source":["Starting Deep Dive Scraper (Target: 2025 Exact Parties)"],"metadata":{"id":"8Q9rLtCI7fHh"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":642784,"status":"ok","timestamp":1766319278149,"user":{"displayName":"FARHAN JAFFAR","userId":"00674461129948116447"},"user_tz":-330},"id":"WlZQ0EsKy06j","outputId":"30f3df2d-c149-4df1-c048-18adba16d96f"},"outputs":[{"name":"stdout","output_type":"stream","text":["--- Starting Deep Dive Scraper (Target: 2025 Exact Parties) ---\n","1. Session initialized.\n","2. Fetching Panchayat List for Malappuram (D10001)...\n","   -> Found 94 Panchayats. Starting Deep Scan...\n","\n","[1/94] Scanning: Abdurehman Nagar (G10072)\n","    -> Found 24 Wards. Fetching candidates for each...\n","\n","[2/94] Scanning: Alamkode (G10096)\n","    -> Found 21 Wards. Fetching candidates for each...\n","\n","[3/94] Scanning: Aliparamba (G10043)\n","    -> Found 24 Wards. Fetching candidates for each...\n","\n","[4/94] Scanning: Amarambalam (G10026)\n","    -> Found 22 Wards. Fetching candidates for each...\n","\n","[5/94] Scanning: Anakayam (G10037)\n","    -> Found 24 Wards. Fetching candidates for each...\n","\n","[6/94] Scanning: Angadippuram (G10050)\n","    -> Found 24 Wards. Fetching candidates for each...\n","\n","[7/94] Scanning: Areacode (G10029)\n","    -> Found 20 Wards. Fetching candidates for each...\n","\n","[8/94] Scanning: Athavanad (G10057)\n","    -> Found 24 Wards. Fetching candidates for each...\n","\n","[9/94] Scanning: Chaliyar (G10006)\n","    -> Found 16 Wards. Fetching candidates for each...\n","\n","[10/94] Scanning: Cheacode (G10034)\n","    -> Found 21 Wards. Fetching candidates for each...\n","\n","[11/94] Scanning: Chelembra (G10015)\n","    -> Found 21 Wards. Fetching candidates for each...\n","\n","[12/94] Scanning: Cheriyamundam (G10066)\n","    -> Found 20 Wards. Fetching candidates for each...\n","\n","[13/94] Scanning: Cherukavu (G10008)\n","    -> Found 22 Wards. Fetching candidates for each...\n","\n","[14/94] Scanning: Chokkad (G10023)\n","    -> Found 20 Wards. Fetching candidates for each...\n","\n","[15/94] Scanning: Chungathara (G10005)\n","    -> Found 22 Wards. Fetching candidates for each...\n","\n","[16/94] Scanning: Edakkara (G10003)\n","    -> Found 19 Wards. Fetching candidates for each...\n","\n","[17/94] Scanning: Edapatta (G10028)\n","    -> Found 17 Wards. Fetching candidates for each...\n","\n","[18/94] Scanning: Edappal (G10094)\n","    -> Found 21 Wards. Fetching candidates for each...\n","\n","[19/94] Scanning: Edarikkode (G10078)\n","    -> Found 18 Wards. Fetching candidates for each...\n","\n","[20/94] Scanning: Edavanna (G10036)\n","    -> Found 24 Wards. Fetching candidates for each...\n","\n","[21/94] Scanning: Edayur (G10058)\n","    -> Found 22 Wards. Fetching candidates for each...\n","\n","[22/94] Scanning: Elamkulam (G10044)\n","    -> Found 18 Wards. Fetching candidates for each...\n","\n","[23/94] Scanning: Irumbiliyum (G10059)\n","    -> Found 20 Wards. Fetching candidates for each...\n","\n","[24/94] Scanning: Kalady (G10095)\n","    -> Found 18 Wards. Fetching candidates for each...\n","\n","[25/94] Scanning: Kalikavu (G10022)\n","    -> Found 22 Wards. Fetching candidates for each...\n","\n","[26/94] Scanning: Kalpakancheri (G10063)\n","    -> Found 21 Wards. Fetching candidates for each...\n","\n","[27/94] Scanning: Kannamangalam (G10076)\n","    -> Found 24 Wards. Fetching candidates for each...\n","\n","[28/94] Scanning: Karulai (G10027)\n","    -> Found 17 Wards. Fetching candidates for each...\n","\n","[29/94] Scanning: Karuvarakundu (G10024)\n","    -> Found 24 Wards. Fetching candidates for each...\n","\n","[30/94] Scanning: Kavannur (G10031)\n","    -> Found 23 Wards. Fetching candidates for each...\n","\n","[31/94] Scanning: Keezhattur (G10046)\n","    -> Found 22 Wards. Fetching candidates for each...\n","\n","[32/94] Scanning: Keezhuparamba (G10032)\n","    -> Found 16 Wards. Fetching candidates for each...\n","\n","[33/94] Scanning: Kodur (G10042)\n","    -> Found 23 Wards. Fetching candidates for each...\n","\n","[34/94] Scanning: Koottilangadi (G10052)\n","    -> Found 22 Wards. Fetching candidates for each...\n","\n","[35/94] Scanning: Kuruva (G10051)\n","    -> Found 24 Wards. Fetching candidates for each...\n","\n","[36/94] Scanning: Kuttippuram (G10061)\n","    -> Found 24 Wards. Fetching candidates for each...\n","\n","[37/94] Scanning: Kuzhimanna (G10033)\n","    -> Found 21 Wards. Fetching candidates for each...\n","\n","[38/94] Scanning: Makkaraparamba (G10055)\n","    -> Found 15 Wards. Fetching candidates for each...\n","\n","[39/94] Scanning: Mampad (G10018)\n","    -> Found 22 Wards. Fetching candidates for each...\n","\n","[40/94] Scanning: Mangalam (G10087)\n","    -> Found 21 Wards. Fetching candidates for each...\n","\n","[41/94] Scanning: Mankada (G10056)\n","    -> Found 21 Wards. Fetching candidates for each...\n","\n","[42/94] Scanning: Marakkara (G10060)\n","    -> Found 24 Wards. Fetching candidates for each...\n","\n","[43/94] Scanning: Maranchery (G10097)\n","    -> Found 22 Wards. Fetching candidates for each...\n","\n","[44/94] Scanning: Melattur (G10045)\n","    -> Found 18 Wards. Fetching candidates for each...\n","\n","[45/94] Scanning: Moonniyur (G10081)\n","    -> Found 24 Wards. Fetching candidates for each...\n","\n","[46/94] Scanning: Moorkanad (G10054)\n","    -> Found 22 Wards. Fetching candidates for each...\n","\n","[47/94] Scanning: Moothedam (G10004)\n","    -> Found 17 Wards. Fetching candidates for each...\n","\n","[48/94] Scanning: Morayur (G10038)\n","    -> Found 21 Wards. Fetching candidates for each...\n","\n","[49/94] Scanning: Muthuvallur (G10014)\n","    -> Found 18 Wards. Fetching candidates for each...\n","\n","[50/94] Scanning: Nannambra (G10080)\n","    -> Found 24 Wards. Fetching candidates for each...\n","\n","[51/94] Scanning: Nannamukku (G10098)\n","    -> Found 19 Wards. Fetching candidates for each...\n","\n","[52/94] Scanning: Niramaruthoor (G10068)\n","    -> Found 19 Wards. Fetching candidates for each...\n","\n","[53/94] Scanning: Oorakam (G10077)\n","    -> Found 19 Wards. Fetching candidates for each...\n","\n","[54/94] Scanning: Othukkungal (G10041)\n","    -> Found 23 Wards. Fetching candidates for each...\n","\n","[55/94] Scanning: Ozhoor (G10067)\n","    -> Found 21 Wards. Fetching candidates for each...\n","\n","[56/94] Scanning: Pallikkal (G10009)\n","    -> Found 24 Wards. Fetching candidates for each...\n","\n","[57/94] Scanning: Pandikkad (G10020)\n","    -> Found 24 Wards. Fetching candidates for each...\n","\n","[58/94] Scanning: Parappur (G10073)\n","    -> Found 22 Wards. Fetching candidates for each...\n","\n","[59/94] Scanning: Perumanna Clari (G10071)\n","    -> Found 18 Wards. Fetching candidates for each...\n","\n","[60/94] Scanning: Perumbadappu (G10099)\n","    -> Found 19 Wards. Fetching candidates for each...\n","\n","[61/94] Scanning: Peruvallur (G10085)\n","    -> Found 21 Wards. Fetching candidates for each...\n","\n","[62/94] Scanning: Ponmala (G10039)\n","    -> Found 21 Wards. Fetching candidates for each...\n","\n","[63/94] Scanning: Ponmundam (G10065)\n","    -> Found 18 Wards. Fetching candidates for each...\n","\n","[64/94] Scanning: Pookkottur (G10040)\n","    -> Found 23 Wards. Fetching candidates for each...\n","\n","[65/94] Scanning: Porur (G10019)\n","    -> Found 19 Wards. Fetching candidates for each...\n","\n","[66/94] Scanning: Pothukal (G10002)\n","    -> Found 19 Wards. Fetching candidates for each...\n","\n","[67/94] Scanning: Pulamanthole (G10049)\n","    -> Found 23 Wards. Fetching candidates for each...\n","\n","[68/94] Scanning: Pulikkal (G10012)\n","    -> Found 24 Wards. Fetching candidates for each...\n","\n","[69/94] Scanning: Pulpetta (G10035)\n","    -> Found 24 Wards. Fetching candidates for each...\n","\n","[70/94] Scanning: Purathur (G10086)\n","    -> Found 20 Wards. Fetching candidates for each...\n","\n","[71/94] Scanning: Puzhakkatiri (G10053)\n","    -> Found 19 Wards. Fetching candidates for each...\n","\n","[72/94] Scanning: Thalakkad (G10090)\n","    -> Found 22 Wards. Fetching candidates for each...\n","\n","[73/94] Scanning: Thanalur (G10069)\n","    -> Found 24 Wards. Fetching candidates for each...\n","\n","[74/94] Scanning: Thavanur (G10092)\n","    -> Found 21 Wards. Fetching candidates for each...\n","\n","[75/94] Scanning: Thazhekkode (G10047)\n","    -> Found 24 Wards. Fetching candidates for each...\n","\n","[76/94] Scanning: Thenhippalam (G10082)\n","    -> Found 20 Wards. Fetching candidates for each...\n","\n","[77/94] Scanning: Thennela (G10074)\n","    -> Found 19 Wards. Fetching candidates for each...\n","\n","[78/94] Scanning: Thirunavaya (G10091)\n","    -> Found 24 Wards. Fetching candidates for each...\n","\n","[79/94] Scanning: Thiruvali (G10017)\n","    -> Found 19 Wards. Fetching candidates for each...\n","\n","[80/94] Scanning: Thrikkalangode (G10021)\n","    -> Found 24 Wards. Fetching candidates for each...\n","\n","[81/94] Scanning: Thriprangode (G10088)\n","    -> Found 24 Wards. Fetching candidates for each...\n","\n","[82/94] Scanning: Thuvvur (G10025)\n","    -> Found 19 Wards. Fetching candidates for each...\n","\n","[83/94] Scanning: Urangattiri (G10030)\n","    -> Found 24 Wards. Fetching candidates for each...\n","\n","[84/94] Scanning: Valavannur (G10070)\n","    -> Found 21 Wards. Fetching candidates for each...\n","\n","[85/94] Scanning: Vallikkunnu (G10084)\n","    -> Found 24 Wards. Fetching candidates for each...\n","\n","[86/94] Scanning: Vattamkulam (G10093)\n","    -> Found 22 Wards. Fetching candidates for each...\n","\n","[87/94] Scanning: Vazhakkad (G10011)\n","    -> Found 22 Wards. Fetching candidates for each...\n","\n","[88/94] Scanning: Vazhayur (G10010)\n","    -> Found 20 Wards. Fetching candidates for each...\n","\n","[89/94] Scanning: Vazhikkadavu (G10001)\n","    -> Found 24 Wards. Fetching candidates for each...\n","\n","[90/94] Scanning: Veliyancode (G10100)\n","    -> Found 21 Wards. Fetching candidates for each...\n","\n","[91/94] Scanning: Vengara (G10075)\n","    -> Found 24 Wards. Fetching candidates for each...\n","\n","[92/94] Scanning: Vettathur (G10048)\n","    -> Found 19 Wards. Fetching candidates for each...\n","\n","[93/94] Scanning: Vettom (G10089)\n","    -> Found 22 Wards. Fetching candidates for each...\n","\n","[94/94] Scanning: Wandoor (G10016)\n","    -> Found 24 Wards. Fetching candidates for each...\n","\n","--- SCRAPING SUCCESS ---\n","     District        Local Body             Type                  Ward  \\\n","0  Malappuram  Abdurehman Nagar  Grama Panchayat     3 - Valiyaparamba   \n","1  Malappuram  Abdurehman Nagar  Grama Panchayat  2 - Pukayoor Kunnath   \n","2  Malappuram  Abdurehman Nagar  Grama Panchayat          4 - Pukayoor   \n","3  Malappuram  Abdurehman Nagar  Grama Panchayat        5 - Kottamchal   \n","4  Malappuram  Abdurehman Nagar  Grama Panchayat      3 - Puthiyangadi   \n","\n","  Candidate Party Front  Votes  Year  \n","0   Unknown   UDF   UDF      0  2025  \n","1   Unknown   UDF   UDF      0  2025  \n","2   Unknown   UDF   UDF      0  2025  \n","3   Unknown   UDF   UDF      0  2025  \n","4   Unknown   UDF   UDF      0  2025  \n","Saved 2000 rows to 'Malappuram_2025_Detailed.csv'\n"]}],"source":["import requests\n","import pandas as pd\n","import time\n","import urllib3\n","import json\n","\n","# 1. SETUP\n","urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n","\n","URL_HOME = \"https://lbtrend.kerala.gov.in/\"\n","URL_LIST = \"https://lbtrend.kerala.gov.in/includes/stateView2_ajax.php\"\n","URL_DETAILS = \"https://lbtrend.kerala.gov.in/includes/lb_ajax2.php\"\n","\n","HEADERS = {\n","    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36\",\n","    \"X-Requested-With\": \"XMLHttpRequest\",\n","    \"Referer\": \"https://lbtrend.kerala.gov.in/\"\n","}\n","\n","def deep_search_for_list(data, min_length=5):\n","    \"\"\"Recursively searches JSON for any list longer than min_length.\"\"\"\n","    candidates = []\n","    if isinstance(data, dict):\n","        for k, v in data.items():\n","            if isinstance(v, list) and len(v) >= min_length:\n","                candidates.append(v)\n","            elif isinstance(v, (dict, list)):\n","                candidates.extend(deep_search_for_list(v, min_length))\n","    elif isinstance(data, list):\n","        for item in data:\n","            if isinstance(item, (dict, list)):\n","                candidates.extend(deep_search_for_list(item, min_length))\n","    return candidates\n","\n","def scrape_kerala_2025_deep():\n","    print(\"--- Starting Deep Dive Scraper (Target: 2025 Exact Parties) ---\")\n","    master_data = []\n","\n","    session = requests.Session()\n","    session.headers.update(HEADERS)\n","\n","    # 1. INIT SESSION\n","    try:\n","        session.get(URL_HOME, verify=False)\n","        print(\"1. Session initialized.\")\n","    except:\n","        pass\n","\n","    # 2. GET PANCHAYAT LIST (Malappuram)\n","    print(\"2. Fetching Panchayat List for Malappuram (D10001)...\")\n","    payload_list = {\n","        \"_p\": \"dv\", \"_l\": \"P\", \"_d\": \"D10001\", \"_s\": \"L\"\n","    }\n","\n","    try:\n","        resp = session.post(URL_LIST, data=payload_list, verify=False)\n","        data_list = resp.json()\n","        found_lists = deep_search_for_list(data_list, min_length=50) # Expecting ~90+ bodies\n","\n","        if not found_lists:\n","            print(\"[ERROR] Panchayat list not found.\")\n","            return\n","\n","        local_bodies = max(found_lists, key=len)\n","        print(f\"   -> Found {len(local_bodies)} Panchayats. Starting Deep Scan...\")\n","\n","        # 3. LOOP PANCHAYATS\n","        total_panchayats = len(local_bodies)\n","\n","        for i, item in enumerate(local_bodies):\n","            # ID Extraction\n","            lb_id = None\n","            lb_name = \"Unknown\"\n","            for col in item:\n","                s_col = str(col)\n","                if s_col.startswith(\"G1\"): lb_id = s_col\n","                elif len(s_col) > 3 and not s_col.startswith(\"G\") and not s_col.isdigit(): lb_name = s_col\n","\n","            if not lb_id: lb_id = item[0]\n","            if lb_name == \"Unknown\": lb_name = item[1]\n","\n","            print(f\"\\n[{i+1}/{total_panchayats}] Scanning: {lb_name} ({lb_id})\")\n","\n","            # 4. GET WARD LIST (Level 3)\n","            payload_wards = {\n","                \"_p\": \"wv\", \"_w\": lb_id, \"_t\": \"P\", \"_s\": \"L\"\n","            }\n","\n","            try:\n","                resp_wards = session.post(URL_DETAILS, data=payload_wards, verify=False)\n","                wards_json = resp_wards.json()\n","                ward_lists = deep_search_for_list(wards_json, min_length=5)\n","\n","                if not ward_lists:\n","                    print(\"    -> No wards found.\")\n","                    continue\n","\n","                wards = max(ward_lists, key=len)\n","                print(f\"    -> Found {len(wards)} Wards. Fetching candidates for each...\")\n","\n","                # 5. DEEP DIVE: LOOP WARDS TO GET CANDIDATES (Level 4)\n","                for w in wards:\n","                    # w format from Level 3: [Party(Front), WardNum, WardName, ???, Votes, WinnerName]\n","                    # We need the Ward ID. It is usually composed of PanchayatID + WardNum\n","                    # e.g., if Panchayat is G10072 and Ward is 1, WardID is likely G10072001\n","\n","                    ward_num = str(w[2]).strip() # Assuming Ward Number is at index 2 (e.g. \"1\")\n","                    ward_name = str(w[5]).strip() # Assuming Name is at index 5\n","\n","                    # Construct Ward ID (Format: G10072 + 001)\n","                    try:\n","                        ward_id_suffix = f\"{int(ward_num):03d}\"\n","                        ward_full_id = f\"{lb_id}{ward_id_suffix}\"\n","                    except:\n","                        # Fallback if ward_num isn't a clean number\n","                        ward_full_id = f\"{lb_id}001\"\n","\n","                    # PAYLOAD FOR CANDIDATES (The one you found!)\n","                    payload_can = {\n","                        \"_p\": \"can\",        # Candidate View\n","                        \"_w\": ward_full_id, # Deep Ward ID\n","                        \"_t\": \"P\",\n","                        \"_s\": \"L\"\n","                    }\n","\n","                    try:\n","                        resp_can = session.post(URL_DETAILS, data=payload_can, verify=False)\n","                        can_json = resp_can.json()\n","\n","                        # Find candidate list\n","                        can_lists = deep_search_for_list(can_json, min_length=1)\n","\n","                        winner_party = \"Unknown\"\n","                        winner_name = \"Unknown\"\n","                        winner_votes = 0\n","                        front_affiliation = w[1] # \"UDF\" from the previous level\n","\n","                        if can_lists:\n","                            candidates = max(can_lists, key=len)\n","\n","                            # LOGIC: Find the candidate with the MAX votes\n","                            # Candidate Row Structure (from screenshot):\n","                            # 0: Party (INC) | 1: ? | 2: Name | ... | Last: Votes\n","\n","                            best_candidate = None\n","                            max_v = -1\n","\n","                            for can in candidates:\n","                                try:\n","                                    # Votes usually at the end. Let's look at the last column.\n","                                    votes = int(can[-1])\n","                                    if votes > max_v:\n","                                        max_v = votes\n","                                        best_candidate = can\n","                                except:\n","                                    pass\n","\n","                            if best_candidate:\n","                                winner_party = best_candidate[0] # The exact party! (INC, BJP)\n","                                winner_name = best_candidate[2]  # The name\n","                                winner_votes = max_v\n","\n","                        # Use data from Level 3 if Level 4 failed, or merge them\n","                        if winner_party == \"Unknown\":\n","                            winner_party = front_affiliation # Fallback to \"UDF\"\n","\n","                        master_data.append({\n","                            \"District\": \"Malappuram\",\n","                            \"Local Body\": lb_name,\n","                            \"Type\": \"Grama Panchayat\",\n","                            \"Ward\": f\"{ward_num} - {ward_name}\",\n","                            \"Candidate\": winner_name,\n","                            \"Party\": winner_party,   # Specific (INC)\n","                            \"Front\": front_affiliation, # Broad (UDF)\n","                            \"Votes\": winner_votes,\n","                            \"Year\": 2025\n","                        })\n","\n","                    except Exception as e:\n","                        # print(f\"Level 4 Error: {e}\")\n","                        pass\n","\n","                    # Be nice to the server!\n","                    time.sleep(0.05)\n","\n","            except Exception as e:\n","                print(f\"    Error processing {lb_name}: {e}\")\n","\n","    except Exception as e:\n","        print(f\"Global Error: {e}\")\n","\n","    # SAVE\n","    if master_data:\n","        df = pd.DataFrame(master_data)\n","        print(\"\\n--- SCRAPING SUCCESS ---\")\n","        print(df.head())\n","        # UTF-8-SIG for Malayalam support\n","        df.to_csv(\"Malappuram_2025_Detailed.csv\", index=False, encoding='utf-8-sig')\n","        print(f\"Saved {len(df)} rows to 'Malappuram_2025_Detailed.csv'\")\n","    else:\n","        print(\"No data collected.\")\n","\n","if __name__ == \"__main__\":\n","    scrape_kerala_2025_deep()"]},{"cell_type":"markdown","source":["DIAGNOSTIC: INSPECTING CANDIDATE DATA"],"metadata":{"id":"k_6dVM3u7oou"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1334,"status":"ok","timestamp":1766319670536,"user":{"displayName":"FARHAN JAFFAR","userId":"00674461129948116447"},"user_tz":-330},"id":"LWdcpi332x7l","outputId":"53c0da12-6541-4839-afe4-5a0fb0cb25ea"},"outputs":[{"name":"stdout","output_type":"stream","text":["--- DIAGNOSTIC: INSPECTING CANDIDATE DATA ---\n","Fetching data for Ward G10072001...\n","\n","[SUCCESS] Found list with 3 rows.\n","--- RAW ROW SAMPLE (Check this!) ---\n","['INC', 3, '', '\\u200d ', 622, 1, 'Y']\n","\n","--- SAMPLE DATAFRAME ---\n","     0  1 2                    3    4  5  6\n","0  INC  3        622  1  Y\n","1  IND  2       278  2  Y\n","2  BJP  1                  39  0  Y\n"]}],"source":["import requests\n","import urllib3\n","import json\n","import pandas as pd\n","\n","urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n","\n","URL_DETAILS = \"https://lbtrend.kerala.gov.in/includes/lb_ajax2.php\"\n","\n","HEADERS = {\n","    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36\",\n","    \"X-Requested-With\": \"XMLHttpRequest\",\n","    \"Referer\": \"https://lbtrend.kerala.gov.in/\"\n","}\n","\n","def inspect_candidate_view():\n","    print(\"--- DIAGNOSTIC: INSPECTING CANDIDATE DATA ---\")\n","    session = requests.Session()\n","    session.headers.update(HEADERS)\n","\n","    # Target: Abdurehman Nagar (G10072) -> Ward 1 (G10072001)\n","    # Using the exact keys from your screenshot\n","    payload = {\n","        \"_p\": \"can\",        # Candidate View\n","        \"_w\": \"G10072001\",  # Ward ID\n","        \"_t\": \"P\",\n","        \"_s\": \"L\"\n","    }\n","\n","    try:\n","        print(\"Fetching data for Ward G10072001...\")\n","        resp = session.post(URL_DETAILS, data=payload, verify=False)\n","        data = resp.json()\n","\n","        # SEARCH FOR THE LIST\n","        candidates = []\n","\n","        # Helper to find lists recursively\n","        def find_lists(d):\n","            found = []\n","            if isinstance(d, dict):\n","                for k, v in d.items():\n","                    if isinstance(v, list) and len(v) > 0: found.append(v)\n","                    elif isinstance(v, (dict, list)): found.extend(find_lists(v))\n","            elif isinstance(d, list):\n","                found.append(d)\n","            return found\n","\n","        all_lists = find_lists(data)\n","\n","        if all_lists:\n","            # The candidate list is likely the one with \"INC\" or \"LDF\" in it.\n","            # We print the first row of the longest list found.\n","            main_list = max(all_lists, key=len)\n","\n","            print(f\"\\n[SUCCESS] Found list with {len(main_list)} rows.\")\n","            print(\"--- RAW ROW SAMPLE (Check this!) ---\")\n","            print(main_list[0])\n","\n","            # create a sample dataframe to verify\n","            print(\"\\n--- SAMPLE DATAFRAME ---\")\n","            df = pd.DataFrame(main_list)\n","            print(df.head())\n","\n","        else:\n","            print(\"[ERROR] No list found in JSON.\")\n","            print(\"Keys:\", data.keys())\n","\n","    except Exception as e:\n","        print(f\"Error: {e}\")\n","\n","if __name__ == \"__main__\":\n","    inspect_candidate_view()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":562903,"status":"ok","timestamp":1766320307676,"user":{"displayName":"FARHAN JAFFAR","userId":"00674461129948116447"},"user_tz":-330},"id":"tqJje6-p3FBb","outputId":"0163dcbd-f799-42d0-e48d-2a2d8530b0c6"},"outputs":[{"name":"stdout","output_type":"stream","text":["--- Starting Final 2025 Deep Scraper ---\n","2. Fetching Panchayat List...\n","   -> Found 94 Panchayats.\n","[1/94] Abdurehman Nagar (G10072)\n","[2/94] Alamkode (G10096)\n","[3/94] Aliparamba (G10043)\n","[4/94] Amarambalam (G10026)\n","[5/94] Anakayam (G10037)\n","[6/94] Angadippuram (G10050)\n","[7/94] Areacode (G10029)\n","[8/94] Athavanad (G10057)\n","[9/94] Chaliyar (G10006)\n","[10/94] Cheacode (G10034)\n","[11/94] Chelembra (G10015)\n","[12/94] Cheriyamundam (G10066)\n","[13/94] Cherukavu (G10008)\n","[14/94] Chokkad (G10023)\n","[15/94] Chungathara (G10005)\n","[16/94] Edakkara (G10003)\n","[17/94] Edapatta (G10028)\n","[18/94] Edappal (G10094)\n","[19/94] Edarikkode (G10078)\n","[20/94] Edavanna (G10036)\n","[21/94] Edayur (G10058)\n","[22/94] Elamkulam (G10044)\n","[23/94] Irumbiliyum (G10059)\n","[24/94] Kalady (G10095)\n","[25/94] Kalikavu (G10022)\n","[26/94] Kalpakancheri (G10063)\n","[27/94] Kannamangalam (G10076)\n","[28/94] Karulai (G10027)\n","[29/94] Karuvarakundu (G10024)\n","[30/94] Kavannur (G10031)\n","[31/94] Keezhattur (G10046)\n","[32/94] Keezhuparamba (G10032)\n","[33/94] Kodur (G10042)\n","[34/94] Koottilangadi (G10052)\n","[35/94] Kuruva (G10051)\n","[36/94] Kuttippuram (G10061)\n","[37/94] Kuzhimanna (G10033)\n","[38/94] Makkaraparamba (G10055)\n","[39/94] Mampad (G10018)\n","[40/94] Mangalam (G10087)\n","[41/94] Mankada (G10056)\n","[42/94] Marakkara (G10060)\n","[43/94] Maranchery (G10097)\n","[44/94] Melattur (G10045)\n","[45/94] Moonniyur (G10081)\n","[46/94] Moorkanad (G10054)\n","[47/94] Moothedam (G10004)\n","[48/94] Morayur (G10038)\n","[49/94] Muthuvallur (G10014)\n","[50/94] Nannambra (G10080)\n","[51/94] Nannamukku (G10098)\n","[52/94] Niramaruthoor (G10068)\n","[53/94] Oorakam (G10077)\n","[54/94] Othukkungal (G10041)\n","[55/94] Ozhoor (G10067)\n","[56/94] Pallikkal (G10009)\n","[57/94] Pandikkad (G10020)\n","[58/94] Parappur (G10073)\n","[59/94] Perumanna Clari (G10071)\n","[60/94] Perumbadappu (G10099)\n","[61/94] Peruvallur (G10085)\n","[62/94] Ponmala (G10039)\n","[63/94] Ponmundam (G10065)\n","[64/94] Pookkottur (G10040)\n","[65/94] Porur (G10019)\n","[66/94] Pothukal (G10002)\n","[67/94] Pulamanthole (G10049)\n","[68/94] Pulikkal (G10012)\n","[69/94] Pulpetta (G10035)\n","[70/94] Purathur (G10086)\n","[71/94] Puzhakkatiri (G10053)\n","[72/94] Thalakkad (G10090)\n","[73/94] Thanalur (G10069)\n","[74/94] Thavanur (G10092)\n","[75/94] Thazhekkode (G10047)\n","[76/94] Thenhippalam (G10082)\n","[77/94] Thennela (G10074)\n","[78/94] Thirunavaya (G10091)\n","[79/94] Thiruvali (G10017)\n","[80/94] Thrikkalangode (G10021)\n","[81/94] Thriprangode (G10088)\n","[82/94] Thuvvur (G10025)\n","[83/94] Urangattiri (G10030)\n","[84/94] Valavannur (G10070)\n","[85/94] Vallikkunnu (G10084)\n","[86/94] Vattamkulam (G10093)\n","[87/94] Vazhakkad (G10011)\n","[88/94] Vazhayur (G10010)\n","[89/94] Vazhikkadavu (G10001)\n","[90/94] Veliyancode (G10100)\n","[91/94] Vengara (G10075)\n","[92/94] Vettathur (G10048)\n","[93/94] Vettom (G10089)\n","[94/94] Wandoor (G10016)\n","\n","--- SAMPLE DATA (First 5 Rows) ---\n","     District        Local Body             Type                  Ward  \\\n","0  Malappuram  Abdurehman Nagar  Grama Panchayat     3 - Valiyaparamba   \n","1  Malappuram  Abdurehman Nagar  Grama Panchayat  2 - Pukayoor Kunnath   \n","2  Malappuram  Abdurehman Nagar  Grama Panchayat          4 - Pukayoor   \n","3  Malappuram  Abdurehman Nagar  Grama Panchayat        5 - Kottamchal   \n","4  Malappuram  Abdurehman Nagar  Grama Panchayat      3 - Puthiyangadi   \n","\n","               Candidate Party Front  Votes  Year  \n","0        IUML   UDF    516  2025  \n","1              IUML   UDF    748  2025  \n","2     IUML   UDF    543  2025  \n","3                 .   INC   UDF    553  2025  \n","4        IUML   UDF    516  2025  \n","\n","Saved 2000 rows to Malappuram_2025_Final.csv\n"]}],"source":["import requests\n","import pandas as pd\n","import time\n","import urllib3\n","import json\n","\n","# 1. SETUP\n","urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n","\n","URL_HOME = \"https://lbtrend.kerala.gov.in/\"\n","URL_LIST = \"https://lbtrend.kerala.gov.in/includes/stateView2_ajax.php\"\n","URL_DETAILS = \"https://lbtrend.kerala.gov.in/includes/lb_ajax2.php\"\n","\n","HEADERS = {\n","    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36\",\n","    \"X-Requested-With\": \"XMLHttpRequest\",\n","    \"Referer\": \"https://lbtrend.kerala.gov.in/\"\n","}\n","\n","def deep_search_for_list(data, min_length=5):\n","    \"\"\"Recursively searches JSON for any list longer than min_length.\"\"\"\n","    candidates = []\n","    if isinstance(data, dict):\n","        for k, v in data.items():\n","            if isinstance(v, list) and len(v) >= min_length:\n","                candidates.append(v)\n","            elif isinstance(v, (dict, list)):\n","                candidates.extend(deep_search_for_list(v, min_length))\n","    elif isinstance(data, list):\n","        for item in data:\n","            if isinstance(item, (dict, list)):\n","                candidates.extend(deep_search_for_list(item, min_length))\n","    return candidates\n","\n","def scrape_kerala_2025_final():\n","    print(\"--- Starting Final 2025 Deep Scraper ---\")\n","    master_data = []\n","\n","    session = requests.Session()\n","    session.headers.update(HEADERS)\n","\n","    # 1. INIT SESSION\n","    try:\n","        session.get(URL_HOME, verify=False)\n","    except:\n","        pass\n","\n","    # 2. GET PANCHAYAT LIST (Malappuram)\n","    print(\"2. Fetching Panchayat List...\")\n","    payload_list = {\n","        \"_p\": \"dv\", \"_l\": \"P\", \"_d\": \"D10001\", \"_s\": \"L\"\n","    }\n","\n","    try:\n","        resp = session.post(URL_LIST, data=payload_list, verify=False)\n","        data_list = resp.json()\n","        found_lists = deep_search_for_list(data_list, min_length=50)\n","\n","        if not found_lists:\n","            print(\"[ERROR] Panchayat list not found.\")\n","            return\n","\n","        local_bodies = max(found_lists, key=len)\n","        print(f\"   -> Found {len(local_bodies)} Panchayats.\")\n","\n","        # 3. LOOP PANCHAYATS\n","        total_panchayats = len(local_bodies)\n","\n","        for i, item in enumerate(local_bodies):\n","            # Extract ID and Name\n","            lb_id = None\n","            lb_name = \"Unknown\"\n","            for col in item:\n","                s_col = str(col)\n","                if s_col.startswith(\"G1\"): lb_id = s_col\n","                elif len(s_col) > 3 and not s_col.startswith(\"G\") and not s_col.isdigit(): lb_name = s_col\n","\n","            if not lb_id: lb_id = item[0]\n","            if lb_name == \"Unknown\": lb_name = item[1]\n","\n","            print(f\"[{i+1}/{total_panchayats}] {lb_name} ({lb_id})\")\n","\n","            # 4. GET WARD LIST (Level 3)\n","            payload_wards = {\n","                \"_p\": \"wv\", \"_w\": lb_id, \"_t\": \"P\", \"_s\": \"L\"\n","            }\n","\n","            try:\n","                resp_wards = session.post(URL_DETAILS, data=payload_wards, verify=False)\n","                wards_json = resp_wards.json()\n","                ward_lists = deep_search_for_list(wards_json, min_length=5)\n","\n","                if not ward_lists:\n","                    print(\"    -> No wards found.\")\n","                    continue\n","\n","                wards = max(ward_lists, key=len)\n","\n","                # 5. DEEP DIVE: GET CANDIDATES (Level 4)\n","                for w in wards:\n","                    # w from Level 3: [Front, WardNum, WardName, ..., Votes, WinnerName]\n","                    # Indices vary, so we rely on your screenshot for WardNum/Name often being 2 and 5 (or 2 and 3)\n","                    # Safest bet: find the number\n","\n","                    ward_num = str(w[2]).strip()\n","                    ward_name = str(w[5]).strip() # Usually index 5 in Ward View\n","                    front_affiliation = w[1]      # This is the FRONT (UDF/LDF) from the summary view\n","\n","                    # Construct Ward ID for Deep Query (G10072 + 001)\n","                    try:\n","                        ward_id_suffix = f\"{int(ward_num):03d}\"\n","                        ward_full_id = f\"{lb_id}{ward_id_suffix}\"\n","                    except:\n","                        ward_full_id = f\"{lb_id}001\"\n","\n","                    # QUERY LEVEL 4 (The Candidate Table)\n","                    payload_can = {\n","                        \"_p\": \"can\", \"_w\": ward_full_id, \"_t\": \"P\", \"_s\": \"L\"\n","                    }\n","\n","                    try:\n","                        resp_can = session.post(URL_DETAILS, data=payload_can, verify=False)\n","                        can_json = resp_can.json()\n","                        can_lists = deep_search_for_list(can_json, min_length=1)\n","\n","                        winner_party = \"Unknown\"\n","                        winner_name = \"Unknown\"\n","                        winner_votes = 0\n","\n","                        if can_lists:\n","                            candidates = max(can_lists, key=len)\n","\n","                            # LOGIC: Find MAX votes\n","                            best_candidate = None\n","                            max_v = -1\n","\n","                            for can in candidates:\n","                                try:\n","                                    # USE DIAGNOSTIC INDICES HERE:\n","                                    # Index 4 is Votes (e.g., 622)\n","                                    votes = int(can[4])\n","                                    if votes > max_v:\n","                                        max_v = votes\n","                                        best_candidate = can\n","                                except:\n","                                    pass\n","\n","                            if best_candidate:\n","                                # USE DIAGNOSTIC INDICES HERE:\n","                                winner_party = best_candidate[0] # Index 0 = Party (INC)\n","                                winner_name = best_candidate[3]  # Index 3 = Name (Malayalam)\n","                                winner_votes = max_v\n","\n","                        master_data.append({\n","                            \"District\": \"Malappuram\",\n","                            \"Local Body\": lb_name,\n","                            \"Type\": \"Grama Panchayat\",\n","                            \"Ward\": f\"{ward_num} - {ward_name}\",\n","                            \"Candidate\": winner_name,\n","                            \"Party\": winner_party,      # Specific (INC)\n","                            \"Front\": front_affiliation, # Broad (UDF) - Carried over\n","                            \"Votes\": winner_votes,\n","                            \"Year\": 2025\n","                        })\n","\n","                    except Exception as e:\n","                        pass\n","\n","                    # Minimal sleep to keep it fast but safe\n","                    time.sleep(0.01)\n","\n","            except Exception as e:\n","                pass\n","\n","    except Exception as e:\n","        print(f\"Global Error: {e}\")\n","\n","    # SAVE AND VERIFY\n","    if master_data:\n","        df = pd.DataFrame(master_data)\n","        print(\"\\n--- SAMPLE DATA (First 5 Rows) ---\")\n","        print(df.head()) # <--- Verification before you celebrate\n","\n","        filename = \"Malappuram_2025_Final.csv\"\n","        df.to_csv(filename, index=False, encoding='utf-8-sig')\n","        print(f\"\\nSaved {len(df)} rows to {filename}\")\n","    else:\n","        print(\"No data collected.\")\n","\n","if __name__ == \"__main__\":\n","    scrape_kerala_2025_final()"]},{"cell_type":"markdown","source":["INSPECTING WARD LIST (Level 3)\n","Fetching Ward List for G10072"],"metadata":{"id":"dTA-zTgv8AfT"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1831,"status":"ok","timestamp":1766324414641,"user":{"displayName":"FARHAN JAFFAR","userId":"00674461129948116447"},"user_tz":-330},"id":"b4xLVnR2I4l_","outputId":"87e8338a-ef96-4eca-a8a2-7451626c7962"},"outputs":[{"name":"stdout","output_type":"stream","text":["--- INSPECTING WARD LIST (Level 3) ---\n","Fetching Ward List for G10072...\n","\n","[SUCCESS] Found list with 24 rows.\n","--- FIRST 3 ROWS (Look for '001', 'Valiyaparamba') ---\n","Row 0: ['G10072001', 'UDF', 3, '\\u200d ', 622, 'Valiyaparamba', 'Y', 2, '2 - \\u200d ', 278]\n","Row 1: ['G10072002', 'UDF', 2, ' ', 748, 'Pukayoor Kunnath', 'Y', 1, '1 -  ', 422]\n","Row 2: ['G10072003', 'UDF', 4, '   ', 516, 'Pukayoor', 'Y', 2, '2 -  ', 490]\n"]}],"source":["import requests\n","import urllib3\n","import json\n","\n","urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n","\n","URL_DETAILS = \"https://lbtrend.kerala.gov.in/includes/lb_ajax2.php\"\n","\n","HEADERS = {\n","    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36\",\n","    \"X-Requested-With\": \"XMLHttpRequest\",\n","    \"Referer\": \"https://lbtrend.kerala.gov.in/\"\n","}\n","\n","def inspect_ward_list():\n","    print(\"--- INSPECTING WARD LIST (Level 3) ---\")\n","    session = requests.Session()\n","    session.headers.update(HEADERS)\n","\n","    # Target: Abdurehman Nagar (G10072)\n","    payload = {\n","        \"_p\": \"wv\",\n","        \"_w\": \"G10072\",\n","        \"_t\": \"P\",\n","        \"_s\": \"L\"\n","    }\n","\n","    try:\n","        print(\"Fetching Ward List for G10072...\")\n","        resp = session.post(URL_DETAILS, data=payload, verify=False)\n","        data = resp.json()\n","\n","        # Helper to find lists\n","        def find_lists(d):\n","            found = []\n","            if isinstance(d, dict):\n","                for k, v in d.items():\n","                    if isinstance(v, list) and len(v) > 0: found.append(v)\n","                    elif isinstance(v, (dict, list)): found.extend(find_lists(v))\n","            elif isinstance(d, list):\n","                found.append(d)\n","            return found\n","\n","        all_lists = find_lists(data)\n","\n","        if all_lists:\n","            # The Ward list is the longest one\n","            main_list = max(all_lists, key=len)\n","\n","            print(f\"\\n[SUCCESS] Found list with {len(main_list)} rows.\")\n","            print(\"--- FIRST 3 ROWS (Look for '001', 'Valiyaparamba') ---\")\n","            for i, row in enumerate(main_list[:3]):\n","                print(f\"Row {i}: {row}\")\n","\n","        else:\n","            print(\"[ERROR] No list found.\")\n","\n","    except Exception as e:\n","        print(f\"Error: {e}\")\n","\n","if __name__ == \"__main__\":\n","    inspect_ward_list()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":470123,"status":"ok","timestamp":1766324982226,"user":{"displayName":"FARHAN JAFFAR","userId":"00674461129948116447"},"user_tz":-330},"id":"LkCRUY4pJQ31","outputId":"3e0e0f24-39b9-4c60-d33b-6408803db6ab"},"outputs":[{"name":"stdout","output_type":"stream","text":["--- Starting Corrected Malappuram 2025 Scraper ---\n","2. Fetching Panchayat List...\n","   -> Found 94 Panchayats.\n","[1/94] Abdurehman Nagar (G10072)\n","[2/94] Alamkode (G10096)\n","[3/94] Aliparamba (G10043)\n","[4/94] Amarambalam (G10026)\n","[5/94] Anakayam (G10037)\n","[6/94] Angadippuram (G10050)\n","[7/94] Areacode (G10029)\n","[8/94] Athavanad (G10057)\n","[9/94] Chaliyar (G10006)\n","[10/94] Cheacode (G10034)\n","[11/94] Chelembra (G10015)\n","[12/94] Cheriyamundam (G10066)\n","[13/94] Cherukavu (G10008)\n","[14/94] Chokkad (G10023)\n","[15/94] Chungathara (G10005)\n","[16/94] Edakkara (G10003)\n","[17/94] Edapatta (G10028)\n","[18/94] Edappal (G10094)\n","[19/94] Edarikkode (G10078)\n","[20/94] Edavanna (G10036)\n","[21/94] Edayur (G10058)\n","[22/94] Elamkulam (G10044)\n","[23/94] Irumbiliyum (G10059)\n","[24/94] Kalady (G10095)\n","[25/94] Kalikavu (G10022)\n","[26/94] Kalpakancheri (G10063)\n","[27/94] Kannamangalam (G10076)\n","[28/94] Karulai (G10027)\n","[29/94] Karuvarakundu (G10024)\n","[30/94] Kavannur (G10031)\n","[31/94] Keezhattur (G10046)\n","[32/94] Keezhuparamba (G10032)\n","[33/94] Kodur (G10042)\n","[34/94] Koottilangadi (G10052)\n","[35/94] Kuruva (G10051)\n","[36/94] Kuttippuram (G10061)\n","[37/94] Kuzhimanna (G10033)\n","[38/94] Makkaraparamba (G10055)\n","[39/94] Mampad (G10018)\n","[40/94] Mangalam (G10087)\n","[41/94] Mankada (G10056)\n","[42/94] Marakkara (G10060)\n","[43/94] Maranchery (G10097)\n","[44/94] Melattur (G10045)\n","[45/94] Moonniyur (G10081)\n","[46/94] Moorkanad (G10054)\n","[47/94] Moothedam (G10004)\n","[48/94] Morayur (G10038)\n","[49/94] Muthuvallur (G10014)\n","[50/94] Nannambra (G10080)\n","[51/94] Nannamukku (G10098)\n","[52/94] Niramaruthoor (G10068)\n","[53/94] Oorakam (G10077)\n","[54/94] Othukkungal (G10041)\n","[55/94] Ozhoor (G10067)\n","[56/94] Pallikkal (G10009)\n","[57/94] Pandikkad (G10020)\n","[58/94] Parappur (G10073)\n","[59/94] Perumanna Clari (G10071)\n","[60/94] Perumbadappu (G10099)\n","[61/94] Peruvallur (G10085)\n","[62/94] Ponmala (G10039)\n","[63/94] Ponmundam (G10065)\n","[64/94] Pookkottur (G10040)\n","[65/94] Porur (G10019)\n","[66/94] Pothukal (G10002)\n","[67/94] Pulamanthole (G10049)\n","[68/94] Pulikkal (G10012)\n","[69/94] Pulpetta (G10035)\n","[70/94] Purathur (G10086)\n","[71/94] Puzhakkatiri (G10053)\n","[72/94] Thalakkad (G10090)\n","[73/94] Thanalur (G10069)\n","[74/94] Thavanur (G10092)\n","[75/94] Thazhekkode (G10047)\n","[76/94] Thenhippalam (G10082)\n","[77/94] Thennela (G10074)\n","[78/94] Thirunavaya (G10091)\n","[79/94] Thiruvali (G10017)\n","[80/94] Thrikkalangode (G10021)\n","[81/94] Thriprangode (G10088)\n","[82/94] Thuvvur (G10025)\n","[83/94] Urangattiri (G10030)\n","[84/94] Valavannur (G10070)\n","[85/94] Vallikkunnu (G10084)\n","[86/94] Vattamkulam (G10093)\n","[87/94] Vazhakkad (G10011)\n","[88/94] Vazhayur (G10010)\n","[89/94] Vazhikkadavu (G10001)\n","[90/94] Veliyancode (G10100)\n","[91/94] Vengara (G10075)\n","[92/94] Vettathur (G10048)\n","[93/94] Vettom (G10089)\n","[94/94] Wandoor (G10016)\n","\n","--- SAMPLE DATA ---\n","     District        Local Body             Type                    Ward  \\\n","0  Malappuram  Abdurehman Nagar  Grama Panchayat     001 - Valiyaparamba   \n","1  Malappuram  Abdurehman Nagar  Grama Panchayat  002 - Pukayoor Kunnath   \n","2  Malappuram  Abdurehman Nagar  Grama Panchayat          003 - Pukayoor   \n","\n","              Candidate Party Front  Votes  Year  \n","0        INC   UDF    622  2025  \n","1             IUML   UDF    748  2025  \n","2       IUML   UDF    516  2025  \n","\n","Saved 2000 rows to Malappuram_2025_Final_Corrected.csv\n"]}],"source":["import requests\n","import pandas as pd\n","import time\n","import urllib3\n","import json\n","\n","# 1. SETUP\n","urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n","\n","URL_HOME = \"https://lbtrend.kerala.gov.in/\"\n","URL_LIST = \"https://lbtrend.kerala.gov.in/includes/stateView2_ajax.php\"\n","URL_DETAILS = \"https://lbtrend.kerala.gov.in/includes/lb_ajax2.php\"\n","\n","HEADERS = {\n","    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36\",\n","    \"X-Requested-With\": \"XMLHttpRequest\",\n","    \"Referer\": \"https://lbtrend.kerala.gov.in/\"\n","}\n","\n","def deep_search_for_list(data, min_length=5):\n","    \"\"\"Recursively searches JSON for any list longer than min_length.\"\"\"\n","    candidates = []\n","    if isinstance(data, dict):\n","        for k, v in data.items():\n","            if isinstance(v, list) and len(v) >= min_length:\n","                candidates.append(v)\n","            elif isinstance(v, (dict, list)):\n","                candidates.extend(deep_search_for_list(v, min_length))\n","    elif isinstance(data, list):\n","        for item in data:\n","            if isinstance(item, (dict, list)):\n","                candidates.extend(deep_search_for_list(item, min_length))\n","    return candidates\n","\n","def scrape_kerala_2025_fixed():\n","    print(\"--- Starting Corrected Malappuram 2025 Scraper ---\")\n","    master_data = []\n","\n","    session = requests.Session()\n","    session.headers.update(HEADERS)\n","\n","    # 1. INIT SESSION\n","    try:\n","        session.get(URL_HOME, verify=False)\n","    except:\n","        pass\n","\n","    # 2. GET PANCHAYAT LIST\n","    print(\"2. Fetching Panchayat List...\")\n","    payload_list = {\n","        \"_p\": \"dv\", \"_l\": \"P\", \"_d\": \"D10001\", \"_s\": \"L\"\n","    }\n","\n","    try:\n","        resp = session.post(URL_LIST, data=payload_list, verify=False)\n","        data_list = resp.json()\n","        found_lists = deep_search_for_list(data_list, min_length=50)\n","\n","        if not found_lists:\n","            print(\"[ERROR] Panchayat list not found.\")\n","            return\n","\n","        local_bodies = max(found_lists, key=len)\n","        print(f\"   -> Found {len(local_bodies)} Panchayats.\")\n","\n","        # 3. LOOP PANCHAYATS\n","        total_panchayats = len(local_bodies)\n","\n","        for i, item in enumerate(local_bodies):\n","            # Extract Panchayat ID\n","            lb_id = None\n","            lb_name = \"Unknown\"\n","            for col in item:\n","                s_col = str(col)\n","                if s_col.startswith(\"G1\"): lb_id = s_col\n","                elif len(s_col) > 3 and not s_col.startswith(\"G\") and not s_col.isdigit(): lb_name = s_col\n","\n","            if not lb_id: lb_id = item[0]\n","            if lb_name == \"Unknown\": lb_name = item[1]\n","\n","            print(f\"[{i+1}/{total_panchayats}] {lb_name} ({lb_id})\")\n","\n","            # 4. GET WARD LIST (Level 3)\n","            payload_wards = {\n","                \"_p\": \"wv\", \"_w\": lb_id, \"_t\": \"P\", \"_s\": \"L\"\n","            }\n","\n","            try:\n","                resp_wards = session.post(URL_DETAILS, data=payload_wards, verify=False)\n","                wards_json = resp_wards.json()\n","                ward_lists = deep_search_for_list(wards_json, min_length=5)\n","\n","                if not ward_lists:\n","                    continue\n","\n","                wards = max(ward_lists, key=len)\n","\n","                # 5. LOOP WARDS (Deep Dive)\n","                for w in wards:\n","                    # CORRECT MAPPING BASED ON YOUR RAW DATA:\n","                    # Index 0: Ward ID (G10072001) -> Contains the Ward Number!\n","                    # Index 1: Front (UDF)\n","                    # Index 5: Ward Name (Valiyaparamba)\n","\n","                    ward_full_id = str(w[0])\n","                    front_affiliation = w[1]\n","                    ward_name = w[5]\n","\n","                    # Extract Ward Number (Last 3 digits of ID)\n","                    ward_num = ward_full_id[-3:]\n","\n","                    # QUERY CANDIDATE VIEW (Level 4)\n","                    payload_can = {\n","                        \"_p\": \"can\", \"_w\": ward_full_id, \"_t\": \"P\", \"_s\": \"L\"\n","                    }\n","\n","                    try:\n","                        resp_can = session.post(URL_DETAILS, data=payload_can, verify=False)\n","                        can_json = resp_can.json()\n","                        can_lists = deep_search_for_list(can_json, min_length=1)\n","\n","                        winner_party = \"Unknown\"\n","                        winner_name = \"Unknown\"\n","                        winner_votes = 0\n","\n","                        if can_lists:\n","                            candidates = max(can_lists, key=len)\n","\n","                            # Find winner (Max Votes)\n","                            best_candidate = None\n","                            max_v = -1\n","\n","                            for can in candidates:\n","                                try:\n","                                    # Level 4 Mapping (Diagnostic):\n","                                    # Index 0: Party (INC)\n","                                    # Index 3: Name (Malayalam)\n","                                    # Index 4: Votes\n","                                    votes = int(can[4])\n","                                    if votes > max_v:\n","                                        max_v = votes\n","                                        best_candidate = can\n","                                except:\n","                                    pass\n","\n","                            if best_candidate:\n","                                winner_party = best_candidate[0] # Specific Party (INC)\n","                                winner_name = best_candidate[3]  # Name\n","                                winner_votes = max_v\n","\n","                        # Fallback for Party if Level 4 failed\n","                        if winner_party == \"Unknown\": winner_party = front_affiliation\n","\n","                        master_data.append({\n","                            \"District\": \"Malappuram\",\n","                            \"Local Body\": lb_name,\n","                            \"Type\": \"Grama Panchayat\",\n","                            \"Ward\": f\"{ward_num} - {ward_name}\",\n","                            \"Candidate\": winner_name,\n","                            \"Party\": winner_party,      # INC/IUML\n","                            \"Front\": front_affiliation, # UDF/LDF\n","                            \"Votes\": winner_votes,\n","                            \"Year\": 2025\n","                        })\n","\n","                    except Exception:\n","                        pass\n","\n","                    time.sleep(0.01) # Be polite\n","\n","            except Exception:\n","                pass\n","\n","    except Exception as e:\n","        print(f\"Global Error: {e}\")\n","\n","    # SAVE\n","    if master_data:\n","        df = pd.DataFrame(master_data)\n","        print(\"\\n--- SAMPLE DATA ---\")\n","        print(df.head(3))\n","\n","        filename = \"Malappuram_2025_Final_Corrected.csv\"\n","        df.to_csv(filename, index=False, encoding='utf-8-sig')\n","        print(f\"\\nSaved {len(df)} rows to {filename}\")\n","    else:\n","        print(\"No data collected.\")\n","\n","if __name__ == \"__main__\":\n","    scrape_kerala_2025_fixed()"]},{"cell_type":"markdown","source":["VERIFYING LOCAL BODY TYPE CODES"],"metadata":{"id":"W0jRr8LF8Inv"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1775,"status":"ok","timestamp":1766326144598,"user":{"displayName":"FARHAN JAFFAR","userId":"00674461129948116447"},"user_tz":-330},"id":"qrW-jY-oPfpb","outputId":"544656ab-8b8e-46fd-9f14-367ad52752b7"},"outputs":[{"name":"stdout","output_type":"stream","text":["--- VERIFYING LOCAL BODY TYPE CODES ---\n","\n","Testing Code: 'P' (Grama Panchayat (Control))\n","   [SUCCESS] Found 94 items.\n","   First Item Raw: ['G10072', 'Abdurehman Nagar', 24, '13', '22', '0', '0', '2', '0']\n","\n","Testing Code: 'B' (Block Panchayat (Testing...))\n","   [SUCCESS] Found 15 items.\n","   First Item Raw: ['B10109', 'Areacode', 19, '10', '18', '0', '0', '1', '0']\n","\n","Testing Code: 'D' (District Panchayat (Testing...))\n","   [SUCCESS] Found 5 items.\n","   First Item Raw: ['D10001', 'MALAPPURAM', 'LDF', 4, 1, 0, 1, 0, 6]\n","\n","Testing Code: 'M' (Municipality (Testing...))\n","   [ERROR] Failed: Expecting value: line 8 column 1 (char 7)\n","\n","Testing Code: 'C' (Corporation (Testing...))\n","   [SUCCESS] Found 12 items.\n","   First Item Raw: ['M10088', 'Kondotty', 41, '21', '31', '2', '0', '8', '0']\n"]}],"source":["import requests\n","import urllib3\n","import json\n","\n","urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n","\n","URL_LIST = \"https://lbtrend.kerala.gov.in/includes/stateView2_ajax.php\"\n","\n","HEADERS = {\n","    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36\",\n","    \"X-Requested-With\": \"XMLHttpRequest\",\n","    \"Referer\": \"https://lbtrend.kerala.gov.in/\"\n","}\n","\n","def deep_search_for_list(data, min_length=1):\n","    \"\"\"Finds list of local bodies inside the JSON\"\"\"\n","    candidates = []\n","    if isinstance(data, dict):\n","        for k, v in data.items():\n","            if isinstance(v, list) and len(v) >= min_length:\n","                candidates.append(v)\n","            elif isinstance(v, (dict, list)):\n","                candidates.extend(deep_search_for_list(v, min_length))\n","    elif isinstance(data, list):\n","        for item in data:\n","            if isinstance(item, (dict, list)):\n","                candidates.extend(deep_search_for_list(item, min_length))\n","    return candidates\n","\n","def verify_type_codes():\n","    print(\"--- VERIFYING LOCAL BODY TYPE CODES ---\")\n","    session = requests.Session()\n","    session.headers.update(HEADERS)\n","\n","    # Codes we want to verify\n","    test_codes = {\n","        \"P\": \"Grama Panchayat (Control)\",\n","        \"B\": \"Block Panchayat (Testing...)\",\n","        \"D\": \"District Panchayat (Testing...)\",\n","        \"M\": \"Municipality (Testing...)\",\n","        \"C\": \"Corporation (Testing...)\"\n","    }\n","\n","    # We use Malappuram (D10001) for testing\n","    district_code = \"D10001\"\n","\n","    for code, desc in test_codes.items():\n","        print(f\"\\nTesting Code: '{code}' ({desc})\")\n","\n","        payload = {\n","            \"_p\": \"dv\",\n","            \"_l\": code,  # <--- Changing this\n","            \"_d\": district_code,\n","            \"_s\": \"L\"\n","        }\n","\n","        try:\n","            resp = session.post(URL_LIST, data=payload, verify=False)\n","            data = resp.json()\n","\n","            # Find the list of bodies\n","            found_lists = deep_search_for_list(data, min_length=1)\n","\n","            if found_lists:\n","                # Get the longest list (usually the main list of bodies)\n","                main_list = max(found_lists, key=len)\n","                count = len(main_list)\n","\n","                # Get first item name (usually Index 1, but we print raw to be sure)\n","                first_item = main_list[0]\n","\n","                print(f\"   [SUCCESS] Found {count} items.\")\n","                print(f\"   First Item Raw: {first_item}\")\n","\n","                # Heuristic Check\n","                name_sample = str(first_item)\n","                if \"Malappuram\" in name_sample and code == \"D\":\n","                    print(\"   -> CONFIRMED: This is District Panchayat data.\")\n","                elif \"Vengara\" in name_sample and code == \"B\":\n","                    # Vengara is a block, so if it appears here, B is likely Block\n","                    print(\"   -> LOOKS GOOD: 'Vengara' found in list.\")\n","            else:\n","                print(\"   [EMPTY] Server returned valid JSON but no list found.\")\n","                print(\"   Keys:\", data.keys())\n","\n","        except Exception as e:\n","            print(f\"   [ERROR] Failed: {e}\")\n","\n","if __name__ == \"__main__\":\n","    verify_type_codes()"]},{"cell_type":"markdown","source":["Starting MASTER Scraper (Block, Muni, District)"],"metadata":{"id":"_1ypZOOh8UKl"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":182910,"status":"ok","timestamp":1766326635895,"user":{"displayName":"FARHAN JAFFAR","userId":"00674461129948116447"},"user_tz":-330},"id":"eGQ2D-VOQojP","outputId":"2c9caa1a-0503-4dfe-ea13-ca5517711ae9"},"outputs":[{"name":"stdout","output_type":"stream","text":["--- Starting MASTER Scraper (Block, Muni, District) ---\n","\n",">>> STARTING: Block Panchayat (Blocks) <<<\n","   -> Found 15 Blocks.\n","   [1/15] Processing: Areacode (B10109)\n","   [2/15] Processing: Kalikavu (B10108)\n","   [3/15] Processing: Kondotty (B10106)\n","   [4/15] Processing: Kuttipuram (B10113)\n","   [5/15] Processing: Malappuram (B10110)\n","   [6/15] Processing: Mankada (B10112)\n","   [7/15] Processing: Nilambur (B10105)\n","   [8/15] Processing: Perinthalmanna (B10111)\n","   [9/15] Processing: Perumpadappu (B10119)\n","   [10/15] Processing: Ponnani (B10118)\n","   [11/15] Processing: Tanur (B10114)\n","   [12/15] Processing: Tirur (B10117)\n","   [13/15] Processing: Tirurangadi (B10116)\n","   [14/15] Processing: Vengara (B10115)\n","   [15/15] Processing: Wandoor (B10107)\n","\n",">>> STARTING: Municipality (Municipalities) <<<\n","   -> Found 12 Municipalities.\n","   [1/12] Processing: Kondotty (M10088)\n","   [2/12] Processing: Kottakkal (M10047)\n","   [3/12] Processing: Malappuram (M10045)\n","   [4/12] Processing: Manjeri (M10046)\n","   [5/12] Processing: Nilambur (M10048)\n","   [6/12] Processing: Parappanangadi (M10073)\n","   [7/12] Processing: Perinthalmanna (M10044)\n","   [8/12] Processing: Ponnani (M10042)\n","   [9/12] Processing: Thanoor (M10072)\n","   [10/12] Processing: Tirur (M10043)\n","   [11/12] Processing: Tirurangadi (M10075)\n","   [12/12] Processing: Valanchery (M10074)\n","\n",">>> STARTING: District Panchayat (District Body) <<<\n","   -> Target: Malappuram District Panchayat (D10001)\n","   [1/1] Processing: Malappuram District Panchayat (D10001)\n","\n","--- SCRAPING COMPLETE ---\n","     District  Local Body Type Local Body               Ward  \\\n","0  Malappuram  Block Panchayat   Areacode  1 - Keezhuparamba   \n","1  Malappuram  Block Panchayat   Areacode   2 - Pathanapuram   \n","2  Malappuram  Block Panchayat   Areacode    3 - Vettilapara   \n","3  Malappuram  Block Panchayat   Areacode        4 - Maithra   \n","4  Malappuram  Block Panchayat   Areacode   5 - Poovathikkal   \n","\n","                             Candidate Party Front  Votes  Year  \n","0                ..    INC   UDF   5775  2025  \n","1                      IUML   UDF   4813  2025  \n","2                              INC   UDF   4754  2025  \n","3       IUML   UDF   5596  2025  \n","4                  ..   IUML   UDF   5714  2025  \n","Saved 788 rows to Malappuram_All_LocalBodies_2025.csv\n"]}],"source":["import requests\n","import pandas as pd\n","import time\n","import urllib3\n","import json\n","\n","# 1. SETUP\n","urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n","\n","URL_HOME = \"https://lbtrend.kerala.gov.in/\"\n","URL_LIST = \"https://lbtrend.kerala.gov.in/includes/stateView2_ajax.php\"\n","URL_DETAILS = \"https://lbtrend.kerala.gov.in/includes/lb_ajax2.php\"\n","\n","HEADERS = {\n","    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36\",\n","    \"X-Requested-With\": \"XMLHttpRequest\",\n","    \"Referer\": \"https://lbtrend.kerala.gov.in/\"\n","}\n","\n","def deep_search_for_list(data, min_length=1):\n","    \"\"\"Recursively searches JSON for any list longer than min_length.\"\"\"\n","    candidates = []\n","    if isinstance(data, dict):\n","        for k, v in data.items():\n","            if isinstance(v, list) and len(v) >= min_length:\n","                candidates.append(v)\n","            elif isinstance(v, (dict, list)):\n","                candidates.extend(deep_search_for_list(v, min_length))\n","    elif isinstance(data, list):\n","        for item in data:\n","            if isinstance(item, (dict, list)):\n","                candidates.extend(deep_search_for_list(item, min_length))\n","    return candidates\n","\n","def get_candidates_level_4(session, ward_full_id, front_affiliation):\n","    \"\"\"Helper to fetch candidate details (Level 4)\"\"\"\n","    payload_can = {\n","        \"_p\": \"can\", \"_w\": ward_full_id, \"_t\": \"P\", \"_s\": \"L\"\n","    }\n","    try:\n","        resp_can = session.post(URL_DETAILS, data=payload_can, verify=False)\n","        can_json = resp_can.json()\n","        can_lists = deep_search_for_list(can_json, min_length=1)\n","\n","        if can_lists:\n","            candidates = max(can_lists, key=len)\n","\n","            # Logic: Find MAX votes\n","            best_candidate = None\n","            max_v = -1\n","\n","            for can in candidates:\n","                try:\n","                    # Index 4 is Votes (validated in diagnostics)\n","                    votes = int(can[4])\n","                    if votes > max_v:\n","                        max_v = votes\n","                        best_candidate = can\n","                except:\n","                    pass\n","\n","            if best_candidate:\n","                # Index 0: Party, Index 3: Name\n","                return best_candidate[0], best_candidate[3], max_v\n","    except:\n","        pass\n","\n","    return \"Unknown\", \"Unknown\", 0\n","\n","def scrape_kerala_master_2025():\n","    print(\"--- Starting MASTER Scraper (Block, Muni, District) ---\")\n","    master_data = []\n","\n","    session = requests.Session()\n","    session.headers.update(HEADERS)\n","\n","    # Init Session\n","    try:\n","        session.get(URL_HOME, verify=False)\n","    except:\n","        pass\n","\n","    # --- CONFIGURATION FOR LOOP ---\n","    # We map the \"Server Code\" to our \"Readable Type\"\n","    # Note: We use 'C' for Municipality because that's where the server put them.\n","    TASKS = [\n","        {\"code\": \"B\", \"type\": \"Block Panchayat\", \"desc\": \"Blocks\"},\n","        {\"code\": \"C\", \"type\": \"Municipality\", \"desc\": \"Municipalities\"},\n","        {\"code\": \"D\", \"type\": \"District Panchayat\", \"desc\": \"District Body\"} # Special handling\n","    ]\n","\n","    for task in TASKS:\n","        type_code = task['code']\n","        type_name = task['type']\n","        print(f\"\\n>>> STARTING: {type_name} ({task['desc']}) <<<\")\n","\n","        local_bodies = []\n","\n","        # STEP A: GET LIST OF BODIES\n","        if type_code == \"D\":\n","            # Special Case: District Panchayat is just ONE item (Malappuram)\n","            # We construct it manually to match the list format\n","            local_bodies = [['D10001', 'Malappuram District Panchayat']]\n","            print(\"   -> Target: Malappuram District Panchayat (D10001)\")\n","\n","        else:\n","            # Normal Case: Fetch List\n","            payload_list = {\n","                \"_p\": \"dv\", \"_l\": type_code, \"_d\": \"D10001\", \"_s\": \"L\"\n","            }\n","            try:\n","                resp = session.post(URL_LIST, data=payload_list, verify=False)\n","                data_list = resp.json()\n","                found_lists = deep_search_for_list(data_list, min_length=5)\n","                if found_lists:\n","                    local_bodies = max(found_lists, key=len)\n","                    print(f\"   -> Found {len(local_bodies)} {task['desc']}.\")\n","                else:\n","                    print(f\"   [ERROR] No list found for {type_name}. Skipping.\")\n","                    continue\n","            except Exception as e:\n","                print(f\"   [ERROR] Network failed for {type_name}: {e}\")\n","                continue\n","\n","        # STEP B: LOOP THROUGH BODIES\n","        total_bodies = len(local_bodies)\n","        for i, item in enumerate(local_bodies):\n","            # Extract ID/Name\n","            lb_id = None\n","            lb_name = \"Unknown\"\n","\n","            # Robust ID extraction\n","            for col in item:\n","                s_col = str(col)\n","                # IDs start with B (Block), M (Muni), D (District)\n","                if len(s_col) > 4 and (s_col.startswith(\"B1\") or s_col.startswith(\"M1\") or s_col.startswith(\"D1\")):\n","                    lb_id = s_col\n","                elif len(s_col) > 3 and not any(c.isdigit() for c in s_col):\n","                    lb_name = s_col\n","\n","            # Fallback\n","            if not lb_id: lb_id = item[0]\n","            if lb_name == \"Unknown\": lb_name = item[1]\n","\n","            print(f\"   [{i+1}/{total_bodies}] Processing: {lb_name} ({lb_id})\")\n","\n","            # STEP C: GET WARDS/DIVISIONS\n","            payload_wards = {\n","                \"_p\": \"wv\", \"_w\": lb_id, \"_t\": \"P\", \"_s\": \"L\"\n","            }\n","\n","            try:\n","                resp_wards = session.post(URL_DETAILS, data=payload_wards, verify=False)\n","                wards_json = resp_wards.json()\n","                ward_lists = deep_search_for_list(wards_json, min_length=3) # Min 3 items\n","\n","                if not ward_lists:\n","                    print(\"      No wards/divisions found.\")\n","                    continue\n","\n","                wards = max(ward_lists, key=len)\n","\n","                # STEP D: LOOP WARDS (DEEP DIVE)\n","                for w in wards:\n","                    # Index 0: Ward ID, Index 1: Front, Index 5: Name\n","                    ward_full_id = str(w[0])\n","                    front_affiliation = w[1]\n","                    ward_name = w[5]\n","\n","                    # Extract Ward/Division Number (Last 3 digits)\n","                    try:\n","                         ward_num = str(int(ward_full_id[-3:]))\n","                    except:\n","                         ward_num = \"0\"\n","\n","                    # Get Level 4 Data (Candidate)\n","                    winner_party, winner_name, winner_votes = get_candidates_level_4(session, ward_full_id, front_affiliation)\n","\n","                    # Fallback\n","                    if winner_party == \"Unknown\": winner_party = front_affiliation\n","\n","                    master_data.append({\n","                        \"District\": \"Malappuram\",\n","                        \"Local Body Type\": type_name, # \"Block\", \"Municipality\", etc.\n","                        \"Local Body\": lb_name,\n","                        \"Ward\": f\"{ward_num} - {ward_name}\",\n","                        \"Candidate\": winner_name,\n","                        \"Party\": winner_party,\n","                        \"Front\": front_affiliation,\n","                        \"Votes\": winner_votes,\n","                        \"Year\": 2025\n","                    })\n","\n","                    # Tiny sleep\n","                    time.sleep(0.01)\n","\n","            except Exception as e:\n","                # print(f\"      Error: {e}\")\n","                pass\n","\n","            # Save partial progress every 5 bodies\n","            if (i+1) % 5 == 0:\n","                pd.DataFrame(master_data).to_csv(\"Malappuram_Partial_Progress.csv\", index=False, encoding='utf-8-sig')\n","\n","    # FINAL SAVE\n","    if master_data:\n","        df = pd.DataFrame(master_data)\n","        print(\"\\n--- SCRAPING COMPLETE ---\")\n","        print(df.head())\n","        filename = \"Malappuram_All_LocalBodies_2025.csv\"\n","        df.to_csv(filename, index=False, encoding='utf-8-sig')\n","        print(f\"Saved {len(df)} rows to {filename}\")\n","    else:\n","        print(\"No data collected.\")\n","\n","if __name__ == \"__main__\":\n","    scrape_kerala_master_2025()"]},{"cell_type":"markdown","source":["STARTING UNIVERSAL KERALA ELECTION SCRAPER 2025"],"metadata":{"id":"GXx948fC8b6_"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5029855,"status":"ok","timestamp":1766332838328,"user":{"displayName":"FARHAN JAFFAR","userId":"00674461129948116447"},"user_tz":-330},"id":"4Vveg8upV0o6","outputId":"97233272-fd1b-46ad-867e-6059bf4d5303"},"outputs":[{"name":"stdout","output_type":"stream","text":["--- STARTING UNIVERSAL KERALA ELECTION SCRAPER 2025 ---\n","1. Session Initialized.\n","\n","==================================================\n","PROCESSING DISTRICT: Thiruvananthapuram (01)\n","==================================================\n","\n","   >>> Scanning Type: Grama Panchayat ('P')\n","      -> Found 73 unique bodies.\n","\n","      -> Finished Grama Panchayat\n","\n","   >>> Scanning Type: Block Panchayat ('B')\n","      -> Found 11 unique bodies.\n","\n","      -> Finished Block Panchayat\n","\n","   >>> Scanning Type: District Panchayat ('D')\n","      -> Found 1 unique bodies.\n","\n","      -> Finished District Panchayat\n","\n","   >>> Scanning Type: Municipality/Corporation ('C')\n","      -> Found 1 unique bodies.\n","\n","      -> Finished Municipality/Corporation\n","\n","[SAVED] Kerala_01_Thiruvananthapuram_2025.csv with 1611 rows.\n","\n","==================================================\n","PROCESSING DISTRICT: Kollam (02)\n","==================================================\n","\n","   >>> Scanning Type: Grama Panchayat ('P')\n","      -> Found 68 unique bodies.\n","\n","      -> Finished Grama Panchayat\n","\n","   >>> Scanning Type: Block Panchayat ('B')\n","      -> Found 11 unique bodies.\n","\n","      -> Finished Block Panchayat\n","\n","   >>> Scanning Type: District Panchayat ('D')\n","      -> Found 1 unique bodies.\n","\n","      -> Finished District Panchayat\n","\n","   >>> Scanning Type: Municipality/Corporation ('C')\n","      -> Found 1 unique bodies.\n","\n","      -> Finished Municipality/Corporation\n","\n","[SAVED] Kerala_02_Kollam_2025.csv with 1534 rows.\n","\n","==================================================\n","PROCESSING DISTRICT: Pathanamthitta (03)\n","==================================================\n","\n","   >>> Scanning Type: Grama Panchayat ('P')\n","      -> Found 53 unique bodies.\n","\n","      -> Finished Grama Panchayat\n","\n","   >>> Scanning Type: Block Panchayat ('B')\n","      -> Found 8 unique bodies.\n","\n","      -> Finished Block Panchayat\n","\n","   >>> Scanning Type: District Panchayat ('D')\n","      -> Found 1 unique bodies.\n","\n","      -> Finished District Panchayat\n","\n","   >>> Scanning Type: Municipality/Corporation ('C')\n","      -> Found 1 unique bodies.\n","\n","      -> Finished Municipality/Corporation\n","\n","[SAVED] Kerala_03_Pathanamthitta_2025.csv with 981 rows.\n","\n","==================================================\n","PROCESSING DISTRICT: Alappuzha (04)\n","==================================================\n","\n","   >>> Scanning Type: Grama Panchayat ('P')\n","      -> Found 72 unique bodies.\n","\n","      -> Finished Grama Panchayat\n","\n","   >>> Scanning Type: Block Panchayat ('B')\n","      -> Found 12 unique bodies.\n","\n","      -> Finished Block Panchayat\n","\n","   >>> Scanning Type: District Panchayat ('D')\n","      -> Found 1 unique bodies.\n","\n","      -> Finished District Panchayat\n","\n","   >>> Scanning Type: Municipality/Corporation ('C')\n","      -> Found 6 unique bodies.\n","\n","      -> Finished Municipality/Corporation\n","\n","[SAVED] Kerala_04_Alappuzha_2025.csv with 1666 rows.\n","\n","==================================================\n","PROCESSING DISTRICT: Kottayam (05)\n","==================================================\n","\n","   >>> Scanning Type: Grama Panchayat ('P')\n","      -> Found 71 unique bodies.\n","\n","      -> Finished Grama Panchayat\n","\n","   >>> Scanning Type: Block Panchayat ('B')\n","      -> Found 11 unique bodies.\n","\n","      -> Finished Block Panchayat\n","\n","   >>> Scanning Type: District Panchayat ('D')\n","      -> Found 1 unique bodies.\n","\n","      -> Finished District Panchayat\n","\n","   >>> Scanning Type: Municipality/Corporation ('C')\n","      -> Found 6 unique bodies.\n","\n","      -> Finished Municipality/Corporation\n","\n","[SAVED] Kerala_05_Kottayam_2025.csv with 1611 rows.\n","\n","==================================================\n","PROCESSING DISTRICT: Idukki (06)\n","==================================================\n","\n","   >>> Scanning Type: Grama Panchayat ('P')\n","      -> Found 52 unique bodies.\n","\n","      -> Finished Grama Panchayat\n","\n","   >>> Scanning Type: Block Panchayat ('B')\n","      -> Found 8 unique bodies.\n","\n","      -> Finished Block Panchayat\n","\n","   >>> Scanning Type: District Panchayat ('D')\n","      -> Found 1 unique bodies.\n","\n","      -> Finished District Panchayat\n","\n","   >>> Scanning Type: Municipality/Corporation ('C')\n","      -> Found 1 unique bodies.\n","\n","      -> Finished Municipality/Corporation\n","\n","[SAVED] Kerala_06_Idukki_2025.csv with 980 rows.\n","\n","==================================================\n","PROCESSING DISTRICT: Ernakulam (07)\n","==================================================\n","\n","   >>> Scanning Type: Grama Panchayat ('P')\n","      -> Found 82 unique bodies.\n","\n","      -> Finished Grama Panchayat\n","\n","   >>> Scanning Type: Block Panchayat ('B')\n","      -> Found 14 unique bodies.\n","\n","      -> Finished Block Panchayat\n","\n","   >>> Scanning Type: District Panchayat ('D')\n","      -> Found 1 unique bodies.\n","\n","      -> Finished District Panchayat\n","\n","   >>> Scanning Type: Municipality/Corporation ('C')\n","      -> Found 14 unique bodies.\n","\n","      -> Finished Municipality/Corporation\n","\n","[SAVED] Kerala_07_Ernakulam_2025.csv with 2219 rows.\n","\n","==================================================\n","PROCESSING DISTRICT: Thrissur (08)\n","==================================================\n","\n","   >>> Scanning Type: Grama Panchayat ('P')\n","      -> Found 86 unique bodies.\n","\n","      -> Finished Grama Panchayat\n","\n","   >>> Scanning Type: Block Panchayat ('B')\n","      -> Found 16 unique bodies.\n","\n","      -> Finished Block Panchayat\n","\n","   >>> Scanning Type: District Panchayat ('D')\n","      -> Found 1 unique bodies.\n","\n","      -> Finished District Panchayat\n","\n","   >>> Scanning Type: Municipality/Corporation ('C')\n","      -> Found 8 unique bodies.\n","\n","      -> Finished Municipality/Corporation\n","\n","[SAVED] Kerala_08_Thrissur_2025.csv with 2204 rows.\n","\n","==================================================\n","PROCESSING DISTRICT: Palakkad (09)\n","==================================================\n","\n","   >>> Scanning Type: Grama Panchayat ('P')\n","      -> Found 88 unique bodies.\n","\n","      -> Finished Grama Panchayat\n","\n","   >>> Scanning Type: Block Panchayat ('B')\n","      -> Found 13 unique bodies.\n","\n","      -> Finished Block Panchayat\n","\n","   >>> Scanning Type: District Panchayat ('D')\n","      -> Found 1 unique bodies.\n","\n","      -> Finished District Panchayat\n","\n","   >>> Scanning Type: Municipality/Corporation ('C')\n","      -> Found 7 unique bodies.\n","\n","      -> Finished Municipality/Corporation\n","\n","[SAVED] Kerala_09_Palakkad_2025.csv with 2116 rows.\n","\n","==================================================\n","PROCESSING DISTRICT: Malappuram (10)\n","==================================================\n","\n","   >>> Scanning Type: Grama Panchayat ('P')\n","      -> Found 94 unique bodies.\n","\n","      -> Finished Grama Panchayat\n","\n","   >>> Scanning Type: Block Panchayat ('B')\n","      -> Found 15 unique bodies.\n","\n","      -> Finished Block Panchayat\n","\n","   >>> Scanning Type: District Panchayat ('D')\n","      -> Found 1 unique bodies.\n","\n","      -> Finished District Panchayat\n","\n","   >>> Scanning Type: Municipality/Corporation ('C')\n","      -> Found 12 unique bodies.\n","\n","      -> Finished Municipality/Corporation\n","\n","[SAVED] Kerala_10_Malappuram_2025.csv with 2788 rows.\n","\n","==================================================\n","PROCESSING DISTRICT: Kozhikode (11)\n","==================================================\n","\n","   >>> Scanning Type: Grama Panchayat ('P')\n","      -> Found 70 unique bodies.\n","\n","      -> Finished Grama Panchayat\n","\n","   >>> Scanning Type: Block Panchayat ('B')\n","      -> Found 12 unique bodies.\n","\n","      -> Finished Block Panchayat\n","\n","   >>> Scanning Type: District Panchayat ('D')\n","      -> Found 1 unique bodies.\n","\n","      -> Finished District Panchayat\n","\n","   >>> Scanning Type: Municipality/Corporation ('C')\n","      -> Found 8 unique bodies.\n","\n","      -> Finished Municipality/Corporation\n","\n","[SAVED] Kerala_11_Kozhikode_2025.csv with 1903 rows.\n","\n","==================================================\n","PROCESSING DISTRICT: Wayanad (12)\n","==================================================\n","\n","   >>> Scanning Type: Grama Panchayat ('P')\n","      -> Found 23 unique bodies.\n","\n","      -> Finished Grama Panchayat\n","\n","   >>> Scanning Type: Block Panchayat ('B')\n","      -> Found 1 unique bodies.\n","\n","      -> Finished Block Panchayat\n","\n","   >>> Scanning Type: District Panchayat ('D')\n","      -> Found 1 unique bodies.\n","\n","      -> Finished District Panchayat\n","\n","   >>> Scanning Type: Municipality/Corporation ('C')\n","      -> Found 1 unique bodies.\n","\n","      -> Finished Municipality/Corporation\n","\n","[SAVED] Kerala_12_Wayanad_2025.csv with 501 rows.\n","\n","==================================================\n","PROCESSING DISTRICT: Kannur (13)\n","==================================================\n","\n","   >>> Scanning Type: Grama Panchayat ('P')\n","      -> Found 71 unique bodies.\n","\n","      -> Finished Grama Panchayat\n","\n","   >>> Scanning Type: Block Panchayat ('B')\n","      -> Found 11 unique bodies.\n","\n","      -> Finished Block Panchayat\n","\n","   >>> Scanning Type: District Panchayat ('D')\n","      -> Found 1 unique bodies.\n","\n","      -> Finished District Panchayat\n","\n","   >>> Scanning Type: Municipality/Corporation ('C')\n","      -> Found 9 unique bodies.\n","\n","      -> Finished Municipality/Corporation\n","\n","[SAVED] Kerala_13_Kannur_2025.csv with 1812 rows.\n","\n","==================================================\n","PROCESSING DISTRICT: Kasaragod (14)\n","==================================================\n","\n","   >>> Scanning Type: Grama Panchayat ('P')\n","      -> Found 38 unique bodies.\n","\n","      -> Finished Grama Panchayat\n","\n","   >>> Scanning Type: Block Panchayat ('B')\n","      -> Found 6 unique bodies.\n","\n","      -> Finished Block Panchayat\n","\n","   >>> Scanning Type: District Panchayat ('D')\n","      -> Found 1 unique bodies.\n","\n","      -> Finished District Panchayat\n","\n","   >>> Scanning Type: Municipality/Corporation ('C')\n","      -> Found 1 unique bodies.\n","\n","      -> Finished Municipality/Corporation\n","\n","[SAVED] Kerala_14_Kasaragod_2025.csv with 853 rows.\n"]}],"source":["import requests\n","import pandas as pd\n","import time\n","import urllib3\n","import json\n","import os\n","\n","# --- 1. CONFIGURATION ---\n","urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n","\n","# API ENDPOINTS\n","URL_HOME = \"https://lbtrend.kerala.gov.in/\"\n","URL_LIST = \"https://lbtrend.kerala.gov.in/includes/stateView2_ajax.php\"\n","URL_DETAILS = \"https://lbtrend.kerala.gov.in/includes/lb_ajax2.php\"\n","\n","HEADERS = {\n","    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36\",\n","    \"X-Requested-With\": \"XMLHttpRequest\",\n","    \"Referer\": \"https://lbtrend.kerala.gov.in/\"\n","}\n","\n","# DISTRICT MAP (01 to 14)\n","DISTRICTS = {\n","    \"01\": \"Thiruvananthapuram\",\n","    \"02\": \"Kollam\",\n","    \"03\": \"Pathanamthitta\",\n","    \"04\": \"Alappuzha\",\n","    \"05\": \"Kottayam\",\n","    \"06\": \"Idukki\",\n","    \"07\": \"Ernakulam\",\n","    \"08\": \"Thrissur\",\n","    \"09\": \"Palakkad\",\n","    \"10\": \"Malappuram\",\n","    \"11\": \"Kozhikode\",\n","    \"12\": \"Wayanad\",\n","    \"13\": \"Kannur\",\n","    \"14\": \"Kasaragod\"\n","}\n","\n","# BODY TYPES TO SCAN\n","# Note: 'C' covers both Municipalities and Corporations in the server backend.\n","BODY_TYPES = [\n","    {\"code\": \"P\", \"name\": \"Grama Panchayat\"},\n","    {\"code\": \"B\", \"name\": \"Block Panchayat\"},\n","    {\"code\": \"D\", \"name\": \"District Panchayat\"},\n","    {\"code\": \"C\", \"name\": \"Municipality/Corporation\"}\n","]\n","\n","# --- 2. HELPER FUNCTIONS ---\n","\n","def deep_search_for_list(data, min_length=1):\n","    \"\"\"Recursively searches JSON for any list longer than min_length.\"\"\"\n","    candidates = []\n","    if isinstance(data, dict):\n","        for k, v in data.items():\n","            if isinstance(v, list) and len(v) >= min_length:\n","                candidates.append(v)\n","            elif isinstance(v, (dict, list)):\n","                candidates.extend(deep_search_for_list(v, min_length))\n","    elif isinstance(data, list):\n","        for item in data:\n","            if isinstance(item, (dict, list)):\n","                candidates.extend(deep_search_for_list(item, min_length))\n","    return candidates\n","\n","def get_candidates_level_4(session, ward_full_id):\n","    \"\"\"\n","    Fetches the specific Candidate List (Level 4) to get exact Party names.\n","    Returns: (Party, Name, Votes)\n","    \"\"\"\n","    payload_can = {\n","        \"_p\": \"can\", \"_w\": ward_full_id, \"_t\": \"P\", \"_s\": \"L\"\n","    }\n","    try:\n","        resp_can = session.post(URL_DETAILS, data=payload_can, verify=False)\n","        can_json = resp_can.json()\n","        can_lists = deep_search_for_list(can_json, min_length=1)\n","\n","        if can_lists:\n","            candidates = max(can_lists, key=len)\n","\n","            # Logic: Find candidate with MAX votes\n","            best_candidate = None\n","            max_v = -1\n","\n","            for can in candidates:\n","                try:\n","                    # SCHEMA (Verified): Index 0=Party, 3=Name, 4=Votes\n","                    votes = int(can[4])\n","                    if votes > max_v:\n","                        max_v = votes\n","                        best_candidate = can\n","                except:\n","                    pass\n","\n","            if best_candidate:\n","                return best_candidate[0], best_candidate[3], max_v\n","\n","    except Exception:\n","        pass\n","\n","    return \"Unknown\", \"Unknown\", 0\n","\n","# --- 3. MAIN SCRAPER ---\n","\n","def scrape_all_districts_2025():\n","    print(\"--- STARTING UNIVERSAL KERALA ELECTION SCRAPER 2025 ---\")\n","\n","    session = requests.Session()\n","    session.headers.update(HEADERS)\n","\n","    # Init Session\n","    try:\n","        session.get(URL_HOME, verify=False)\n","        print(\"1. Session Initialized.\")\n","    except Exception as e:\n","        print(f\"Warning: Session init failed: {e}\")\n","\n","    # --- OUTER LOOP: DISTRICTS ---\n","    for dist_code, dist_name in DISTRICTS.items():\n","        print(f\"\\n==================================================\")\n","        print(f\"PROCESSING DISTRICT: {dist_name} ({dist_code})\")\n","        print(f\"==================================================\")\n","\n","        district_data = []\n","        district_id = f\"D{dist_code}001\" # e.g., D01001, D10001\n","\n","        # --- INNER LOOP: BODY TYPES ---\n","        for b_type in BODY_TYPES:\n","            type_code = b_type['code']\n","            type_name = b_type['name']\n","\n","            print(f\"\\n   >>> Scanning Type: {type_name} ('{type_code}')\")\n","\n","            # 1. Fetch List of Bodies\n","            payload_list = {\n","                \"_p\": \"dv\", \"_l\": type_code, \"_d\": district_id, \"_s\": \"L\"\n","            }\n","\n","            local_bodies = []\n","            try:\n","                resp = session.post(URL_LIST, data=payload_list, verify=False)\n","                data_list = resp.json()\n","                found_lists = deep_search_for_list(data_list, min_length=1) # Min 1 for District/Corp\n","\n","                if found_lists:\n","                    # Get the longest list found\n","                    raw_list = max(found_lists, key=len)\n","\n","                    # DEDUPLICATION LOGIC\n","                    # The server might return multiple rows for the same body (status summary)\n","                    # We extract unique IDs.\n","                    seen_ids = set()\n","                    for item in raw_list:\n","                        lb_id = None\n","                        lb_name = \"Unknown\"\n","\n","                        # ID Extraction Strategy\n","                        for col in item:\n","                            s_col = str(col)\n","                            # Look for IDs starting with G, B, D, M, C followed by numbers\n","                            if len(s_col) > 4 and s_col[0] in ['G','B','D','M','C'] and s_col[1].isdigit():\n","                                lb_id = s_col\n","                                break\n","\n","                        # Fallback: Index 0\n","                        if not lb_id: lb_id = str(item[0])\n","\n","                        # Name Extraction: First non-ID string\n","                        if lb_name == \"Unknown\":\n","                            for col in item:\n","                                if isinstance(col, str) and col != lb_id and len(col) > 3:\n","                                    lb_name = col\n","                                    break\n","\n","                        if lb_id and lb_id not in seen_ids:\n","                            seen_ids.add(lb_id)\n","                            local_bodies.append({'id': lb_id, 'name': lb_name})\n","\n","                    print(f\"      -> Found {len(local_bodies)} unique bodies.\")\n","                else:\n","                    print(f\"      -> No bodies found (Empty list).\")\n","                    continue\n","\n","            except Exception as e:\n","                print(f\"      -> Error fetching list: {e}\")\n","                continue\n","\n","            # 2. Loop Through Each Body\n","            for i, body in enumerate(local_bodies):\n","                lb_id = body['id']\n","                lb_name = body['name']\n","\n","                print(f\"      [{i+1}/{len(local_bodies)}] {lb_name} ({lb_id})\", end=\"\\r\")\n","\n","                # Fetch Wards (Level 3)\n","                payload_wards = {\n","                    \"_p\": \"wv\", \"_w\": lb_id, \"_t\": \"P\", \"_s\": \"L\"\n","                }\n","\n","                try:\n","                    resp_wards = session.post(URL_DETAILS, data=payload_wards, verify=False)\n","                    wards_json = resp_wards.json()\n","                    ward_lists = deep_search_for_list(wards_json, min_length=1)\n","\n","                    if not ward_lists: continue\n","\n","                    wards = max(ward_lists, key=len)\n","\n","                    # Loop Wards (Level 4 Deep Dive)\n","                    for w in wards:\n","                        # Schema Assumption from previous analysis:\n","                        # Index 0: Ward Full ID (contains Number)\n","                        # Index 1: Front Affiliation (UDF/LDF)\n","                        # Index 5: Ward Name\n","\n","                        ward_full_id = str(w[0])\n","                        front_affiliation = str(w[1])\n","\n","                        # Name might be at index 5 or 2 depending on view, scanning for string\n","                        ward_name = \"Unknown\"\n","                        if len(w) > 5: ward_name = str(w[5])\n","                        elif len(w) > 2: ward_name = str(w[2])\n","\n","                        # Extract Ward Number (Last 3 digits of ID)\n","                        try:\n","                            ward_num = str(int(ward_full_id[-3:]))\n","                        except:\n","                            ward_num = \"0\"\n","\n","                        # FETCH CANDIDATE (Level 4)\n","                        c_party, c_name, c_votes = get_candidates_level_4(session, ward_full_id)\n","\n","                        # Fallback for Party\n","                        if c_party == \"Unknown\": c_party = front_affiliation\n","\n","                        district_data.append({\n","                            \"District\": dist_name,\n","                            \"Local Body Type\": type_name,\n","                            \"Local Body ID\": lb_id,\n","                            \"Local Body\": lb_name,\n","                            \"Ward Number\": ward_num,\n","                            \"Ward Name\": ward_name,\n","                            \"Candidate\": c_name,\n","                            \"Party\": c_party,\n","                            \"Front\": front_affiliation,\n","                            \"Votes\": c_votes,\n","                            \"Year\": 2025\n","                        })\n","\n","                        time.sleep(0.001) # Micro-sleep to prevent flooding\n","\n","                except Exception:\n","                    pass\n","            print(f\"\\n      -> Finished {type_name}\")\n","\n","        # --- SAVE DISTRICT DATA ---\n","        if district_data:\n","            filename = f\"Kerala_{dist_code}_{dist_name}_2025.csv\"\n","            df = pd.DataFrame(district_data)\n","            df.to_csv(filename, index=False, encoding='utf-8-sig')\n","            print(f\"\\n[SAVED] {filename} with {len(df)} rows.\")\n","        else:\n","            print(f\"\\n[SKIPPED] No data for {dist_name}.\")\n","\n","if __name__ == \"__main__\":\n","    scrape_all_districts_2025()"]},{"cell_type":"markdown","source":["Some districts had missing about urban area, fixing those.. ( For districts like Thiruvananthapuram\n"],"metadata":{"id":"KkYc2zEeHB5i"}},{"cell_type":"code","source":["import requests\n","import pandas as pd\n","import time\n","import urllib3\n","import json\n","\n","# --- 1. CONFIGURATION ---\n","urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n","\n","URL_HOME = \"https://lbtrend.kerala.gov.in/\"\n","URL_LIST = \"https://lbtrend.kerala.gov.in/includes/stateView2_ajax.php\"\n","URL_DETAILS = \"https://lbtrend.kerala.gov.in/includes/lb_ajax2.php\"\n","\n","HEADERS = {\n","    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36\",\n","    \"X-Requested-With\": \"XMLHttpRequest\",\n","    \"Referer\": \"https://lbtrend.kerala.gov.in/\"\n","}\n","\n","# ONLY THE 6 PROBLEMATIC DISTRICTS\n","DISTRICTS = {\n","    \"01\": \"Thiruvananthapuram\",\n","    \"02\": \"Kollam\",\n","    \"03\": \"Pathanamthitta\",\n","    \"06\": \"Idukki\",\n","    \"12\": \"Wayanad\",\n","    \"14\": \"Kasaragod\"\n","}\n","\n","# DUAL SCAN MODE: Check both 'M' and 'C' to catch everything\n","BODY_TYPES = [\n","    {\"code\": \"P\", \"name\": \"Grama Panchayat\"},\n","    {\"code\": \"B\", \"name\": \"Block Panchayat\"},\n","    {\"code\": \"D\", \"name\": \"District Panchayat\"},\n","    {\"code\": \"M\", \"name\": \"Municipality\"},    # Explicitly check M\n","    {\"code\": \"C\", \"name\": \"Corporation\"}      # Explicitly check C\n","]\n","\n","# --- 2. HELPER FUNCTIONS ---\n","\n","def deep_search_for_list(data, min_length=1):\n","    candidates = []\n","    if isinstance(data, dict):\n","        for k, v in data.items():\n","            if isinstance(v, list) and len(v) >= min_length:\n","                candidates.append(v)\n","            elif isinstance(v, (dict, list)):\n","                candidates.extend(deep_search_for_list(v, min_length))\n","    elif isinstance(data, list):\n","        for item in data:\n","            if isinstance(item, (dict, list)):\n","                candidates.extend(deep_search_for_list(item, min_length))\n","    return candidates\n","\n","def get_candidates_level_4(session, ward_full_id):\n","    \"\"\"Fetches Level 4 Candidate Data (Party/Name/Votes)\"\"\"\n","    payload_can = {\n","        \"_p\": \"can\", \"_w\": ward_full_id, \"_t\": \"P\", \"_s\": \"L\"\n","    }\n","    try:\n","        resp_can = session.post(URL_DETAILS, data=payload_can, verify=False)\n","        can_json = resp_can.json()\n","        can_lists = deep_search_for_list(can_json, min_length=1)\n","\n","        if can_lists:\n","            candidates = max(can_lists, key=len)\n","            best_candidate = None\n","            max_v = -1\n","\n","            for can in candidates:\n","                try:\n","                    # SCHEMA: Index 0=Party, 3=Name, 4=Votes\n","                    votes = int(can[4])\n","                    if votes > max_v:\n","                        max_v = votes\n","                        best_candidate = can\n","                except:\n","                    pass\n","\n","            if best_candidate:\n","                return best_candidate[0], best_candidate[3], max_v\n","    except:\n","        pass\n","\n","    return \"Unknown\", \"Unknown\", 0\n","\n","# --- 3. MAIN SCRAPER ---\n","\n","def scrape_problem_districts_2025():\n","    print(\"--- STARTING TARGETED FIX FOR 6 DISTRICTS ---\")\n","\n","    session = requests.Session()\n","    session.headers.update(HEADERS)\n","\n","    try:\n","        session.get(URL_HOME, verify=False)\n","    except:\n","        pass\n","\n","    for dist_code, dist_name in DISTRICTS.items():\n","        print(f\"\\n==================================================\")\n","        print(f\"FIXING DISTRICT: {dist_name} ({dist_code})\")\n","        print(f\"==================================================\")\n","\n","        district_data = []\n","        district_id = f\"D{dist_code}001\"\n","\n","        # Track processed IDs to avoid duplicates between 'M' and 'C'\n","        processed_body_ids = set()\n","\n","        for b_type in BODY_TYPES:\n","            type_code = b_type['code']\n","            type_name = b_type['name']\n","\n","            print(f\"\\n   >>> Scanning Type: {type_name} ('{type_code}')\")\n","\n","            # 1. Fetch List\n","            payload_list = {\n","                \"_p\": \"dv\", \"_l\": type_code, \"_d\": district_id, \"_s\": \"L\"\n","            }\n","\n","            local_bodies = []\n","            try:\n","                resp = session.post(URL_LIST, data=payload_list, verify=False)\n","                data_list = resp.json()\n","                found_lists = deep_search_for_list(data_list, min_length=1)\n","\n","                if found_lists:\n","                    raw_list = max(found_lists, key=len)\n","\n","                    # Extract unique IDs\n","                    temp_bodies = []\n","                    for item in raw_list:\n","                        lb_id = None\n","                        lb_name = \"Unknown\"\n","\n","                        # ID Extraction\n","                        for col in item:\n","                            s_col = str(col)\n","                            if len(s_col) > 4 and s_col[0] in ['G','B','D','M','C'] and s_col[1].isdigit():\n","                                lb_id = s_col\n","                                break\n","                        if not lb_id: lb_id = str(item[0])\n","\n","                        # Name Extraction\n","                        if lb_name == \"Unknown\":\n","                            for col in item:\n","                                if isinstance(col, str) and col != lb_id and len(col) > 3:\n","                                    lb_name = col\n","                                    break\n","\n","                        # DEDUPLICATION CHECK\n","                        # We specifically filter out 'D' IDs in Urban scans\n","                        if type_code in ['M', 'C'] and lb_id.startswith('D'):\n","                             continue # Skip District ID leak\n","\n","                        if lb_id and lb_id not in processed_body_ids:\n","                            processed_body_ids.add(lb_id)\n","                            temp_bodies.append({'id': lb_id, 'name': lb_name})\n","\n","                    local_bodies = temp_bodies\n","                    print(f\"      -> Found {len(local_bodies)} VALID bodies.\")\n","                else:\n","                    print(f\"      -> No bodies found.\")\n","                    continue\n","\n","            except Exception:\n","                continue\n","\n","            # 2. Loop Bodies\n","            for i, body in enumerate(local_bodies):\n","                lb_id = body['id']\n","                lb_name = body['name']\n","\n","                print(f\"      [{i+1}/{len(local_bodies)}] {lb_name} ({lb_id})\", end=\"\\r\")\n","\n","                # Fetch Wards\n","                payload_wards = {\n","                    \"_p\": \"wv\", \"_w\": lb_id, \"_t\": \"P\", \"_s\": \"L\"\n","                }\n","\n","                try:\n","                    resp_wards = session.post(URL_DETAILS, data=payload_wards, verify=False)\n","                    wards_json = resp_wards.json()\n","                    ward_lists = deep_search_for_list(wards_json, min_length=1)\n","\n","                    if not ward_lists: continue\n","\n","                    wards = max(ward_lists, key=len)\n","\n","                    for w in wards:\n","                        ward_full_id = str(w[0])\n","                        front_affiliation = str(w[1])\n","\n","                        ward_name = \"Unknown\"\n","                        if len(w) > 5: ward_name = str(w[5])\n","                        elif len(w) > 2: ward_name = str(w[2])\n","\n","                        try:\n","                            ward_num = str(int(ward_full_id[-3:]))\n","                        except:\n","                            ward_num = \"0\"\n","\n","                        # Level 4\n","                        c_party, c_name, c_votes = get_candidates_level_4(session, ward_full_id)\n","\n","                        if c_party == \"Unknown\": c_party = front_affiliation\n","\n","                        district_data.append({\n","                            \"District\": dist_name,\n","                            \"Local Body Type\": type_name,\n","                            \"Local Body ID\": lb_id,\n","                            \"Local Body\": lb_name,\n","                            \"Ward Number\": ward_num,\n","                            \"Ward Name\": ward_name,\n","                            \"Candidate\": c_name,\n","                            \"Party\": c_party,\n","                            \"Front\": front_affiliation,\n","                            \"Votes\": c_votes,\n","                            \"Year\": 2025\n","                        })\n","\n","                        time.sleep(0.001)\n","\n","                except Exception:\n","                    pass\n","            print(f\"\\n      -> Finished {type_name}\")\n","\n","        # --- SAVE ---\n","        if district_data:\n","            filename = f\"Kerala_{dist_code}_{dist_name}_2025.csv\"\n","            df = pd.DataFrame(district_data)\n","            df.to_csv(filename, index=False, encoding='utf-8-sig')\n","            print(f\"\\n[SAVED] {filename} with {len(df)} rows.\")\n","\n","if __name__ == \"__main__\":\n","    scrape_problem_districts_2025()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"By7PypMRG6G_","outputId":"9d97c3e2-aa3a-4dbb-ccfe-02637555477c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--- STARTING TARGETED FIX FOR 6 DISTRICTS ---\n","\n","==================================================\n","FIXING DISTRICT: Thiruvananthapuram (01)\n","==================================================\n","\n","   >>> Scanning Type: Grama Panchayat ('P')\n","      -> Found 73 VALID bodies.\n","\n","      -> Finished Grama Panchayat\n","\n","   >>> Scanning Type: Block Panchayat ('B')\n","      -> Found 11 VALID bodies.\n","\n","      -> Finished Block Panchayat\n","\n","   >>> Scanning Type: District Panchayat ('D')\n","      -> Found 1 VALID bodies.\n","\n","      -> Finished District Panchayat\n","\n","   >>> Scanning Type: Municipality ('M')\n","\n","   >>> Scanning Type: Corporation ('C')\n","      -> Found 0 VALID bodies.\n","\n","      -> Finished Corporation\n","\n","[SAVED] Kerala_01_Thiruvananthapuram_2025.csv with 1583 rows.\n","\n","==================================================\n","FIXING DISTRICT: Kollam (02)\n","==================================================\n","\n","   >>> Scanning Type: Grama Panchayat ('P')\n","      -> Found 68 VALID bodies.\n"]}]},{"cell_type":"code","source":["import requests\n","import urllib3\n","import string\n","\n","# 1. SETUP\n","urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n","URL_LIST = \"https://lbtrend.kerala.gov.in/includes/stateView2_ajax.php\"\n","\n","HEADERS = {\n","    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36\",\n","    \"X-Requested-With\": \"XMLHttpRequest\",\n","    \"Referer\": \"https://lbtrend.kerala.gov.in/\"\n","}\n","\n","def deep_search_first_list(data):\n","    \"\"\"Finds the first list in the JSON response.\"\"\"\n","    if isinstance(data, dict):\n","        for k, v in data.items():\n","            if isinstance(v, list) and len(v) > 0: return v\n","            if isinstance(v, dict):\n","                res = deep_search_first_list(v)\n","                if res: return res\n","    elif isinstance(data, list):\n","        return data\n","    return None\n","\n","def brute_force_find_codes():\n","    print(\"--- BRUTE FORCE DISCOVERY FOR THIRUVANANTHAPURAM (D01001) ---\")\n","    session = requests.Session()\n","    session.headers.update(HEADERS)\n","\n","    # We test every letter from A to Z\n","    alphabet = list(string.ascii_uppercase)\n","\n","    found_something = False\n","\n","    for code in alphabet:\n","        payload = {\n","            \"_p\": \"dv\",\n","            \"_l\": code,      # <--- Testing this letter\n","            \"_d\": \"D01001\",  # Thiruvananthapuram\n","            \"_s\": \"L\"\n","        }\n","\n","        try:\n","            resp = session.post(URL_LIST, data=payload, verify=False)\n","            data = resp.json()\n","\n","            # Look for a list in the response\n","            result_list = deep_search_first_list(data)\n","\n","            if result_list:\n","                count = len(result_list)\n","                first_item = result_list[0]\n","\n","                # We only care if it found a list of Local Bodies\n","                # Check if the first item looks like a Local Body (has ID)\n","                sample_str = str(first_item)\n","\n","                print(f\"Code '{code}': Found {count} items.\")\n","                print(f\"   -> Sample: {sample_str[:100]}...\") # Print first 100 chars\n","\n","                # HIGHLIGHT INTERESTING FINDS\n","                if \"Attingal\" in sample_str or \"Nedumangad\" in sample_str:\n","                    print(\"   *** FOUND MUNICIPALITIES! ***\")\n","                if \"Thiruvananthapuram\" in sample_str and count > 10:\n","                    # If count is small (1-5), it's likely District Panchayat. Corp usually has many wards, but here we look for Body List.\n","                    # Actually Corp list is just 1 item usually.\n","                    pass\n","\n","                found_something = True\n","            else:\n","                # print(f\"Code '{code}': [Empty]\")\n","                pass\n","\n","        except Exception as e:\n","            print(f\"Code '{code}': Error - {e}\")\n","\n","    if not found_something:\n","        print(\"\\n[FAILURE] No codes returned any lists. The issue might be the '_d' parameter.\")\n","\n","if __name__ == \"__main__\":\n","    brute_force_find_codes()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MaK0LPlxJf7v","executionInfo":{"status":"ok","timestamp":1766341355462,"user_tz":-330,"elapsed":6886,"user":{"displayName":"FARHAN JAFFAR","userId":"00674461129948116447"}},"outputId":"a5a0b19b-3f38-4478-ece4-bcfefab9a2d0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--- BRUTE FORCE DISCOVERY FOR THIRUVANANTHAPURAM (D01001) ---\n","Code 'A': Error - Expecting value: line 8 column 1 (char 7)\n","Code 'B': Found 1 items.\n","   -> Sample: ['Total', 73, 11, 1, 4, 1]...\n","Code 'C': Found 1 items.\n","   -> Sample: ['Total', 73, 11, 1, 4, 1]...\n","Code 'D': Found 1 items.\n","   -> Sample: ['Total', 73, 11, 1, 4, 1]...\n","Code 'E': Error - Expecting value: line 8 column 1 (char 7)\n","Code 'F': Error - Expecting value: line 8 column 1 (char 7)\n","Code 'G': Error - Expecting value: line 8 column 1 (char 7)\n","Code 'H': Error - Expecting value: line 8 column 1 (char 7)\n","Code 'I': Error - Expecting value: line 8 column 1 (char 7)\n","Code 'J': Error - Expecting value: line 8 column 1 (char 7)\n","Code 'K': Error - Expecting value: line 8 column 1 (char 7)\n","Code 'L': Error - Expecting value: line 8 column 1 (char 7)\n","Code 'M': Error - Expecting value: line 8 column 1 (char 7)\n","Code 'N': Error - Expecting value: line 8 column 1 (char 7)\n","Code 'O': Error - Expecting value: line 8 column 1 (char 7)\n","Code 'P': Found 1 items.\n","   -> Sample: ['Total', 73, 11, 1, 4, 1]...\n","Code 'Q': Error - Expecting value: line 8 column 1 (char 7)\n","Code 'R': Error - Expecting value: line 8 column 1 (char 7)\n","Code 'S': Error - Expecting value: line 8 column 1 (char 7)\n","Code 'T': Error - Expecting value: line 8 column 1 (char 7)\n","Code 'U': Error - Expecting value: line 8 column 1 (char 7)\n","Code 'V': Error - Expecting value: line 8 column 1 (char 7)\n","Code 'W': Error - Expecting value: line 8 column 1 (char 7)\n","Code 'X': Error - Expecting value: line 8 column 1 (char 7)\n","Code 'Y': Error - Expecting value: line 8 column 1 (char 7)\n","Code 'Z': Error - Expecting value: line 8 column 1 (char 7)\n"]}]},{"cell_type":"code","source":["import requests\n","import pandas as pd\n","import time\n","import urllib3\n","import json\n","\n","# --- 1. CONFIGURATION ---\n","urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n","\n","URL_HOME = \"https://lbtrend.kerala.gov.in/\"\n","URL_LIST = \"https://lbtrend.kerala.gov.in/includes/stateView2_ajax.php\"\n","URL_DETAILS = \"https://lbtrend.kerala.gov.in/includes/lb_ajax2.php\"\n","\n","HEADERS = {\n","    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36\",\n","    \"X-Requested-With\": \"XMLHttpRequest\",\n","    \"Referer\": \"https://lbtrend.kerala.gov.in/\"\n","}\n","\n","# THE 6 PROBLEM DISTRICTS ONLY\n","DISTRICTS = {\n","    \"01\": \"Thiruvananthapuram\",\n","    \"02\": \"Kollam\",\n","    \"03\": \"Pathanamthitta\",\n","    \"06\": \"Idukki\",\n","    \"12\": \"Wayanad\",\n","    \"14\": \"Kasaragod\"\n","}\n","\n","# SCAN TYPES: We focus on Urban Bodies ('C' covers both in these districts usually)\n","BODY_TYPES = [\n","    {\"code\": \"C\", \"name\": \"Urban Body (Muni/Corp)\"}\n","]\n","\n","# --- 2. HELPER FUNCTIONS ---\n","\n","def find_all_lists(data):\n","    \"\"\"Recursively finds ALL lists in the JSON, not just the first one.\"\"\"\n","    found_lists = []\n","    if isinstance(data, dict):\n","        for k, v in data.items():\n","            if isinstance(v, list) and len(v) > 0:\n","                found_lists.append(v)\n","            elif isinstance(v, (dict, list)):\n","                found_lists.extend(find_all_lists(v))\n","    elif isinstance(data, list):\n","        found_lists.append(data) # The list itself\n","        for item in data:\n","            if isinstance(item, (dict, list)):\n","                found_lists.extend(find_all_lists(item))\n","    return found_lists\n","\n","def get_candidates_level_4(session, ward_full_id):\n","    payload_can = {\"_p\": \"can\", \"_w\": ward_full_id, \"_t\": \"P\", \"_s\": \"L\"}\n","    try:\n","        resp_can = session.post(URL_DETAILS, data=payload_can, verify=False)\n","        can_lists = find_all_lists(resp_can.json())\n","        if can_lists:\n","            # Candidate list is usually the one with the most columns\n","            candidates = max(can_lists, key=lambda l: len(l) if len(l)>0 and isinstance(l[0], list) else 0)\n","\n","            best_candidate = None\n","            max_v = -1\n","            for can in candidates:\n","                if isinstance(can, list) and len(can) > 4:\n","                    try:\n","                        votes = int(can[4])\n","                        if votes > max_v:\n","                            max_v = votes\n","                            best_candidate = can\n","                    except: pass\n","\n","            if best_candidate:\n","                return best_candidate[0], best_candidate[3], max_v\n","    except:\n","        pass\n","    return \"Unknown\", \"Unknown\", 0\n","\n","# --- 3. MAIN SCRAPER ---\n","\n","def scrape_urban_fix_2025():\n","    print(\"--- STARTING URBAN FIX FOR 6 DISTRICTS ---\")\n","    session = requests.Session()\n","    session.headers.update(HEADERS)\n","\n","    try: session.get(URL_HOME, verify=False)\n","    except: pass\n","\n","    for dist_code, dist_name in DISTRICTS.items():\n","        print(f\"\\nProcessing: {dist_name} ({dist_code})\")\n","\n","        # Load existing file to append/update\n","        filename = f\"Kerala_{dist_code}_{dist_name}_2025.csv\"\n","        try:\n","            existing_df = pd.read_csv(filename)\n","            # Remove bad rows (Urban bodies with District ID 'D...')\n","            # We keep 'Grama' and 'Block' rows, and 'District' rows (if valid)\n","            # Valid District rows usually have 'District Panchayat' as type, but ID Dxx001.\n","            # The BAD rows are 'Municipality' type with 'D' ID.\n","\n","            mask_bad = (existing_df['Local Body Type'].str.contains(\"Municipality|Corporation\", case=False)) & \\\n","                       (existing_df['Local Body ID'].str.startswith(\"D\"))\n","\n","            clean_df = existing_df[~mask_bad]\n","            print(f\"   -> Removed {mask_bad.sum()} bad rows. Current count: {len(clean_df)}\")\n","        except:\n","            print(\"   -> File not found, starting fresh.\")\n","            clean_df = pd.DataFrame()\n","\n","        new_urban_data = []\n","        district_id = f\"D{dist_code}001\"\n","\n","        # FETCH LIST\n","        payload_list = {\"_p\": \"dv\", \"_l\": \"C\", \"_d\": district_id, \"_s\": \"L\"}\n","\n","        try:\n","            resp = session.post(URL_LIST, data=payload_list, verify=False)\n","            all_lists = find_all_lists(resp.json())\n","\n","            valid_bodies = []\n","\n","            # Smart Filter: Look for the list that actually contains Bodies\n","            for lst in all_lists:\n","                if not lst: continue\n","                # Check first item structure\n","                first_item = lst[0]\n","                if isinstance(first_item, list):\n","                    # Row: [ID, Name, ...]\n","                    # We check if ID matches M... or C...\n","                    sample_id = str(first_item[0])\n","                    # Accept M (Muni), C (Corp), or even names that aren't \"Total\"\n","                    if sample_id.startswith(\"M\") or sample_id.startswith(\"C\") or (len(first_item)>1 and \"Total\" not in str(first_item)):\n","                        valid_bodies = lst\n","                        break\n","\n","            if not valid_bodies:\n","                print(\"   -> [ERROR] No valid urban list found via 'C'.\")\n","                # Fallback: Try 'M' just in case? No, stick to User input 'C'.\n","            else:\n","                print(f\"   -> Found {len(valid_bodies)} Urban Bodies!\")\n","\n","                for body in valid_bodies:\n","                    # Extract ID and Name\n","                    lb_id = str(body[0])\n","                    # If ID is just a number (rare), skip or fix.\n","                    # If ID is \"Total\", skip.\n","                    if \"Total\" in lb_id: continue\n","\n","                    lb_name = \"Unknown\"\n","                    for col in body:\n","                        if isinstance(col, str) and len(col) > 3 and col != lb_id:\n","                            lb_name = col\n","                            break\n","\n","                    print(f\"      Scanning: {lb_name} ({lb_id})\")\n","\n","                    # FETCH WARDS\n","                    payload_w = {\"_p\": \"wv\", \"_w\": lb_id, \"_t\": \"P\", \"_s\": \"L\"}\n","                    try:\n","                        resp_w = session.post(URL_DETAILS, data=payload_w, verify=False)\n","                        w_lists = find_all_lists(resp_w.json())\n","                        if not w_lists: continue\n","\n","                        wards = max(w_lists, key=len)\n","\n","                        for w in wards:\n","                            ward_id = str(w[0])\n","                            front = str(w[1])\n","                            w_name = str(w[5]) if len(w)>5 else str(w[2])\n","                            w_num = ward_id[-3:]\n","\n","                            party, c_name, votes = get_candidates_level_4(session, ward_id)\n","                            if party == \"Unknown\": party = front\n","\n","                            new_urban_data.append({\n","                                \"District\": dist_name,\n","                                \"Local Body Type\": \"Municipality/Corporation\",\n","                                \"Local Body ID\": lb_id,\n","                                \"Local Body\": lb_name,\n","                                \"Ward Number\": w_num,\n","                                \"Ward Name\": w_name,\n","                                \"Candidate\": c_name,\n","                                \"Party\": party,\n","                                \"Front\": front,\n","                                \"Votes\": votes,\n","                                \"Year\": 2025\n","                            })\n","                            time.sleep(0.001)\n","                    except: pass\n","\n","        except Exception as e:\n","            print(f\"   -> Network Error: {e}\")\n","\n","        # MERGE AND SAVE\n","        if new_urban_data:\n","            new_df = pd.DataFrame(new_urban_data)\n","            final_df = pd.concat([clean_df, new_df], ignore_index=True)\n","            final_df.to_csv(filename, index=False, encoding='utf-8-sig')\n","            print(f\"   -> [SAVED] Updated {filename} (Total: {len(final_df)} rows)\")\n","        else:\n","            print(\"   -> No new data found to append.\")\n","\n","if __name__ == \"__main__\":\n","    scrape_urban_fix_2025()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AGq-NDGUKoVS","executionInfo":{"status":"ok","timestamp":1766341786510,"user_tz":-330,"elapsed":138492,"user":{"displayName":"FARHAN JAFFAR","userId":"00674461129948116447"}},"outputId":"a58b8723-1458-4a75-e9ba-1dae3be6e349"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--- STARTING URBAN FIX FOR 6 DISTRICTS ---\n","\n","Processing: Thiruvananthapuram (01)\n","   -> Removed 0 bad rows. Current count: 1583\n","   -> Found 5 Urban Bodies!\n","      Scanning: THIRUVANANTHAPURAM (D01001)\n","      Scanning: THIRUVANANTHAPURAM (D01001)\n","      Scanning: THIRUVANANTHAPURAM (D01001)\n","      Scanning: THIRUVANANTHAPURAM (D01001)\n","      Scanning: THIRUVANANTHAPURAM (D01001)\n","   -> [SAVED] Updated Kerala_01_Thiruvananthapuram_2025.csv (Total: 1723 rows)\n","\n","Processing: Kollam (02)\n","   -> File not found, starting fresh.\n","   -> Found 5 Urban Bodies!\n","      Scanning: KOLLAM (D02001)\n","      Scanning: KOLLAM (D02001)\n","      Scanning: KOLLAM (D02001)\n","      Scanning: KOLLAM (D02001)\n","      Scanning: KOLLAM (D02001)\n","   -> [SAVED] Updated Kerala_02_Kollam_2025.csv (Total: 135 rows)\n","\n","Processing: Pathanamthitta (03)\n","   -> File not found, starting fresh.\n","   -> Found 5 Urban Bodies!\n","      Scanning: PATHANAMTHITTA (D03001)\n","      Scanning: PATHANAMTHITTA (D03001)\n","      Scanning: PATHANAMTHITTA (D03001)\n","      Scanning: PATHANAMTHITTA (D03001)\n","      Scanning: PATHANAMTHITTA (D03001)\n","   -> [SAVED] Updated Kerala_03_Pathanamthitta_2025.csv (Total: 85 rows)\n","\n","Processing: Idukki (06)\n","   -> File not found, starting fresh.\n","   -> Found 5 Urban Bodies!\n","      Scanning: IDUKKI (D06001)\n","      Scanning: IDUKKI (D06001)\n","      Scanning: IDUKKI (D06001)\n","      Scanning: IDUKKI (D06001)\n","      Scanning: IDUKKI (D06001)\n","   -> [SAVED] Updated Kerala_06_Idukki_2025.csv (Total: 85 rows)\n","\n","Processing: Wayanad (12)\n","   -> File not found, starting fresh.\n","   -> Found 5 Urban Bodies!\n","      Scanning: WAYANAD (D12001)\n","      Scanning: WAYANAD (D12001)\n","      Scanning: WAYANAD (D12001)\n","      Scanning: WAYANAD (D12001)\n","      Scanning: WAYANAD (D12001)\n","   -> [SAVED] Updated Kerala_12_Wayanad_2025.csv (Total: 85 rows)\n","\n","Processing: Kasaragod (14)\n","   -> File not found, starting fresh.\n","   -> Found 5 Urban Bodies!\n","      Scanning: KASARGOD (D14001)\n","      Scanning: KASARGOD (D14001)\n","      Scanning: KASARGOD (D14001)\n","      Scanning: KASARGOD (D14001)\n","      Scanning: KASARGOD (D14001)\n","   -> [SAVED] Updated Kerala_14_Kasaragod_2025.csv (Total: 90 rows)\n"]}]},{"cell_type":"markdown","source":[" JSON X-RAY: THIRUVANANTHAPURAM (Code 'C')"],"metadata":{"id":"eC-e9L228y5w"}},{"cell_type":"code","source":["import requests\n","import urllib3\n","import json\n","\n","# 1. SETUP\n","urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n","URL_LIST = \"https://lbtrend.kerala.gov.in/includes/stateView2_ajax.php\"\n","\n","HEADERS = {\n","    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36\",\n","    \"X-Requested-With\": \"XMLHttpRequest\",\n","    \"Referer\": \"https://lbtrend.kerala.gov.in/\"\n","}\n","\n","def x_ray_thiruvananthapuram():\n","    print(\"--- JSON X-RAY: THIRUVANANTHAPURAM (Code 'C') ---\")\n","    session = requests.Session()\n","    session.headers.update(HEADERS)\n","\n","    # The Exact Payload you confirmed from the browser\n","    payload = {\n","        \"_p\": \"dv\",\n","        \"_l\": \"C\",\n","        \"_d\": \"D01001\",\n","        \"_s\": \"L\"\n","    }\n","\n","    try:\n","        resp = session.post(URL_LIST, data=payload, verify=False)\n","        data = resp.json()\n","\n","        print(\"\\n[RESPONSE KEYS]\")\n","        print(data.keys())\n","\n","        # Check 'mdata' (Master Data) usually holds the list\n","        if 'mdata' in data:\n","            print(\"\\n[INSIDE 'mdata']\")\n","            mdata = data['mdata']\n","            print(f\"Type: {type(mdata)}\")\n","            if isinstance(mdata, list):\n","                print(f\"Length: {len(mdata)}\")\n","                if len(mdata) > 0:\n","                    print(f\"First Item: {mdata[0]}\")\n","            elif isinstance(mdata, str):\n","                print(f\"Content (First 500 chars): {mdata[:500]}\")\n","\n","        # Check 'summary'\n","        if 'summary' in data:\n","            print(\"\\n[INSIDE 'summary']\")\n","            print(data['summary'])\n","\n","        # Print Raw text snippet if it's confusing\n","        print(\"\\n[RAW JSON SNIPPET (First 1000 chars)]\")\n","        print(json.dumps(data, indent=2)[:1000])\n","\n","    except Exception as e:\n","        print(f\"Error: {e}\")\n","\n","if __name__ == \"__main__\":\n","    x_ray_thiruvananthapuram()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uP9Rx1CcM4r7","executionInfo":{"status":"ok","timestamp":1766342237999,"user_tz":-330,"elapsed":1205,"user":{"displayName":"FARHAN JAFFAR","userId":"00674461129948116447"}},"outputId":"27322533-608f-4a9b-9b0d-d33c2aa7e813"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--- JSON X-RAY: THIRUVANANTHAPURAM (Code 'C') ---\n","\n","[RESPONSE KEYS]\n","dict_keys(['mdata', 'total', 'summary', 'payload'])\n","\n","[INSIDE 'mdata']\n","Type: <class 'dict'>\n","\n","[INSIDE 'summary']\n","[['D01001', 'THIRUVANANTHAPURAM', 'LDF', 35, 5, 1, 4, 0, 45], ['D01001', 'THIRUVANANTHAPURAM', 'NDA', 6, 0, 0, 0, 1, 7], ['D01001', 'THIRUVANANTHAPURAM', 'OTH', 0, 0, 0, 0, 0, 0], ['D01001', 'THIRUVANANTHAPURAM', 'Tie', 15, 0, 0, 0, 0, 15], ['D01001', 'THIRUVANANTHAPURAM', 'UDF', 25, 6, 0, 0, 0, 31]]\n","\n","[RAW JSON SNIPPET (First 1000 chars)]\n","{\n","  \"mdata\": {\n","    \"rls\": 0,\n","    \"info\": \"\\ud83d\\ude4f Thanks \\u2013 Team SEC\",\n","    \"ut\": \"19-Dec-25 11:37:31\"\n","  },\n","  \"total\": [\n","    [\n","      \"Total\",\n","      73,\n","      11,\n","      1,\n","      4,\n","      1\n","    ]\n","  ],\n","  \"summary\": [\n","    [\n","      \"D01001\",\n","      \"THIRUVANANTHAPURAM\",\n","      \"LDF\",\n","      35,\n","      5,\n","      1,\n","      4,\n","      0,\n","      45\n","    ],\n","    [\n","      \"D01001\",\n","      \"THIRUVANANTHAPURAM\",\n","      \"NDA\",\n","      6,\n","      0,\n","      0,\n","      0,\n","      1,\n","      7\n","    ],\n","    [\n","      \"D01001\",\n","      \"THIRUVANANTHAPURAM\",\n","      \"OTH\",\n","      0,\n","      0,\n","      0,\n","      0,\n","      0,\n","      0\n","    ],\n","    [\n","      \"D01001\",\n","      \"THIRUVANANTHAPURAM\",\n","      \"Tie\",\n","      15,\n","      0,\n","      0,\n","      0,\n","      0,\n","      15\n","    ],\n","    [\n","      \"D01001\",\n","      \"THIRUVANANTHAPURAM\",\n","      \"UDF\",\n","      25,\n","      6,\n","      0,\n","      0,\n","      0,\n","      31\n","    ]\n","  ],\n","  \"payload\": [\n","    [\n","      \"M01003\",\n","      \"Attingal   \",\n","      32,\n","      \"17\",\n","      \"7\",\n","      \"16\",\n","      \"7\",\n","      \"2\",\n","      \"0\"\n","    ],\n","    [\n","     \n"]}]},{"cell_type":"markdown","source":["STARTING 'PAYLOAD' KEY EXTRACTION FIX"],"metadata":{"id":"loLCI6x184d8"}},{"cell_type":"code","source":["import requests\n","import pandas as pd\n","import time\n","import urllib3\n","import json\n","import os\n","\n","# --- 1. CONFIGURATION ---\n","urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n","\n","URL_HOME = \"https://lbtrend.kerala.gov.in/\"\n","URL_LIST = \"https://lbtrend.kerala.gov.in/includes/stateView2_ajax.php\"\n","URL_DETAILS = \"https://lbtrend.kerala.gov.in/includes/lb_ajax2.php\"\n","\n","HEADERS = {\n","    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36\",\n","    \"X-Requested-With\": \"XMLHttpRequest\",\n","    \"Referer\": \"https://lbtrend.kerala.gov.in/\"\n","}\n","\n","# THE 6 PROBLEM DISTRICTS\n","DISTRICTS = {\n","    \"01\": \"Thiruvananthapuram\",\n","    \"02\": \"Kollam\",\n","    \"03\": \"Pathanamthitta\",\n","    \"06\": \"Idukki\",\n","    \"12\": \"Wayanad\",\n","    \"14\": \"Kasaragod\"\n","}\n","\n","# --- 2. HELPER FUNCTIONS ---\n","\n","def deep_search_for_list(data, min_length=1):\n","    \"\"\"Fallback list finder (recursive)\"\"\"\n","    candidates = []\n","    if isinstance(data, dict):\n","        for k, v in data.items():\n","            if isinstance(v, list) and len(v) >= min_length:\n","                candidates.append(v)\n","            elif isinstance(v, (dict, list)):\n","                candidates.extend(deep_search_for_list(v, min_length))\n","    elif isinstance(data, list):\n","        for item in data:\n","            if isinstance(item, (dict, list)):\n","                candidates.extend(deep_search_for_list(item, min_length))\n","    return candidates\n","\n","def get_candidates_level_4(session, ward_full_id):\n","    \"\"\"Fetches Level 4 Candidate Data\"\"\"\n","    payload_can = {\"_p\": \"can\", \"_w\": ward_full_id, \"_t\": \"P\", \"_s\": \"L\"}\n","    try:\n","        resp_can = session.post(URL_DETAILS, data=payload_can, verify=False)\n","        can_json = resp_can.json()\n","\n","        # Candidate list is usually in 'payload' too, but let's be safe and search deep\n","        # or check 'payload' specifically if consistent.\n","        # Fallback to deep search is safer for Level 4 as it varies less.\n","        can_lists = deep_search_for_list(can_json, min_length=1)\n","\n","        if can_lists:\n","            candidates = max(can_lists, key=len)\n","            best_candidate = None\n","            max_v = -1\n","\n","            for can in candidates:\n","                try:\n","                    # Index 4 is Votes\n","                    votes = int(can[4])\n","                    if votes > max_v:\n","                        max_v = votes\n","                        best_candidate = can\n","                except: pass\n","\n","            if best_candidate:\n","                return best_candidate[0], best_candidate[3], max_v\n","    except:\n","        pass\n","    return \"Unknown\", \"Unknown\", 0\n","\n","# --- 3. MAIN SCRAPER ---\n","\n","def scrape_payload_fix_2025():\n","    print(\"--- STARTING 'PAYLOAD' KEY EXTRACTION FIX ---\")\n","\n","    session = requests.Session()\n","    session.headers.update(HEADERS)\n","\n","    try: session.get(URL_HOME, verify=False)\n","    except: pass\n","\n","    for dist_code, dist_name in DISTRICTS.items():\n","        print(f\"\\n==================================================\")\n","        print(f\"FIXING DISTRICT: {dist_name} ({dist_code})\")\n","        print(f\"==================================================\")\n","\n","        # 1. CLEANUP OLD FILE\n","        filename = f\"Kerala_{dist_code}_{dist_name}_2025.csv\"\n","        clean_df = pd.DataFrame()\n","\n","        if os.path.exists(filename):\n","            try:\n","                existing_df = pd.read_csv(filename)\n","                # Remove ANY row that claims to be Municipality/Corp but has a 'D' ID\n","                # This wipes the slate clean for Urban bodies.\n","                mask_bad = (existing_df['Local Body Type'].str.contains(\"Municipality|Corporation\", case=False))\n","                # We essentially re-scrape ALL urban bodies to be safe.\n","                # So we keep only Grama (P) and Block (B) and valid District (D) rows.\n","\n","                # Valid District rows: Type='District Panchayat' AND ID starts with 'D'\n","                # Bad Urban rows: Type='Municipality...'\n","\n","                clean_df = existing_df[~mask_bad]\n","                print(f\"   -> Removed {mask_bad.sum()} old Urban rows. Preserved {len(clean_df)} Panchayat/Block rows.\")\n","            except:\n","                print(\"   -> File read error, starting fresh.\")\n","        else:\n","            print(\"   -> File not found, starting fresh.\")\n","\n","        district_data = []\n","        district_id = f\"D{dist_code}001\"\n","\n","        # 2. FETCH THE 'PAYLOAD' LIST\n","        # We use _l=\"C\" because your browser inspection confirmed it returns the payload\n","        payload_list = {\"_p\": \"dv\", \"_l\": \"C\", \"_d\": district_id, \"_s\": \"L\"}\n","\n","        try:\n","            resp = session.post(URL_LIST, data=payload_list, verify=False)\n","            data_json = resp.json()\n","\n","            # *** THE KEY FIX: Look in 'payload' explicitly ***\n","            target_list = data_json.get('payload', [])\n","\n","            if not target_list:\n","                print(\"   -> [ERROR] 'payload' key is empty or missing.\")\n","                continue\n","\n","            print(f\"   -> Found {len(target_list)} Urban Bodies in 'payload'!\")\n","\n","            # 3. LOOP THROUGH BODIES\n","            for body in target_list:\n","                # Body Format: ['M01003', 'Attingal', 32, ...]\n","                lb_id = str(body[0])\n","                lb_name = str(body[1]).strip()\n","\n","                print(f\"      Scanning: {lb_name} ({lb_id})\")\n","\n","                # FETCH WARDS\n","                payload_w = {\"_p\": \"wv\", \"_w\": lb_id, \"_t\": \"P\", \"_s\": \"L\"}\n","\n","                try:\n","                    resp_w = session.post(URL_DETAILS, data=payload_w, verify=False)\n","                    # Wards are usually in 'payload' or the main list.\n","                    # Let's check 'payload' first, fall back to deep search.\n","                    w_json = resp_w.json()\n","                    w_list = w_json.get('payload', [])\n","                    if not w_list:\n","                        w_lists_deep = deep_search_for_list(w_json, min_length=1)\n","                        if w_lists_deep:\n","                             w_list = max(w_lists_deep, key=len)\n","\n","                    if not w_list: continue\n","\n","                    for w in w_list:\n","                        ward_id = str(w[0])\n","                        front = str(w[1])\n","                        # Name/Num logic\n","                        w_name = \"Unknown\"\n","                        if len(w) > 5: w_name = str(w[5])\n","                        elif len(w) > 2: w_name = str(w[2])\n","\n","                        try:\n","                            w_num = str(int(ward_id[-3:]))\n","                        except:\n","                            w_num = \"0\"\n","\n","                        # Level 4 Candidate\n","                        party, c_name, votes = get_candidates_level_4(session, ward_id)\n","                        if party == \"Unknown\": party = front\n","\n","                        district_data.append({\n","                            \"District\": dist_name,\n","                            \"Local Body Type\": \"Municipality/Corporation\",\n","                            \"Local Body ID\": lb_id,\n","                            \"Local Body\": lb_name,\n","                            \"Ward Number\": w_num,\n","                            \"Ward Name\": w_name,\n","                            \"Candidate\": c_name,\n","                            \"Party\": party,\n","                            \"Front\": front,\n","                            \"Votes\": votes,\n","                            \"Year\": 2025\n","                        })\n","                        time.sleep(0.001)\n","\n","                except Exception as e:\n","                    # print(f\"Ward Error: {e}\")\n","                    pass\n","\n","        except Exception as e:\n","            print(f\"   -> Network Error: {e}\")\n","            continue\n","\n","        # 4. SAVE AND MERGE\n","        if district_data:\n","            new_df = pd.DataFrame(district_data)\n","            final_df = pd.concat([clean_df, new_df], ignore_index=True)\n","            final_df.to_csv(filename, index=False, encoding='utf-8-sig')\n","            print(f\"   -> [SAVED] Updated {filename} (Total: {len(final_df)} rows)\")\n","        else:\n","            print(\"   -> No new data collected.\")\n","\n","if __name__ == \"__main__\":\n","    scrape_payload_fix_2025()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4iiFTl6FNPRe","executionInfo":{"status":"ok","timestamp":1766342519771,"user_tz":-330,"elapsed":191197,"user":{"displayName":"FARHAN JAFFAR","userId":"00674461129948116447"}},"outputId":"23ba6acb-ccf9-4c08-ef42-e06285ee1ca7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--- STARTING 'PAYLOAD' KEY EXTRACTION FIX ---\n","\n","==================================================\n","FIXING DISTRICT: Thiruvananthapuram (01)\n","==================================================\n","   -> Removed 140 old Urban rows. Preserved 1583 Panchayat/Block rows.\n","   -> Found 5 Urban Bodies in 'payload'!\n","      Scanning: Attingal (M01003)\n","      Scanning: Nedumangad (M01002)\n","      Scanning: Neyyattinkara (M01001)\n","      Scanning: Thiruvananthapuram (C01001)\n","      Scanning: Varkala (M01004)\n","   -> [SAVED] Updated Kerala_01_Thiruvananthapuram_2025.csv (Total: 1837 rows)\n","\n","==================================================\n","FIXING DISTRICT: Kollam (02)\n","==================================================\n","   -> Removed 135 old Urban rows. Preserved 0 Panchayat/Block rows.\n","   -> Found 5 Urban Bodies in 'payload'!\n","      Scanning: Karunagappally (M02007)\n","      Scanning: Kollam (C02002)\n","      Scanning: Kottarakkara (M02087)\n","      Scanning: Paravoor (M02005)\n","      Scanning: Punalur (M02006)\n","   -> [SAVED] Updated Kerala_02_Kollam_2025.csv (Total: 191 rows)\n","\n","==================================================\n","FIXING DISTRICT: Pathanamthitta (03)\n","==================================================\n","   -> Removed 85 old Urban rows. Preserved 0 Panchayat/Block rows.\n","   -> Found 4 Urban Bodies in 'payload'!\n","      Scanning: Adoor (M03008)\n","      Scanning: Pandalam (M03061)\n","      Scanning: Pathanamthitta (M03009)\n","      Scanning: Thiruvalla (M03010)\n","   -> [SAVED] Updated Kerala_03_Pathanamthitta_2025.csv (Total: 135 rows)\n","\n","==================================================\n","FIXING DISTRICT: Idukki (06)\n","==================================================\n","   -> Removed 85 old Urban rows. Preserved 0 Panchayat/Block rows.\n","   -> Found 2 Urban Bodies in 'payload'!\n","      Scanning: Kattappana (M06065)\n","      Scanning: Thodupuzha (M06020)\n","   -> [SAVED] Updated Kerala_06_Idukki_2025.csv (Total: 73 rows)\n","\n","==================================================\n","FIXING DISTRICT: Wayanad (12)\n","==================================================\n","   -> Removed 85 old Urban rows. Preserved 0 Panchayat/Block rows.\n","   -> Found 3 Urban Bodies in 'payload'!\n","      Scanning: Kalpetta (M12051)\n","      Scanning: Mananthavadi (M12081)\n","      Scanning: Sulthanbethery (M12082)\n","   -> [SAVED] Updated Kerala_12_Wayanad_2025.csv (Total: 103 rows)\n","\n","==================================================\n","FIXING DISTRICT: Kasaragod (14)\n","==================================================\n","   -> Removed 90 old Urban rows. Preserved 0 Panchayat/Block rows.\n","   -> Found 3 Urban Bodies in 'payload'!\n","      Scanning: Kanhangad (M14058)\n","      Scanning: Kasaragod (M14059)\n","      Scanning: Nileshwar (M14060)\n","   -> [SAVED] Updated Kerala_14_Kasaragod_2025.csv (Total: 120 rows)\n"]}]},{"cell_type":"code","source":["import requests\n","import pandas as pd\n","import time\n","import urllib3\n","import json\n","import os\n","\n","# --- 1. CONFIGURATION ---\n","urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n","\n","URL_HOME = \"https://lbtrend.kerala.gov.in/\"\n","URL_LIST = \"https://lbtrend.kerala.gov.in/includes/stateView2_ajax.php\"\n","URL_DETAILS = \"https://lbtrend.kerala.gov.in/includes/lb_ajax2.php\"\n","\n","HEADERS = {\n","    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36\",\n","    \"X-Requested-With\": \"XMLHttpRequest\",\n","    \"Referer\": \"https://lbtrend.kerala.gov.in/\"\n","}\n","\n","# THE 5 REMAINING DISTRICTS (TVM Removed)\n","DISTRICTS = {\n","    \"02\": \"Kollam\",\n","    \"03\": \"Pathanamthitta\",\n","    \"06\": \"Idukki\",\n","    \"12\": \"Wayanad\",\n","    \"14\": \"Kasaragod\"\n","}\n","\n","# --- 2. HELPER FUNCTIONS ---\n","\n","def deep_search_for_list(data, min_length=1):\n","    \"\"\"Recursive search for standard lists (P, B, D)\"\"\"\n","    candidates = []\n","    if isinstance(data, dict):\n","        for k, v in data.items():\n","            if isinstance(v, list) and len(v) >= min_length:\n","                candidates.append(v)\n","            elif isinstance(v, (dict, list)):\n","                candidates.extend(deep_search_for_list(v, min_length))\n","    elif isinstance(data, list):\n","        for item in data:\n","            if isinstance(item, (dict, list)):\n","                candidates.extend(deep_search_for_list(item, min_length))\n","    return candidates\n","\n","def get_candidates_level_4(session, ward_full_id):\n","    \"\"\"Fetches Level 4 Candidate Data\"\"\"\n","    payload_can = {\"_p\": \"can\", \"_w\": ward_full_id, \"_t\": \"P\", \"_s\": \"L\"}\n","    try:\n","        resp_can = session.post(URL_DETAILS, data=payload_can, verify=False)\n","        can_json = resp_can.json()\n","\n","        # Candidate list is usually in 'payload' or standard structure\n","        can_lists = deep_search_for_list(can_json, min_length=1)\n","\n","        if can_lists:\n","            candidates = max(can_lists, key=len)\n","            best_candidate = None\n","            max_v = -1\n","\n","            for can in candidates:\n","                try:\n","                    # Index 4 is Votes\n","                    votes = int(can[4])\n","                    if votes > max_v:\n","                        max_v = votes\n","                        best_candidate = can\n","                except: pass\n","\n","            if best_candidate:\n","                return best_candidate[0], best_candidate[3], max_v\n","    except:\n","        pass\n","    return \"Unknown\", \"Unknown\", 0\n","\n","# --- 3. MAIN SCRAPER ---\n","\n","def scrape_full_rebuild_final_5():\n","    print(\"--- STARTING FULL REBUILD FOR REMAINING 5 DISTRICTS ---\")\n","\n","    session = requests.Session()\n","    session.headers.update(HEADERS)\n","\n","    try: session.get(URL_HOME, verify=False)\n","    except: pass\n","\n","    for dist_code, dist_name in DISTRICTS.items():\n","        print(f\"\\n==================================================\")\n","        print(f\"REBUILDING: {dist_name} ({dist_code})\")\n","        print(f\"==================================================\")\n","\n","        district_data = []\n","        district_id = f\"D{dist_code}001\"\n","\n","        # ---------------------------------------------------------\n","        # PART A: STANDARD TYPES (Grama, Block, District)\n","        # ---------------------------------------------------------\n","        STANDARD_TYPES = [\n","            {\"code\": \"P\", \"name\": \"Grama Panchayat\"},\n","            {\"code\": \"B\", \"name\": \"Block Panchayat\"},\n","            {\"code\": \"D\", \"name\": \"District Panchayat\"}\n","        ]\n","\n","        for b_type in STANDARD_TYPES:\n","            type_code = b_type['code']\n","            type_name = b_type['name']\n","            print(f\"   >>> Scanning {type_name} ('{type_code}')...\")\n","\n","            payload_list = {\"_p\": \"dv\", \"_l\": type_code, \"_d\": district_id, \"_s\": \"L\"}\n","            try:\n","                resp = session.post(URL_LIST, data=payload_list, verify=False)\n","                data_list = resp.json()\n","                found_lists = deep_search_for_list(data_list, min_length=1)\n","\n","                if not found_lists:\n","                    print(\"      -> No bodies found.\")\n","                    continue\n","\n","                raw_list = max(found_lists, key=len)\n","\n","                # Deduplication logic\n","                seen_ids = set()\n","                bodies_to_scan = []\n","                for item in raw_list:\n","                    lb_id = None\n","                    lb_name = \"Unknown\"\n","                    for col in item:\n","                        s_col = str(col)\n","                        if len(s_col) > 4 and s_col[0] in ['G','B','D'] and s_col[1].isdigit():\n","                            lb_id = s_col\n","                            break\n","                    if not lb_id: lb_id = str(item[0])\n","\n","                    if lb_name == \"Unknown\":\n","                        for col in item:\n","                            if isinstance(col, str) and col != lb_id and len(col) > 3:\n","                                lb_name = col\n","                                break\n","\n","                    if lb_id and lb_id not in seen_ids:\n","                        seen_ids.add(lb_id)\n","                        bodies_to_scan.append({'id': lb_id, 'name': lb_name})\n","\n","                # Process Bodies\n","                for i, body in enumerate(bodies_to_scan):\n","                    payload_w = {\"_p\": \"wv\", \"_w\": body['id'], \"_t\": \"P\", \"_s\": \"L\"}\n","                    try:\n","                        resp_w = session.post(URL_DETAILS, data=payload_w, verify=False)\n","                        w_lists = deep_search_for_list(resp_w.json(), min_length=1)\n","                        if not w_lists: continue\n","\n","                        wards = max(w_lists, key=len)\n","                        for w in wards:\n","                            # Extract Ward Data\n","                            ward_id = str(w[0])\n","                            front = str(w[1])\n","                            w_name = str(w[5]) if len(w)>5 else str(w[2])\n","                            try: w_num = str(int(ward_id[-3:]))\n","                            except: w_num = \"0\"\n","\n","                            # Level 4\n","                            party, c_name, votes = get_candidates_level_4(session, ward_id)\n","                            if party == \"Unknown\": party = front\n","\n","                            district_data.append({\n","                                \"District\": dist_name,\n","                                \"Local Body Type\": type_name,\n","                                \"Local Body ID\": body['id'],\n","                                \"Local Body\": body['name'],\n","                                \"Ward Number\": w_num,\n","                                \"Ward Name\": w_name,\n","                                \"Candidate\": c_name,\n","                                \"Party\": party,\n","                                \"Front\": front,\n","                                \"Votes\": votes,\n","                                \"Year\": 2025\n","                            })\n","                    except: pass\n","                print(f\"      -> Completed {type_name}\")\n","\n","            except Exception as e:\n","                print(f\"      -> Error: {e}\")\n","\n","        # ---------------------------------------------------------\n","        # PART B: URBAN BODIES (Muni/Corp) - PAYLOAD METHOD\n","        # ---------------------------------------------------------\n","        print(f\"   >>> Scanning Urban Bodies (Payload Method)...\")\n","        payload_urban = {\"_p\": \"dv\", \"_l\": \"C\", \"_d\": district_id, \"_s\": \"L\"}\n","\n","        try:\n","            resp = session.post(URL_LIST, data=payload_urban, verify=False)\n","            u_json = resp.json()\n","            target_list = u_json.get('payload', [])\n","\n","            if target_list:\n","                print(f\"      -> Found {len(target_list)} Urban Bodies.\")\n","                for body in target_list:\n","                    lb_id = str(body[0])\n","                    lb_name = str(body[1]).strip()\n","                    if \"Total\" in lb_id: continue\n","\n","                    print(f\"      Processing: {lb_name} ({lb_id})\")\n","\n","                    # Fetch Wards\n","                    payload_w = {\"_p\": \"wv\", \"_w\": lb_id, \"_t\": \"P\", \"_s\": \"L\"}\n","                    try:\n","                        resp_w = session.post(URL_DETAILS, data=payload_w, verify=False)\n","                        w_json = resp_w.json()\n","                        w_list = w_json.get('payload', [])\n","                        if not w_list:\n","                            w_deep = deep_search_for_list(w_json, min_length=1)\n","                            if w_deep: w_list = max(w_deep, key=len)\n","\n","                        if w_list:\n","                            for w in w_list:\n","                                ward_id = str(w[0])\n","                                front = str(w[1])\n","                                w_name = str(w[5]) if len(w)>5 else str(w[2])\n","                                try: w_num = str(int(ward_id[-3:]))\n","                                except: w_num = \"0\"\n","\n","                                party, c_name, votes = get_candidates_level_4(session, ward_id)\n","                                if party == \"Unknown\": party = front\n","\n","                                district_data.append({\n","                                    \"District\": dist_name,\n","                                    \"Local Body Type\": \"Municipality/Corporation\",\n","                                    \"Local Body ID\": lb_id,\n","                                    \"Local Body\": lb_name,\n","                                    \"Ward Number\": w_num,\n","                                    \"Ward Name\": w_name,\n","                                    \"Candidate\": c_name,\n","                                    \"Party\": party,\n","                                    \"Front\": front,\n","                                    \"Votes\": votes,\n","                                    \"Year\": 2025\n","                                })\n","                    except: pass\n","            else:\n","                print(\"      -> No Urban Bodies found in payload.\")\n","\n","        except Exception as e:\n","            print(f\"      -> Urban Error: {e}\")\n","\n","        # ---------------------------------------------------------\n","        # SAVE FILE\n","        # ---------------------------------------------------------\n","        if district_data:\n","            filename = f\"Kerala_{dist_code}_{dist_name}_2025.csv\"\n","            df = pd.DataFrame(district_data)\n","            df.to_csv(filename, index=False, encoding='utf-8-sig')\n","            print(f\"   -> [SUCCESS] Saved {filename} with {len(df)} rows.\")\n","        else:\n","            print(\"   -> [ERROR] No data collected!\")\n","\n","if __name__ == \"__main__\":\n","    scrape_full_rebuild_final_5()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OvGePXzAPay1","executionInfo":{"status":"ok","timestamp":1766344087634,"user_tz":-330,"elapsed":569682,"user":{"displayName":"FARHAN JAFFAR","userId":"00674461129948116447"}},"outputId":"aeb471fc-2c5a-48c4-ed15-b216540e7b77"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--- STARTING FULL REBUILD FOR REMAINING 5 DISTRICTS ---\n","\n","==================================================\n","REBUILDING: Kollam (02)\n","==================================================\n","   >>> Scanning Grama Panchayat ('P')...\n","      -> Completed Grama Panchayat\n","   >>> Scanning Block Panchayat ('B')...\n","      -> Completed Block Panchayat\n","   >>> Scanning District Panchayat ('D')...\n","      -> Completed District Panchayat\n","   >>> Scanning Urban Bodies (Payload Method)...\n","      -> Found 5 Urban Bodies.\n","      Processing: Karunagappally (M02007)\n","      Processing: Kollam (C02002)\n","      Processing: Kottarakkara (M02087)\n","      Processing: Paravoor (M02005)\n","      Processing: Punalur (M02006)\n","   -> [SUCCESS] Saved Kerala_02_Kollam_2025.csv with 1698 rows.\n","\n","==================================================\n","REBUILDING: Pathanamthitta (03)\n","==================================================\n","   >>> Scanning Grama Panchayat ('P')...\n","      -> Completed Grama Panchayat\n","   >>> Scanning Block Panchayat ('B')...\n","      -> Completed Block Panchayat\n","   >>> Scanning District Panchayat ('D')...\n","      -> Completed District Panchayat\n","   >>> Scanning Urban Bodies (Payload Method)...\n","      -> Found 4 Urban Bodies.\n","      Processing: Adoor (M03008)\n","      Processing: Pandalam (M03061)\n","      Processing: Pathanamthitta (M03009)\n","      Processing: Thiruvalla (M03010)\n","   -> [SUCCESS] Saved Kerala_03_Pathanamthitta_2025.csv with 1099 rows.\n","\n","==================================================\n","REBUILDING: Idukki (06)\n","==================================================\n","   >>> Scanning Grama Panchayat ('P')...\n","      -> Completed Grama Panchayat\n","   >>> Scanning Block Panchayat ('B')...\n","      -> Completed Block Panchayat\n","   >>> Scanning District Panchayat ('D')...\n","      -> Completed District Panchayat\n","   >>> Scanning Urban Bodies (Payload Method)...\n","      -> Found 2 Urban Bodies.\n","      Processing: Kattappana (M06065)\n","      Processing: Thodupuzha (M06020)\n","   -> [SUCCESS] Saved Kerala_06_Idukki_2025.csv with 1036 rows.\n","\n","==================================================\n","REBUILDING: Wayanad (12)\n","==================================================\n","   >>> Scanning Grama Panchayat ('P')...\n","      -> Completed Grama Panchayat\n","   >>> Scanning Block Panchayat ('B')...\n","      -> Completed Block Panchayat\n","   >>> Scanning District Panchayat ('D')...\n","      -> Completed District Panchayat\n","   >>> Scanning Urban Bodies (Payload Method)...\n","      -> Found 3 Urban Bodies.\n","      Processing: Kalpetta (M12051)\n","      Processing: Mananthavadi (M12081)\n","      Processing: Sulthanbethery (M12082)\n","   -> [SUCCESS] Saved Kerala_12_Wayanad_2025.csv with 587 rows.\n","\n","==================================================\n","REBUILDING: Kasaragod (14)\n","==================================================\n","   >>> Scanning Grama Panchayat ('P')...\n","      -> Completed Grama Panchayat\n","   >>> Scanning Block Panchayat ('B')...\n","      -> Completed Block Panchayat\n","   >>> Scanning District Panchayat ('D')...\n","      -> Completed District Panchayat\n","   >>> Scanning Urban Bodies (Payload Method)...\n","      -> Found 3 Urban Bodies.\n","      Processing: Kanhangad (M14058)\n","      Processing: Kasaragod (M14059)\n","      Processing: Nileshwar (M14060)\n","   -> [SUCCESS] Saved Kerala_14_Kasaragod_2025.csv with 955 rows.\n"]}]},{"cell_type":"markdown","source":["Combaing all 14 districts"],"metadata":{"id":"MEXuYjn0Nagy"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1345,"status":"ok","timestamp":1766333452156,"user":{"displayName":"FARHAN JAFFAR","userId":"00674461129948116447"},"user_tz":-330},"id":"C5QorxQkrX41","outputId":"78d077bd-177c-4e66-98b9-e21c5111bf3f"},"outputs":[{"name":"stdout","output_type":"stream","text":["--- COMBINING 14 DISTRICT FILES ---\n","Found 14 files: ['Kerala_03_Pathanamthitta_2025.csv', 'Kerala_04_Alappuzha_2025.csv', 'Kerala_08_Thrissur_2025.csv', 'Kerala_09_Palakkad_2025.csv', 'Kerala_13_Kannur_2025.csv', 'Kerala_01_Thiruvananthapuram_2025.csv', 'Kerala_14_Kasaragod_2025.csv', 'Kerala_05_Kottayam_2025.csv', 'Kerala_11_Kozhikode_2025.csv', 'Kerala_07_Ernakulam_2025.csv', 'Kerala_12_Wayanad_2025.csv', 'Kerala_06_Idukki_2025.csv', 'Kerala_10_Malappuram_2025.csv', 'Kerala_02_Kollam_2025.csv']\n","   -> Loaded Kerala_03_Pathanamthitta_2025.csv (981 rows)\n","   -> Loaded Kerala_04_Alappuzha_2025.csv (1666 rows)\n","   -> Loaded Kerala_08_Thrissur_2025.csv (2204 rows)\n","   -> Loaded Kerala_09_Palakkad_2025.csv (2116 rows)\n","   -> Loaded Kerala_13_Kannur_2025.csv (1812 rows)\n","   -> Loaded Kerala_01_Thiruvananthapuram_2025.csv (1611 rows)\n","   -> Loaded Kerala_14_Kasaragod_2025.csv (853 rows)\n","   -> Loaded Kerala_05_Kottayam_2025.csv (1611 rows)\n","   -> Loaded Kerala_11_Kozhikode_2025.csv (1903 rows)\n","   -> Loaded Kerala_07_Ernakulam_2025.csv (2219 rows)\n","   -> Loaded Kerala_12_Wayanad_2025.csv (501 rows)\n","   -> Loaded Kerala_06_Idukki_2025.csv (980 rows)\n","   -> Loaded Kerala_10_Malappuram_2025.csv (2788 rows)\n","   -> Loaded Kerala_02_Kollam_2025.csv (1534 rows)\n","\n","--- APPLYING DATA CLEANING ---\n","   -> Fixed 14 rows for 'Ala' Grama Panchayat (G04040).\n","\n","--- SUCCESS! ---\n","Combined File Saved: Kerala_LocalBodies_Election_2025_MASTER.csv\n","Total Rows: 22779\n","Total Districts: 14\n"]}],"source":["import pandas as pd\n","import glob\n","import os\n","\n","def combine_kerala_election_data():\n","    print(\"--- COMBINING 14 DISTRICT FILES ---\")\n","\n","    # 1. Find all district CSV files\n","    # Matches patterns like \"Kerala_01_Thiruvananthapuram_2025.csv\"\n","    all_files = glob.glob(\"Kerala_*_2025.csv\")\n","\n","    if not all_files:\n","        print(\"[ERROR] No CSV files found! Make sure you are in the correct directory.\")\n","        return\n","\n","    print(f\"Found {len(all_files)} files: {all_files}\")\n","\n","    # 2. Read and Concatenate\n","    df_list = []\n","    for filename in all_files:\n","        try:\n","            df = pd.read_csv(filename)\n","            df_list.append(df)\n","            print(f\"   -> Loaded {filename} ({len(df)} rows)\")\n","        except Exception as e:\n","            print(f\"   -> Error reading {filename}: {e}\")\n","\n","    if not df_list:\n","        return\n","\n","    master_df = pd.concat(df_list, ignore_index=True)\n","\n","    # 3. APPLY FIXES (Data Cleaning)\n","    print(\"\\n--- APPLYING DATA CLEANING ---\")\n","\n","    # Fix 1: Alappuzha \"Ala\" Grama Panchayat (G04040) which was \"Unknown\"\n","    # We check if ID is G04040 and name is Unknown, then replace with 'Ala'\n","    mask_ala = (master_df['Local Body ID'] == 'G04040') & (master_df['Local Body'] == 'Unknown')\n","    if mask_ala.any():\n","        master_df.loc[mask_ala, 'Local Body'] = 'Ala'\n","        print(f\"   -> Fixed {mask_ala.sum()} rows for 'Ala' Grama Panchayat (G04040).\")\n","    else:\n","        print(\"   -> 'Ala' fix not needed (already correct or not found).\")\n","\n","    # 4. SAVE MASTER FILE\n","    output_filename = \"Kerala_LocalBodies_Election_2025_MASTER.csv\"\n","    master_df.to_csv(output_filename, index=False, encoding='utf-8-sig')\n","\n","    print(f\"\\n--- SUCCESS! ---\")\n","    print(f\"Combined File Saved: {output_filename}\")\n","    print(f\"Total Rows: {len(master_df)}\")\n","    print(f\"Total Districts: {master_df['District'].nunique()}\")\n","\n","    return master_df\n","\n","# Run the function\n","df_master = combine_kerala_election_data()"]},{"cell_type":"markdown","metadata":{"id":"Pvy2mWdRue8z"},"source":["Starting 2020 Election Scaping"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1646,"status":"ok","timestamp":1766334289684,"user":{"displayName":"FARHAN JAFFAR","userId":"00674461129948116447"},"user_tz":-330},"id":"6ErEyDbLukIx","outputId":"22250b6a-6ce5-4db1-8042-e79ed9f5444a"},"outputs":[{"name":"stdout","output_type":"stream","text":["--- INSPECTING 2020 SITE STRUCTURE ---\n","Target: https://www.sec.kerala.gov.in/results/trend2020/views/index.php\n","Connection Status: 200\n","[WARNING] No dropdowns found in HTML. They might be loaded via AJAX.\n"]}],"source":["import requests\n","from bs4 import BeautifulSoup\n","import urllib3\n","\n","# Setup\n","urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n","URL_2020 = \"https://www.sec.kerala.gov.in/results/trend2020/views/index.php\"\n","\n","def inspect_2020_structure():\n","    print(f\"--- INSPECTING 2020 SITE STRUCTURE ---\")\n","    print(f\"Target: {URL_2020}\")\n","\n","    try:\n","        # 1. Fetch Homepage\n","        # We use verify=False because government certs often expire\n","        resp = requests.get(URL_2020, verify=False)\n","        print(f\"Connection Status: {resp.status_code}\")\n","\n","        soup = BeautifulSoup(resp.text, 'html.parser')\n","\n","        # 2. Find Dropdowns (Select tags)\n","        selects = soup.find_all('select')\n","\n","        if not selects:\n","            print(\"[WARNING] No dropdowns found in HTML. They might be loaded via AJAX.\")\n","\n","        for i, sel in enumerate(selects):\n","            name = sel.get('name') or sel.get('id') or f\"Unnamed_{i}\"\n","            options = sel.find_all('option')\n","\n","            print(f\"\\n[{i+1}] DROPDOWN FOUND: '{name}'\")\n","            print(f\"    Total Options: {len(options)}\")\n","\n","            # Print first 5 options to verify IDs\n","            print(\"    Sample Values:\")\n","            for opt in options[:5]:\n","                val = opt.get('value')\n","                txt = opt.text.strip()\n","                if val:\n","                    print(f\"      Code: '{val}' -> Name: '{txt}'\")\n","\n","            # Check specifically for Malappuram\n","            for opt in options:\n","                if \"Malappuram\" in opt.text:\n","                    print(f\"    [KEY INFO] Malappuram Code is: '{opt.get('value')}'\")\n","                    break\n","\n","    except Exception as e:\n","        print(f\"Error: {e}\")\n","\n","if __name__ == \"__main__\":\n","    inspect_2020_structure()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"9UsEbRZ_vcZO","outputId":"b301a1d2-54c5-4927-f26f-dd117351c882"},"outputs":[{"name":"stdout","output_type":"stream","text":["--- STARTING UNIVERSAL KERALA ELECTION SCRAPER 2020 ---\n","Target Base URL: https://www.sec.kerala.gov.in/results/trend2020/\n","1. Session Initialized.\n","\n","==================================================\n","PROCESSING DISTRICT: Thiruvananthapuram (01)\n","==================================================\n","\n","   >>> Scanning Type: Grama Panchayat ('P')\n","      -> Found 73 unique bodies.\n","\n","      -> Finished Grama Panchayat\n","\n","   >>> Scanning Type: Block Panchayat ('B')\n","      -> Found 11 unique bodies.\n","\n","      -> Finished Block Panchayat\n","\n","   >>> Scanning Type: District Panchayat ('D')\n","      -> Found 1 unique bodies.\n","\n","      -> Finished District Panchayat\n","\n","   >>> Scanning Type: Municipality/Corporation ('C')\n","      -> Found 1 unique bodies.\n","\n","      -> Finished Municipality/Corporation\n","\n","[SAVED] Kerala_01_Thiruvananthapuram_2020.csv with 1503 rows.\n","\n","==================================================\n","PROCESSING DISTRICT: Kollam (02)\n","==================================================\n","\n","   >>> Scanning Type: Grama Panchayat ('P')\n","      -> Found 68 unique bodies.\n","\n","      -> Finished Grama Panchayat\n","\n","   >>> Scanning Type: Block Panchayat ('B')\n","      -> Found 11 unique bodies.\n","\n","      -> Finished Block Panchayat\n","\n","   >>> Scanning Type: District Panchayat ('D')\n","      -> Found 1 unique bodies.\n","\n","      -> Finished District Panchayat\n","\n","   >>> Scanning Type: Municipality/Corporation ('C')\n","      -> Found 1 unique bodies.\n","\n","      -> Finished Municipality/Corporation\n","\n","[SAVED] Kerala_02_Kollam_2020.csv with 1435 rows.\n","\n","==================================================\n","PROCESSING DISTRICT: Pathanamthitta (03)\n","==================================================\n","\n","   >>> Scanning Type: Grama Panchayat ('P')\n","      -> Found 53 unique bodies.\n","\n","      -> Finished Grama Panchayat\n","\n","   >>> Scanning Type: Block Panchayat ('B')\n","      -> Found 8 unique bodies.\n","\n","      -> Finished Block Panchayat\n","\n","   >>> Scanning Type: District Panchayat ('D')\n","      -> Found 1 unique bodies.\n","\n","      -> Finished District Panchayat\n","\n","   >>> Scanning Type: Municipality/Corporation ('C')\n","      -> Found 1 unique bodies.\n","\n","      -> Finished Municipality/Corporation\n","\n","[SAVED] Kerala_03_Pathanamthitta_2020.csv with 926 rows.\n","\n","==================================================\n","PROCESSING DISTRICT: Alappuzha (04)\n","==================================================\n","\n","   >>> Scanning Type: Grama Panchayat ('P')\n","      -> Found 72 unique bodies.\n","\n","      -> Finished Grama Panchayat\n","\n","   >>> Scanning Type: Block Panchayat ('B')\n","      -> Found 12 unique bodies.\n","\n","      -> Finished Block Panchayat\n","\n","   >>> Scanning Type: District Panchayat ('D')\n","      -> Found 1 unique bodies.\n","\n","      -> Finished District Panchayat\n","\n","   >>> Scanning Type: Municipality/Corporation ('C')\n","      -> Found 6 unique bodies.\n","\n","      -> Finished Municipality/Corporation\n","\n","[SAVED] Kerala_04_Alappuzha_2020.csv with 1564 rows.\n","\n","==================================================\n","PROCESSING DISTRICT: Kottayam (05)\n","==================================================\n","\n","   >>> Scanning Type: Grama Panchayat ('P')\n","      -> Found 71 unique bodies.\n","\n","      -> Finished Grama Panchayat\n","\n","   >>> Scanning Type: Block Panchayat ('B')\n","      -> Found 11 unique bodies.\n","\n","      -> Finished Block Panchayat\n","\n","   >>> Scanning Type: District Panchayat ('D')\n","      -> Found 1 unique bodies.\n","\n","      -> Finished District Panchayat\n","\n","   >>> Scanning Type: Municipality/Corporation ('C')\n","      -> Found 6 unique bodies.\n","\n","      -> Finished Municipality/Corporation\n","\n","[SAVED] Kerala_05_Kottayam_2020.csv with 1510 rows.\n","\n","==================================================\n","PROCESSING DISTRICT: Idukki (06)\n","==================================================\n","\n","   >>> Scanning Type: Grama Panchayat ('P')\n","      -> Found 52 unique bodies.\n","\n","      -> Finished Grama Panchayat\n","\n","   >>> Scanning Type: Block Panchayat ('B')\n","      -> Found 8 unique bodies.\n","\n","      -> Finished Block Panchayat\n","\n","   >>> Scanning Type: District Panchayat ('D')\n","      -> Found 1 unique bodies.\n","\n","      -> Finished District Panchayat\n","\n","   >>> Scanning Type: Municipality/Corporation ('C')\n","      -> Found 1 unique bodies.\n","\n","      -> Finished Municipality/Corporation\n","\n","[SAVED] Kerala_06_Idukki_2020.csv with 925 rows.\n","\n","==================================================\n","PROCESSING DISTRICT: Ernakulam (07)\n","==================================================\n","\n","   >>> Scanning Type: Grama Panchayat ('P')\n","      -> Found 82 unique bodies.\n","\n","      -> Finished Grama Panchayat\n","\n","   >>> Scanning Type: Block Panchayat ('B')\n","      -> Found 14 unique bodies.\n","\n","      -> Finished Block Panchayat\n","\n","   >>> Scanning Type: District Panchayat ('D')\n","      -> Found 1 unique bodies.\n","\n","      -> Finished District Panchayat\n","\n","   >>> Scanning Type: Municipality/Corporation ('C')\n","      -> Found 14 unique bodies.\n","\n","      -> Finished Municipality/Corporation\n","\n","[SAVED] Kerala_07_Ernakulam_2020.csv with 2043 rows.\n","\n","==================================================\n","PROCESSING DISTRICT: Thrissur (08)\n","==================================================\n","\n","   >>> Scanning Type: Grama Panchayat ('P')\n","      -> Found 86 unique bodies.\n","\n","      -> Finished Grama Panchayat\n","\n","   >>> Scanning Type: Block Panchayat ('B')\n","      -> Found 16 unique bodies.\n","\n","      -> Finished Block Panchayat\n","\n","   >>> Scanning Type: District Panchayat ('D')\n","      -> Found 1 unique bodies.\n","\n","      -> Finished District Panchayat\n","\n","   >>> Scanning Type: Municipality/Corporation ('C')\n","      -> Found 8 unique bodies.\n","\n","      -> Finished Municipality/Corporation\n","\n","[SAVED] Kerala_08_Thrissur_2020.csv with 2033 rows.\n","\n","==================================================\n","PROCESSING DISTRICT: Palakkad (09)\n","==================================================\n","\n","   >>> Scanning Type: Grama Panchayat ('P')\n","      -> Found 88 unique bodies.\n","\n","      -> Finished Grama Panchayat\n","\n","   >>> Scanning Type: Block Panchayat ('B')\n","      -> Found 13 unique bodies.\n","\n","      -> Finished Block Panchayat\n","\n","   >>> Scanning Type: District Panchayat ('D')\n","      -> Found 1 unique bodies.\n","\n","      -> Finished District Panchayat\n","\n","   >>> Scanning Type: Municipality/Corporation ('C')\n","      -> Found 7 unique bodies.\n","\n","      -> Finished Municipality/Corporation\n","\n","[SAVED] Kerala_09_Palakkad_2020.csv with 1937 rows.\n","\n","==================================================\n","PROCESSING DISTRICT: Malappuram (10)\n","==================================================\n","\n","   >>> Scanning Type: Grama Panchayat ('P')\n","      -> Found 94 unique bodies.\n","\n","      -> Finished Grama Panchayat\n","\n","   >>> Scanning Type: Block Panchayat ('B')\n","      -> Found 15 unique bodies.\n","\n","      -> Finished Block Panchayat\n","\n","   >>> Scanning Type: District Panchayat ('D')\n","      -> Found 1 unique bodies.\n","\n","      -> Finished District Panchayat\n","\n","   >>> Scanning Type: Municipality/Corporation ('C')\n","      -> Found 12 unique bodies.\n","\n","      -> Finished Municipality/Corporation\n","\n","[SAVED] Kerala_10_Malappuram_2020.csv with 2498 rows.\n","\n","==================================================\n","PROCESSING DISTRICT: Kozhikode (11)\n","==================================================\n","\n","   >>> Scanning Type: Grama Panchayat ('P')\n","      -> Found 70 unique bodies.\n","\n","      -> Finished Grama Panchayat\n","\n","   >>> Scanning Type: Block Panchayat ('B')\n","      -> Found 12 unique bodies.\n","\n","      -> Finished Block Panchayat\n","\n","   >>> Scanning Type: District Panchayat ('D')\n","      -> Found 1 unique bodies.\n","\n","      -> Finished District Panchayat\n","\n","   >>> Scanning Type: Municipality/Corporation ('C')\n","      -> Found 8 unique bodies.\n","\n","      -> Finished Municipality/Corporation\n","\n","[SAVED] Kerala_11_Kozhikode_2020.csv with 1759 rows.\n","\n","==================================================\n","PROCESSING DISTRICT: Wayanad (12)\n","==================================================\n","\n","   >>> Scanning Type: Grama Panchayat ('P')\n","      -> Found 23 unique bodies.\n","\n","      -> Finished Grama Panchayat\n","\n","   >>> Scanning Type: Block Panchayat ('B')\n","      -> Found 1 unique bodies.\n","\n","      -> Finished Block Panchayat\n","\n","   >>> Scanning Type: District Panchayat ('D')\n","      -> Found 1 unique bodies.\n","\n","      -> Finished District Panchayat\n","\n","   >>> Scanning Type: Municipality/Corporation ('C')\n","      -> Found 1 unique bodies.\n","\n","      -> Finished Municipality/Corporation\n","\n","[SAVED] Kerala_12_Wayanad_2020.csv with 461 rows.\n","\n","==================================================\n","PROCESSING DISTRICT: Kannur (13)\n","==================================================\n","\n","   >>> Scanning Type: Grama Panchayat ('P')\n","      -> Found 71 unique bodies.\n","\n","      -> Finished Grama Panchayat\n","\n","   >>> Scanning Type: Block Panchayat ('B')\n","      -> Found 11 unique bodies.\n","\n","      -> Finished Block Panchayat\n","\n","   >>> Scanning Type: District Panchayat ('D')\n","      -> Found 1 unique bodies.\n","\n","      -> Finished District Panchayat\n","\n","   >>> Scanning Type: Municipality/Corporation ('C')\n","      -> Found 9 unique bodies.\n","\n","      -> Finished Municipality/Corporation\n","\n","[SAVED] Kerala_13_Kannur_2020.csv with 1681 rows.\n","\n","==================================================\n","PROCESSING DISTRICT: Kasaragod (14)\n","==================================================\n","\n","   >>> Scanning Type: Grama Panchayat ('P')\n","      -> Found 38 unique bodies.\n","\n","      -> Finished Grama Panchayat\n","\n","   >>> Scanning Type: Block Panchayat ('B')\n","      -> Found 6 unique bodies.\n","\n","      -> Finished Block Panchayat\n","\n","   >>> Scanning Type: District Panchayat ('D')\n","      -> Found 1 unique bodies.\n","\n","      -> Finished District Panchayat\n","\n","   >>> Scanning Type: Municipality/Corporation ('C')\n","      -> Found 1 unique bodies.\n","\n","      -> Finished Municipality/Corporation\n","\n","[SAVED] Kerala_14_Kasaragod_2020.csv with 780 rows.\n"]}],"source":["import requests\n","import pandas as pd\n","import time\n","import urllib3\n","import json\n","import os\n","\n","# --- 1. CONFIGURATION ---\n","urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n","\n","# *** CRITICAL CHANGE: 2020 URLS ***\n","BASE_URL = \"https://www.sec.kerala.gov.in/results/trend2020/\"\n","URL_HOME = BASE_URL + \"views/index.php\"\n","URL_LIST = BASE_URL + \"includes/stateView2_ajax.php\"\n","URL_DETAILS = BASE_URL + \"includes/lb_ajax2.php\"\n","\n","HEADERS = {\n","    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36\",\n","    \"X-Requested-With\": \"XMLHttpRequest\",\n","    \"Referer\": URL_HOME\n","}\n","\n","# DISTRICT MAP (Standard)\n","DISTRICTS = {\n","    \"01\": \"Thiruvananthapuram\", \"02\": \"Kollam\", \"03\": \"Pathanamthitta\",\n","    \"04\": \"Alappuzha\", \"05\": \"Kottayam\", \"06\": \"Idukki\", \"07\": \"Ernakulam\",\n","    \"08\": \"Thrissur\", \"09\": \"Palakkad\", \"10\": \"Malappuram\", \"11\": \"Kozhikode\",\n","    \"12\": \"Wayanad\", \"13\": \"Kannur\", \"14\": \"Kasaragod\"\n","}\n","\n","# BODY TYPES (Same as 2025)\n","BODY_TYPES = [\n","    {\"code\": \"P\", \"name\": \"Grama Panchayat\"},\n","    {\"code\": \"B\", \"name\": \"Block Panchayat\"},\n","    {\"code\": \"D\", \"name\": \"District Panchayat\"},\n","    {\"code\": \"C\", \"name\": \"Municipality/Corporation\"}\n","]\n","\n","# --- 2. HELPER FUNCTIONS ---\n","\n","def deep_search_for_list(data, min_length=1):\n","    candidates = []\n","    if isinstance(data, dict):\n","        for k, v in data.items():\n","            if isinstance(v, list) and len(v) >= min_length:\n","                candidates.append(v)\n","            elif isinstance(v, (dict, list)):\n","                candidates.extend(deep_search_for_list(v, min_length))\n","    elif isinstance(data, list):\n","        for item in data:\n","            if isinstance(item, (dict, list)):\n","                candidates.extend(deep_search_for_list(item, min_length))\n","    return candidates\n","\n","def get_candidates_level_4(session, ward_full_id):\n","    \"\"\"Fetches Level 4 Candidate Data (Party/Name/Votes)\"\"\"\n","    payload_can = {\n","        \"_p\": \"can\", \"_w\": ward_full_id, \"_t\": \"P\", \"_s\": \"L\"\n","    }\n","    try:\n","        resp_can = session.post(URL_DETAILS, data=payload_can, verify=False)\n","        can_json = resp_can.json()\n","        can_lists = deep_search_for_list(can_json, min_length=1)\n","\n","        if can_lists:\n","            candidates = max(can_lists, key=len)\n","            best_candidate = None\n","            max_v = -1\n","\n","            for can in candidates:\n","                try:\n","                    # SCHEMA CHECK:\n","                    # In 2025, Index 4 was votes.\n","                    # If 2020 is exact replica, this holds true.\n","                    votes = int(can[4])\n","                    if votes > max_v:\n","                        max_v = votes\n","                        best_candidate = can\n","                except:\n","                    pass\n","\n","            if best_candidate:\n","                # Index 0: Party, Index 3: Name\n","                return best_candidate[0], best_candidate[3], max_v\n","    except:\n","        pass\n","\n","    return \"Unknown\", \"Unknown\", 0\n","\n","# --- 3. MAIN SCRAPER (2020 EDITION) ---\n","\n","def scrape_all_districts_2020():\n","    print(\"--- STARTING UNIVERSAL KERALA ELECTION SCRAPER 2020 ---\")\n","    print(f\"Target Base URL: {BASE_URL}\")\n","\n","    session = requests.Session()\n","    session.headers.update(HEADERS)\n","\n","    # Init Session\n","    try:\n","        session.get(URL_HOME, verify=False)\n","        print(\"1. Session Initialized.\")\n","    except:\n","        print(\"Warning: Session init failed.\")\n","\n","    # --- OUTER LOOP: DISTRICTS ---\n","    for dist_code, dist_name in DISTRICTS.items():\n","        print(f\"\\n==================================================\")\n","        print(f\"PROCESSING DISTRICT: {dist_name} ({dist_code})\")\n","        print(f\"==================================================\")\n","\n","        district_data = []\n","        district_id = f\"D{dist_code}001\"\n","\n","        # --- INNER LOOP: BODY TYPES ---\n","        for b_type in BODY_TYPES:\n","            type_code = b_type['code']\n","            type_name = b_type['name']\n","\n","            print(f\"\\n   >>> Scanning Type: {type_name} ('{type_code}')\")\n","\n","            # 1. Fetch List of Bodies\n","            payload_list = {\n","                \"_p\": \"dv\", \"_l\": type_code, \"_d\": district_id, \"_s\": \"L\"\n","            }\n","\n","            local_bodies = []\n","            try:\n","                resp = session.post(URL_LIST, data=payload_list, verify=False)\n","                # DEBUG: Check if we got redirected (often happens on legacy sites)\n","                if resp.url != URL_LIST:\n","                    print(\"      [ERROR] Redirected to login/home. API might be blocked.\")\n","                    continue\n","\n","                data_list = resp.json()\n","                found_lists = deep_search_for_list(data_list, min_length=1)\n","\n","                if found_lists:\n","                    raw_list = max(found_lists, key=len)\n","\n","                    # Deduplication & ID Extraction\n","                    seen_ids = set()\n","                    for item in raw_list:\n","                        lb_id = None\n","                        lb_name = \"Unknown\"\n","\n","                        for col in item:\n","                            s_col = str(col)\n","                            if len(s_col) > 4 and s_col[0] in ['G','B','D','M','C'] and s_col[1].isdigit():\n","                                lb_id = s_col\n","                                break\n","\n","                        if not lb_id: lb_id = str(item[0])\n","\n","                        if lb_name == \"Unknown\":\n","                            for col in item:\n","                                if isinstance(col, str) and col != lb_id and len(col) > 3:\n","                                    lb_name = col\n","                                    break\n","\n","                        if lb_id and lb_id not in seen_ids:\n","                            seen_ids.add(lb_id)\n","                            local_bodies.append({'id': lb_id, 'name': lb_name})\n","\n","                    print(f\"      -> Found {len(local_bodies)} unique bodies.\")\n","                else:\n","                    print(f\"      -> No bodies found (Empty list).\")\n","                    continue\n","\n","            except Exception as e:\n","                print(f\"      -> Error: {e}\")\n","                continue\n","\n","            # 2. Loop Through Each Body\n","            for i, body in enumerate(local_bodies):\n","                lb_id = body['id']\n","                lb_name = body['name']\n","\n","                print(f\"      [{i+1}/{len(local_bodies)}] {lb_name} ({lb_id})\", end=\"\\r\")\n","\n","                # Fetch Wards\n","                payload_wards = {\n","                    \"_p\": \"wv\", \"_w\": lb_id, \"_t\": \"P\", \"_s\": \"L\"\n","                }\n","\n","                try:\n","                    resp_wards = session.post(URL_DETAILS, data=payload_wards, verify=False)\n","                    wards_json = resp_wards.json()\n","                    ward_lists = deep_search_for_list(wards_json, min_length=1)\n","\n","                    if not ward_lists: continue\n","\n","                    wards = max(ward_lists, key=len)\n","\n","                    for w in wards:\n","                        ward_full_id = str(w[0])\n","                        front_affiliation = str(w[1])\n","\n","                        # Name/Num Extraction\n","                        ward_name = \"Unknown\"\n","                        if len(w) > 5: ward_name = str(w[5])\n","                        elif len(w) > 2: ward_name = str(w[2])\n","\n","                        try:\n","                            ward_num = str(int(ward_full_id[-3:]))\n","                        except:\n","                            ward_num = \"0\"\n","\n","                        # Level 4: Candidate\n","                        c_party, c_name, c_votes = get_candidates_level_4(session, ward_full_id)\n","\n","                        if c_party == \"Unknown\": c_party = front_affiliation\n","\n","                        district_data.append({\n","                            \"District\": dist_name,\n","                            \"Local Body Type\": type_name,\n","                            \"Local Body ID\": lb_id,\n","                            \"Local Body\": lb_name,\n","                            \"Ward Number\": ward_num,\n","                            \"Ward Name\": ward_name,\n","                            \"Candidate\": c_name,\n","                            \"Party\": c_party,\n","                            \"Front\": front_affiliation,\n","                            \"Votes\": c_votes,\n","                            \"Year\": 2020\n","                        })\n","\n","                        time.sleep(0.001)\n","\n","                except Exception:\n","                    pass\n","            print(f\"\\n      -> Finished {type_name}\")\n","\n","        # --- SAVE ---\n","        if district_data:\n","            filename = f\"Kerala_{dist_code}_{dist_name}_2020.csv\"\n","            df = pd.DataFrame(district_data)\n","            df.to_csv(filename, index=False, encoding='utf-8-sig')\n","            print(f\"\\n[SAVED] {filename} with {len(df)} rows.\")\n","\n","if __name__ == \"__main__\":\n","    scrape_all_districts_2020()"]},{"cell_type":"markdown","source":["Combing 2025, 2020 and 2015 results"],"metadata":{"id":"O2w1x2KZwj5f"}},{"cell_type":"code","source":["import pandas as pd\n","import glob\n","import os\n","\n","def simple_combine_all():\n","    print(\"--- UNIVERSAL CSV MERGER ---\")\n","\n","    # 1. Find ALL CSV files in the folder\n","    all_csvs = glob.glob(\"*.csv\")\n","\n","    # Exclude the output filename itself if it exists to avoid infinite loops\n","    output_filename = \"Kerala_Election_Complete_Master.csv\"\n","    files_to_merge = [f for f in all_csvs if f != output_filename]\n","\n","    if not files_to_merge:\n","        print(\"[ERROR] No CSV files found in the folder!\")\n","        print(\"Please make sure you have uploaded the files.\")\n","        return\n","\n","    print(f\"Found {len(files_to_merge)} files to merge:\")\n","    for f in files_to_merge:\n","        print(f\"  - {f}\")\n","\n","    # 2. Read and Merge\n","    df_list = []\n","    for filename in files_to_merge:\n","        try:\n","            df = pd.read_csv(filename)\n","\n","            # Optional: Attempt to detect year if missing\n","            if 'Year' not in df.columns:\n","                if '2015' in filename: df['Year'] = 2015\n","                elif '2020' in filename: df['Year'] = 2020\n","                elif '2025' in filename: df['Year'] = 2025\n","\n","            df_list.append(df)\n","            print(f\"    > Loaded {len(df)} rows from {filename}\")\n","        except Exception as e:\n","            print(f\"    x Skipped {filename}: {e}\")\n","\n","    # 3. Save Final File\n","    if df_list:\n","        master_df = pd.concat(df_list, ignore_index=True)\n","\n","        # Sort if possible\n","        if 'Year' in master_df.columns and 'District' in master_df.columns:\n","            master_df.sort_values(by=['Year', 'District', 'Local Body'], inplace=True)\n","\n","        master_df.to_csv(output_filename, index=False, encoding='utf-8-sig')\n","\n","        print(\"\\n\" + \"=\"*30)\n","        print(\"SUCCESS! MERGE COMPLETE\")\n","        print(\"=\"*30)\n","        print(f\"Saved as: {output_filename}\")\n","        print(f\"Total Rows: {len(master_df)}\")\n","        if 'Year' in master_df.columns:\n","            print(\"Breakdown by Year:\")\n","            print(master_df['Year'].value_counts().to_string())\n","    else:\n","        print(\"Nothing to save.\")\n","\n","simple_combine_all()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u1tWptsDwjN2","executionInfo":{"status":"ok","timestamp":1766351991461,"user_tz":-330,"elapsed":1345,"user":{"displayName":"FARHAN JAFFAR","userId":"00674461129948116447"}},"outputId":"2c7a7b0a-415b-4a33-f76b-0267e87269d9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--- UNIVERSAL CSV MERGER ---\n","Found 3 files to merge:\n","  - Kerala_LocalBodies_Election_2020_MASTER.csv\n","  - Kerala_LocalBodies_Election_2025_MASTER.csv\n","  - Kerala_LocalBodies_Election_2015_MASTER.csv\n","    > Loaded 21783 rows from Kerala_LocalBodies_Election_2020_MASTER.csv\n","    > Loaded 23531 rows from Kerala_LocalBodies_Election_2025_MASTER.csv\n","    > Loaded 21823 rows from Kerala_LocalBodies_Election_2015_MASTER.csv\n","\n","==============================\n","SUCCESS! MERGE COMPLETE\n","==============================\n","Saved as: Kerala_Election_Complete_Master.csv\n","Total Rows: 67137\n","Breakdown by Year:\n","Year\n","2025    23531\n","2015    21823\n","2020    21783\n"]}]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPPJ/L21VEzszrtf75yOD2R"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}